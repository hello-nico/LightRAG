#!/usr/bin/env python3
"""
åˆ†ædomain_kg_enhanced.jsonæ•°æ®ç»“æ„å¹¶ç»Ÿè®¡ä¿¡æ¯
"""

import json
from collections import Counter
from typing import Dict, List, Any

def analyze_kg_structure(file_path: str) -> Dict[str, Any]:
    """åˆ†æKGæ•°æ®ç»“æ„å¹¶è¿”å›ç»Ÿè®¡ä¿¡æ¯"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # åŸºæœ¬ç»Ÿè®¡
    domain_name = data.get('domain_name', 'Unknown')
    entities = data.get('entities', [])
    relationships = data.get('relationships', [])
    
    # å®ä½“ç»Ÿè®¡
    entity_types = Counter()
    entity_names = []
    
    for entity in entities:
        entity_type = entity.get('type', 'Unknown')
        entity_name = entity.get('name', 'Unknown')
        entity_types[entity_type] += 1
        entity_names.append(entity_name)
    
    # å…³ç³»ç»Ÿè®¡
    relationship_descriptions = []
    relationship_weights = []
    
    for rel in relationships:
        description = rel.get('description', 'Unknown')
        weight = rel.get('weight', 0.0)
        relationship_descriptions.append(description)
        relationship_weights.append(weight)
    
    # åˆ†æå…³ç³»ç±»å‹ï¼ˆåŸºäºæè¿°å’Œå®ä½“ç±»å‹ç»„åˆï¼‰
    relationship_types = Counter()
    for rel in relationships:
        src_id = rel.get('src_id', '')
        tgt_id = rel.get('tgt_id', '')
        description = rel.get('description', '')
        
        # æ ¹æ®æè¿°æ¨æ–­å…³ç³»ç±»å‹
        desc_lower = description.lower()
        if 'author' in desc_lower or 'ä½œè€…' in description:
            rel_type = 'authorship'
        elif 'affiliated' in desc_lower or 'institution' in desc_lower or 'æœºæ„' in description:
            rel_type = 'affiliation'
        elif 'component' in desc_lower or 'ç»„æˆéƒ¨åˆ†' in description:
            rel_type = 'component_of'
        elif 'used' in desc_lower or 'ä½¿ç”¨' in description:
            rel_type = 'uses'
        elif 'evaluated' in desc_lower or 'evaluation' in desc_lower or 'è¯„ä¼°' in description:
            rel_type = 'evaluation'
        elif 'application' in desc_lower or 'åº”ç”¨' in description:
            rel_type = 'application'
        elif 'based' in desc_lower or 'åŸºç¡€' in description:
            rel_type = 'based_on'
        else:
            rel_type = 'related_to'
        
        relationship_types[rel_type] += 1
    
    return {
        'domain_name': domain_name,
        'total_entities': len(entities),
        'total_relationships': len(relationships),
        'entity_types': dict(entity_types),
        'relationship_types': dict(relationship_types),
        'sample_entities': entity_names[:10],  # æ˜¾ç¤ºå‰10ä¸ªå®ä½“
        'sample_relationships': relationship_descriptions[:5],  # æ˜¾ç¤ºå‰5ä¸ªå…³ç³»
        'weight_stats': {
            'min': min(relationship_weights) if relationship_weights else 0,
            'max': max(relationship_weights) if relationship_weights else 0,
            'avg': sum(relationship_weights) / len(relationship_weights) if relationship_weights else 0
        }
    }

def print_analysis_report(stats: Dict[str, Any]):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    print("=" * 60)
    print(f"ğŸ“Š KGæ•°æ®åˆ†ææŠ¥å‘Š: {stats['domain_name']}")
    print("=" * 60)
    
    print(f"\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
    print(f"   â€¢ å®ä½“æ€»æ•°: {stats['total_entities']}")
    print(f"   â€¢ å…³ç³»æ€»æ•°: {stats['total_relationships']}")
    print(f"   â€¢ å®ä½“ç±»å‹æ•°: {len(stats['entity_types'])}")
    print(f"   â€¢ å…³ç³»ç±»å‹æ•°: {len(stats['relationship_types'])}")
    
    print(f"\nğŸ·ï¸  å®ä½“ç±»å‹åˆ†å¸ƒ:")
    for entity_type, count in sorted(stats['entity_types'].items(), key=lambda x: x[1], reverse=True):
        percentage = (count / stats['total_entities']) * 100
        print(f"   â€¢ {entity_type}: {count} ({percentage:.1f}%)")
    
    print(f"\nğŸ”— å…³ç³»ç±»å‹åˆ†å¸ƒ:")
    for rel_type, count in sorted(stats['relationship_types'].items(), key=lambda x: x[1], reverse=True):
        percentage = (count / stats['total_relationships']) * 100
        print(f"   â€¢ {rel_type}: {count} ({percentage:.1f}%)")
    
    print(f"\nâš–ï¸  å…³ç³»æƒé‡ç»Ÿè®¡:")
    weight_stats = stats['weight_stats']
    print(f"   â€¢ æœ€å°å€¼: {weight_stats['min']:.2f}")
    print(f"   â€¢ æœ€å¤§å€¼: {weight_stats['max']:.2f}")
    print(f"   â€¢ å¹³å‡å€¼: {weight_stats['avg']:.2f}")
    
    print(f"\nğŸ“ å®ä½“æ ·æœ¬ (å‰10ä¸ª):")
    for i, entity in enumerate(stats['sample_entities'], 1):
        print(f"   {i:2d}. {entity}")
    
    print(f"\nğŸ”— å…³ç³»æ ·æœ¬ (å‰5ä¸ª):")
    for i, rel in enumerate(stats['sample_relationships'], 1):
        print(f"   {i}. {rel}")

if __name__ == "__main__":
    file_path = "/home/chencheng/py/src/LightRAG/datasets/domain_kg_enhanced.json"
    stats = analyze_kg_structure(file_path)
    print_analysis_report(stats)