{
  "domain_name": "RAG",
  "entities": [
    {
      "name": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "type": "Paper",
      "description": "Paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)"
    },
    {
      "name": "Patrick Lewis",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Ethan Perez",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Aleksandra Piktus",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Fabio Petroni",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Vladimir Karpukhin",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Naman Goyal",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Heinrich Küttler",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Mike Lewis",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Wen-tau Yih",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Tim Rocktäschel",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Sebastian Riedel",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Douwe Kiela",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "Facebook AI Research",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "University College London",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "New York University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "name": "DPR (Dense Passage Retriever)",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Bi-encoder architecture with BERT-base document encoder and query encoder"
    },
    {
      "name": "BERT-base",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used as document encoder and query encoder in DPR"
    },
    {
      "name": "BART-large",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Pre-trained seq2seq transformer used as generator component"
    },
    {
      "name": "Natural Questions",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Open-domain question answering dataset"
    },
    {
      "name": "TriviaQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Trivia question answering dataset"
    },
    {
      "name": "WebQuestions",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Web-based question answering dataset"
    },
    {
      "name": "CuratedTrec",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Curated TREC question answering dataset"
    },
    {
      "name": "MS-MARCO",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Machine reading comprehension dataset for abstractive QA"
    },
    {
      "name": "FEVER",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Fact extraction and verification dataset"
    },
    {
      "name": "SearchQA (Jeopardy)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Jeopardy question generation dataset"
    },
    {
      "name": "PipelineRAG",
      "type": "PipelineRAG",
      "description": "PipelineRAG: Combines pre-trained retriever (DPR) with pre-trained seq2seq model (BART) trained end-to-end"
    },
    {
      "name": "Query Encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Document Index",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Marginalization",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "DenseRetrieval",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "AbstractiveGeneration",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "JointTraining",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Exact Match (EM)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Exact string match between generated and reference answers for QA tasks"
    },
    {
      "name": "BLEU-1",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Unigram BLEU score for generation quality"
    },
    {
      "name": "ROUGE-L",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Longest common subsequence based ROUGE score"
    },
    {
      "name": "Q-BLEU-1",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Question-specific BLEU variant with higher weight for matching entities"
    },
    {
      "name": "Label Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Classification accuracy for FEVER fact verification task"
    },
    {
      "name": "Factuality",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation of whether statements can be corroborated by trusted external sources"
    },
    {
      "name": "Specificity",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation of mutual dependence between input and output"
    },
    {
      "name": "Fairseq",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "HuggingFace Transformers",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "FAISS",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "QA",
      "type": "QA",
      "description": "Target task: QA"
    },
    {
      "name": "DocumentSummarization",
      "type": "DocumentSummarization",
      "description": "Target task: DocumentSummarization"
    },
    {
      "name": "ConversationalAI",
      "type": "ConversationalAI",
      "description": "Target task: ConversationalAI"
    },
    {
      "name": "Open-domain question answering",
      "type": "DomainApplication",
      "description": "Domain application: Open-domain question answering"
    },
    {
      "name": "Abstractive question answering",
      "type": "DomainApplication",
      "description": "Domain application: Abstractive question answering"
    },
    {
      "name": "Fact verification",
      "type": "DomainApplication",
      "description": "Domain application: Fact verification"
    },
    {
      "name": "Question generation",
      "type": "DomainApplication",
      "description": "Domain application: Question generation"
    },
    {
      "name": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "type": "Paper",
      "description": "Paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION (2023)"
    },
    {
      "name": "Akari Asai",
      "type": "Author",
      "description": "Author of paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "Zeqiu Wu",
      "type": "Author",
      "description": "Author of paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "Yizhong Wang",
      "type": "Author",
      "description": "Author of paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "Avirup Sil",
      "type": "Author",
      "description": "Author of paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "Hannaneh Hajishirzi",
      "type": "Author",
      "description": "Author of paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "University of Washington",
      "type": "Institution",
      "description": "Institution affiliated with paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "Allen Institute for AI",
      "type": "Institution",
      "description": "Institution affiliated with paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "IBM Research AI",
      "type": "Institution",
      "description": "Institution affiliated with paper: SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "name": "Contriever-MS MARCO",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Off-the-shelf retriever model used to retrieve up to ten documents for each input"
    },
    {
      "name": "Llama2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Base language model used for both generator and critic initialization"
    },
    {
      "name": "GPT-4",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used to generate reflection tokens for training data collection"
    },
    {
      "name": "SELF-RAG",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned language model that generates text with reflection tokens"
    },
    {
      "name": "Open-Instruct",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Diverse instruction-following input-output pairs including ShareGPT, GPT-4 Alpaca, Alpaca, OpenAssistant, and FLAN subsets"
    },
    {
      "name": "PopQA",
      "type": "TestDataset",
      "description": "TestDataset: Long-tail subset with rare entity queries whose monthly Wikipedia page views are less than 100"
    },
    {
      "name": "TriviaQA-unfiltered",
      "type": "TestDataset",
      "description": "TestDataset: Open-domain question answering dataset"
    },
    {
      "name": "ASQA",
      "type": "TestDataset",
      "description": "TestDataset: Long-form question answering task from ALCE"
    },
    {
      "name": "PubHealth",
      "type": "TestDataset",
      "description": "TestDataset: Health-related fact verification dataset"
    },
    {
      "name": "ARC-Challenge",
      "type": "TestDataset",
      "description": "TestDataset: AI2 Reasoning Challenge dataset"
    },
    {
      "name": "AdaptiveRAG",
      "type": "AdaptiveRAG",
      "description": "AdaptiveRAG: Self-Reflective Retrieval-Augmented Generation framework that adaptively retrieves passages on-demand and generates reflection tokens"
    },
    {
      "name": "Generator LM",
      "type": "Method",
      "description": "Component in AdaptiveRAG"
    },
    {
      "name": "Retriever",
      "type": "Method",
      "description": "Component in AdaptiveRAG"
    },
    {
      "name": "Critic Model",
      "type": "Method",
      "description": "Component in AdaptiveRAG"
    },
    {
      "name": "Reflection Tokens",
      "type": "Method",
      "description": "Component in AdaptiveRAG"
    },
    {
      "name": "IterativeGeneration",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "SeparateTraining",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Standard accuracy metric for closed-set tasks like PubHealth and ARC-Challenge"
    },
    {
      "name": "FactScore",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Fine-grained atomic evaluation of factual precision in long form text generation"
    },
    {
      "name": "Citation Precision",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures whether model-generated claims are precisely grounded in citations"
    },
    {
      "name": "Citation Recall",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures coverage of citation support for generated content"
    },
    {
      "name": "MAUVE",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Measures the gap between neural text and human text using divergence frontiers"
    },
    {
      "name": "str-em",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: String exact match metric for evaluating correctness in ASQA"
    },
    {
      "name": "ROUGE",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Standard ROUGE metric for text generation evaluation"
    },
    {
      "name": "Wikipedia embeddings",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Contriever-MS MARCO",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "FactScore",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "MAUVE",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Open-domain QA",
      "type": "DomainApplication",
      "description": "Domain application: Open-domain QA"
    },
    {
      "name": "Long-form generation",
      "type": "DomainApplication",
      "description": "Domain application: Long-form generation"
    },
    {
      "name": "Reasoning tasks",
      "type": "DomainApplication",
      "description": "Domain application: Reasoning tasks"
    },
    {
      "name": "Biography generation",
      "type": "DomainApplication",
      "description": "Domain application: Biography generation"
    },
    {
      "name": "What Makes Good In-Context Examples for GPT-3?",
      "type": "Paper",
      "description": "Paper: What Makes Good In-Context Examples for GPT-3? (2021)"
    },
    {
      "name": "Jiachang Liu",
      "type": "Author",
      "description": "Author of paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Dinghan Shen",
      "type": "Author",
      "description": "Author of paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Yizhe Zhang",
      "type": "Author",
      "description": "Author of paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Bill Dolan",
      "type": "Author",
      "description": "Author of paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Lawrence Carin",
      "type": "Author",
      "description": "Author of paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Weizhu Chen",
      "type": "Author",
      "description": "Author of paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Duke University",
      "type": "Institution",
      "description": "Institution affiliated with paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Microsoft Dynamics 365 AI",
      "type": "Institution",
      "description": "Institution affiliated with paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "Microsoft Research",
      "type": "Institution",
      "description": "Institution affiliated with paper: What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "name": "RoBERTa-large",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Pre-trained RoBERTa-large model used as sentence encoder for computing semantic similarity"
    },
    {
      "name": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: RoBERTa-large model fine-tuned on natural language inference datasets"
    },
    {
      "name": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: RoBERTa-large model fine-tuned on NLI and semantic textual similarity datasets"
    },
    {
      "name": "GPT-3",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Large-scale autoregressive language model used for in-context few-shot learning"
    },
    {
      "name": "SST-2",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Stanford Sentiment Treebank dataset used as source for in-context examples"
    },
    {
      "name": "IMDB",
      "type": "TestDataset",
      "description": "TestDataset: Movie review sentiment classification dataset used for evaluation"
    },
    {
      "name": "ToTTo",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Controlled table-to-text generation dataset with Wikipedia tables"
    },
    {
      "name": "Natural Questions (NQ)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Open-domain question answering dataset with real user questions"
    },
    {
      "name": "Web Questions (WQ)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Question answering dataset based on Freebase knowledge base"
    },
    {
      "name": "Sentence encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Similarity computation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "k-NN retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Context construction",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "GPT-3 generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "BLEU",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Bilingual Evaluation Understudy score for table-to-text generation quality"
    },
    {
      "name": "PARENT",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Precision and recall metric for table-to-text generation that considers table content"
    },
    {
      "name": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "type": "Paper",
      "description": "Paper: Retrieval Augmented Classification for Long-Tail Visual Recognition (2022)"
    },
    {
      "name": "Alexander Long",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Wei Yin",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Thalaiyasingam Ajanthan",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Vu Nguyen",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Pulak Purkait",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Ravi Garg",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Alan Blair",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Chunhua Shen",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Anton van den Hengel",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Amazon",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "The University of Adelaide",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "University of New South Wales",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "Zhejiang University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "name": "ViT-B-16",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Visual Image Transformer used as frozen pretrained image encoder for retrieval module"
    },
    {
      "name": "ViT-B-16",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Visual Image Transformer used as base image encoder backbone"
    },
    {
      "name": "BERT-like text encoder from CLIP",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Text encoder for processing retrieved text snippets"
    },
    {
      "name": "Places365-LT",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Synthetic long-tail variant of Places2 with highly skewed class distribution"
    },
    {
      "name": "iNaturalist-2018",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Fine-grained species classification with naturally occurring class imbalance"
    },
    {
      "name": "ImageNet21k",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Used for expanding the external memory index"
    },
    {
      "name": "Base image encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Retrieval module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "External memory index",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Text encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Logit combination mechanism",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Top-1 Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Standard classification accuracy measured on balanced test sets"
    },
    {
      "name": "Per-class Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Accuracy bucketed into few-shot (<20), medium (≤100), and many (>100) shot categories"
    },
    {
      "name": "MedicalRAG",
      "type": "MedicalRAG",
      "description": "Domain application: MedicalRAG"
    },
    {
      "name": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "type": "Paper",
      "description": "Paper: Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context (2024)"
    },
    {
      "name": "Gemini Team",
      "type": "Author",
      "description": "Author of paper: Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
    },
    {
      "name": "Google",
      "type": "Author",
      "description": "Author of paper: Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
    },
    {
      "name": "Google",
      "type": "Institution",
      "description": "Institution affiliated with paper: Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
    },
    {
      "name": "Gemini 1.5 Pro",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Sparse mixture-of-expert (MoE) Transformer-based model with long-context capabilities up to 10M tokens"
    },
    {
      "name": "Gemini 1.5 Flash",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense Transformer decoder model with 2M+ context and multimodal capabilities, designed for efficient utilization"
    },
    {
      "name": "Gemini 1.5 Pro",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Multimodal model capable of processing text, images, video, and audio with millions of tokens context"
    },
    {
      "name": "Gemini 1.5 Flash",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Lightweight variant designed for efficiency with minimal regression in quality, online distilled from Gemini 1.5 Pro"
    },
    {
      "name": "Natural_Questions",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Used for evaluation of long-context QA capabilities"
    },
    {
      "name": "BEIR",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Benchmark for information retrieval evaluation"
    },
    {
      "name": "End2EndRAG",
      "type": "End2EndRAG",
      "description": "End2EndRAG: Native multimodal transformer architecture with extremely long context windows eliminating need for external retrieval"
    },
    {
      "name": "Sparse MoE layers",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Long-context attention",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Multimodal encoders",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Online distillation",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Needle-in-a-haystack recall",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Measures ability to retrieve specific information from long contexts, achieving >99% recall up to 10M tokens"
    },
    {
      "name": "Perplexity",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Negative log-likelihood evaluation showing continued improvement in next-token prediction up to 10M tokens"
    },
    {
      "name": "Long-document QA accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Question answering performance on long documents like Les Misérables (710k tokens)"
    },
    {
      "name": "Video QA accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Performance on hour-long video question answering tasks"
    },
    {
      "name": "JAX",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "ML Pathways",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "LegalRAG",
      "type": "LegalRAG",
      "description": "Domain application: LegalRAG"
    },
    {
      "name": "EducationalRAG",
      "type": "EducationalRAG",
      "description": "Domain application: EducationalRAG"
    },
    {
      "name": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "type": "Paper",
      "description": "Paper: A Survey of Knowledge-Enhanced Pre-trained Language Models (2022)"
    },
    {
      "name": "Linmei Hu",
      "type": "Author",
      "description": "Author of paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Zeyi Liu",
      "type": "Author",
      "description": "Author of paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Ziwang Zhao",
      "type": "Author",
      "description": "Author of paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Lei Hou",
      "type": "Author",
      "description": "Author of paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Liqiang Nie",
      "type": "Author",
      "description": "Author of paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Juanzi Li",
      "type": "Author",
      "description": "Author of paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Beijing Institute of Technology",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Beijing University of Posts and Telecommunications",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Tsinghua University",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "Harbin Institute of Technology (Shenzhen)",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "name": "REALM",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: utilizes text corpus to train a text retriever explicitly, exploiting information retrieved from external knowledge bases such as Wikipedia documents"
    },
    {
      "name": "BERT",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: masked language model (bidirectional) that aims to predict the 'masked' word conditioned on all the other words"
    },
    {
      "name": "GPT",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: autoregressive language model (unidirectional) which predicts the next word given all the previous words"
    },
    {
      "name": "T5",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: encoder-decoder language model that learns to generate a sequence when given an input sequence"
    },
    {
      "name": "BART",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: encoder-decoder language model for denoising sequence-to-sequence pre-training"
    },
    {
      "name": "WikiText",
      "type": "TrainingDataset",
      "description": "TrainingDataset: General-domain text collection"
    },
    {
      "name": "Wikipedia",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Large text corpus used for knowledge retrieval"
    },
    {
      "name": "HierarchicalRAG",
      "type": "HierarchicalRAG",
      "description": "HierarchicalRAG: Knowledge-Enhanced Pre-trained Language Models with different integration strategies for NLU and NLG tasks"
    },
    {
      "name": "Knowledge Integration Module",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Pre-trained Language Model",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Task-specific Fine-tuning",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Knowledge Fusion Components",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "HybridRetrieval",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "HybridGeneration",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Performance on downstream tasks",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluation on various NLU and NLG tasks including text classification, relation extraction, question answering, dialogue generation"
    },
    {
      "name": "Knowledge reasoning capability",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Assessment of symbolic reasoning capabilities and commonsense reasoning performance"
    },
    {
      "name": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "type": "Paper",
      "description": "Paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN (2020)"
    },
    {
      "name": "Shangqing Liu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "Yu Chen",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "Xiaofei Xie",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "Jingkai Siow",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "Yang Liu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "Nanyang Technology University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "Rensselaer Polytechnic Institute",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "name": "BiLSTM",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used to encode node sequences and retrieved summaries"
    },
    {
      "name": "Lucene",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for text similarity calculation and retrieval"
    },
    {
      "name": "LSTM Decoder",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Attention-based LSTM decoder for summary generation"
    },
    {
      "name": "Hybrid GNN (HGNN)",
      "type": "DomainSpecificModel",
      "description": "DomainSpecificModel: Novel hybrid graph neural network combining static and dynamic message passing"
    },
    {
      "name": "C Code Summarization Dataset (CCSD)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: New challenging benchmark crawled from diversified large-scale open-source C projects"
    },
    {
      "name": "Python Code Summarization Dataset (PCSD)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Public dataset used for comparison with existing methods"
    },
    {
      "name": "Retrieval-augmented Static Graph Construction",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Attention-based Dynamic Graph Construction",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Hybrid Message Passing GNN",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "LSTM Decoder",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "BLEU-4",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Automatic evaluation metric for machine translation and text summarization"
    },
    {
      "name": "METEOR",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Metric for evaluation of translation with explicit ordering"
    },
    {
      "name": "Relevance",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation of relevance between generated summary and source code"
    },
    {
      "name": "Similarity",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation of similarity between generated and ground-truth summaries"
    },
    {
      "name": "Code Summarization",
      "type": "DomainApplication",
      "description": "Domain application: Code Summarization"
    },
    {
      "name": "Software Engineering",
      "type": "DomainApplication",
      "description": "Domain application: Software Engineering"
    },
    {
      "name": "Program Comprehension",
      "type": "DomainApplication",
      "description": "Domain application: Program Comprehension"
    },
    {
      "name": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "type": "Paper",
      "description": "Paper: Few-Shot Bot: Prompt-Based Learning for Dialogue Systems (2021)"
    },
    {
      "name": "Andrea Madotto",
      "type": "Author",
      "description": "Author of paper: Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "name": "Zhaojiang Lin",
      "type": "Author",
      "description": "Author of paper: Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "name": "Genta Indra Winata",
      "type": "Author",
      "description": "Author of paper: Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "name": "Pascale Fung",
      "type": "Author",
      "description": "Author of paper: Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "name": "The Hong Kong University of Science and Technology",
      "type": "Institution",
      "description": "Institution affiliated with paper: Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "name": "TF-IDF",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: traditional sparse retrieval method"
    },
    {
      "name": "GPT-2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: GPT-2 models of four sizes (0.1B, 0.3B, 0.8B, 1.6B)"
    },
    {
      "name": "GPT-NEO",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: GPT models trained on The Pile dataset"
    },
    {
      "name": "GPT-J",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: largest released language model used in experiments"
    },
    {
      "name": "GPT-Jurassic",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: accessible via API for FSB deployment"
    },
    {
      "name": "Wizard of Wikipedia (WoW)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: open-domain conversational dataset grounded on Wikipedia knowledge"
    },
    {
      "name": "Wizard of Internet (WiT)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: open-domain conversational dataset grounded on knowledge retrieved from the internet"
    },
    {
      "name": "PersonaChat",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: human-to-human multi-turn dialogue dataset with persona information"
    },
    {
      "name": "Multi-Session Chat (MSC)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: extension of PersonaChat simulating long-term conversations"
    },
    {
      "name": "DialKG",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: KG grounded dialogue dataset"
    },
    {
      "name": "Skill Selector",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Knowledge Retrievers",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Response Generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Conversational Parser",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "No training required",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "F1 Score",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: harmonic mean of precision and recall for token-level matching"
    },
    {
      "name": "Rouge-L",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: longest common subsequence based evaluation"
    },
    {
      "name": "Joint Goal Accuracy (JGA)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: accuracy of dialogue state tracking predictions"
    },
    {
      "name": "Retrieval Precision (RPrec)",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: precision of retrieved documents for knowledge grounding"
    },
    {
      "name": "ParlAI",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Neo4J",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "KILT",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "open-domain chat",
      "type": "DomainApplication",
      "description": "Domain application: open-domain chat"
    },
    {
      "name": "task-oriented dialogue",
      "type": "DomainApplication",
      "description": "Domain application: task-oriented dialogue"
    },
    {
      "name": "knowledge-grounded conversation",
      "type": "DomainApplication",
      "description": "Domain application: knowledge-grounded conversation"
    },
    {
      "name": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "type": "Paper",
      "description": "Paper: Re-Imagen: Retrieval-Augmented Text-to-Image Generator (2022)"
    },
    {
      "name": "Wenhu Chen",
      "type": "Author",
      "description": "Author of paper: Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "name": "Hexiang Hu",
      "type": "Author",
      "description": "Author of paper: Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "name": "Chitwan Saharia",
      "type": "Author",
      "description": "Author of paper: Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "name": "William W. Cohen",
      "type": "Author",
      "description": "Author of paper: Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "name": "Google Research",
      "type": "Institution",
      "description": "Institution affiliated with paper: Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "name": "BM25",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Text-to-text BM25 similarity for retrieving top-k neighbors from external knowledge base"
    },
    {
      "name": "CLIP",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Experimented with CLIP similarity scores for retrieval"
    },
    {
      "name": "Re-Imagen",
      "type": "DomainSpecificModel",
      "description": "DomainSpecificModel: Cascaded diffusion model consisting of 64×64 text-to-image model, 256×256 super-resolution model, and 1024×1024 super-resolution model"
    },
    {
      "name": "KNN-ImageText",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Constructed dataset based on Imagen's training data, where each instance is associated with top-k nearest neighbors based on BM25 score"
    },
    {
      "name": "COCO",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Widely-used benchmark for text-to-image generation evaluation"
    },
    {
      "name": "WikiImages",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Entity-focused dataset constructed from WebQA multimodal corpus from Wikimedia Commons"
    },
    {
      "name": "EntityDrawBench",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: New benchmark evaluating image generation for diverse entities from frequent to rare across dogs, foods, landmarks, birds, and characters"
    },
    {
      "name": "LAION-400M",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Out-of-domain dataset used as external knowledge base for retrieval"
    },
    {
      "name": "DStack encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "UStack decoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Multi-head attention module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "External knowledge base",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Retrieval system",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FID",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Fréchet Inception Distance for measuring image quality and distribution similarity"
    },
    {
      "name": "Faithfulness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation metric rating whether image is faithful to both entity appearance and text description"
    },
    {
      "name": "Photorealism",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation metric rating whether image is moderately realistic without noticeable artifacts"
    },
    {
      "name": "Text-to-image generation",
      "type": "TaskApplication",
      "description": "Target task: Text-to-image generation"
    },
    {
      "name": "Rare entity visualization",
      "type": "TaskApplication",
      "description": "Target task: Rare entity visualization"
    },
    {
      "name": "Multi-modal content generation",
      "type": "TaskApplication",
      "description": "Target task: Multi-modal content generation"
    },
    {
      "name": "Visual content creation",
      "type": "DomainApplication",
      "description": "Domain application: Visual content creation"
    },
    {
      "name": "Educational visualization",
      "type": "DomainApplication",
      "description": "Domain application: Educational visualization"
    },
    {
      "name": "Cultural artifact generation",
      "type": "DomainApplication",
      "description": "Domain application: Cultural artifact generation"
    },
    {
      "name": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "type": "Paper",
      "description": "Paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey (2024)"
    },
    {
      "name": "Penghao Zhao",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Hailin Zhang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Qinhan Yu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Zhengren Wang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Yunteng Geng",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Fangcheng Fu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Ling Yang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Wentao Zhang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Jie Jiang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Bin Cui",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "Peking University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "name": "BERT",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Pre-trained model employed to encode queries and keys individually for dense passage retrieval"
    },
    {
      "name": "DPR",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense Passage Retrieval model for encoding queries and documents"
    },
    {
      "name": "GPT series",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Large Language Models for text and code generation"
    },
    {
      "name": "LLAMA series",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Open foundation models for various text generation tasks"
    },
    {
      "name": "Stable Diffusion",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Latent diffusion model for text-to-image generation"
    },
    {
      "name": "Data Store",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Augmentation Methodology",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Precision",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Measures the fraction of retrieved documents that are relevant"
    },
    {
      "name": "Recall",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Measures the fraction of relevant documents that are retrieved"
    },
    {
      "name": "F1Score",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Harmonic mean of precision and recall"
    },
    {
      "name": "LangChain",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "LlamaIndex",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Pinecone",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Weaviate",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Chroma",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "RAGAS",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "TrueLens",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "CodeGeneration",
      "type": "TaskApplication",
      "description": "Target task: CodeGeneration"
    },
    {
      "name": "ImageCaptioning",
      "type": "TaskApplication",
      "description": "Target task: ImageCaptioning"
    },
    {
      "name": "VideoQA",
      "type": "TaskApplication",
      "description": "Target task: VideoQA"
    },
    {
      "name": "AudioGeneration",
      "type": "TaskApplication",
      "description": "Target task: AudioGeneration"
    },
    {
      "name": "ScientificRAG",
      "type": "DomainApplication",
      "description": "Domain application: ScientificRAG"
    },
    {
      "name": "Gorilla: Large Language Model Connected with Massive APIs",
      "type": "Paper",
      "description": "Paper: Gorilla: Large Language Model Connected with Massive APIs (2023)"
    },
    {
      "name": "Shishir G. Patil",
      "type": "Author",
      "description": "Author of paper: Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "name": "Tianjun Zhang",
      "type": "Author",
      "description": "Author of paper: Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "name": "Xin Wang",
      "type": "Author",
      "description": "Author of paper: Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "name": "Joseph E. Gonzalez",
      "type": "Author",
      "description": "Author of paper: Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "name": "UC Berkeley",
      "type": "Institution",
      "description": "Institution affiliated with paper: Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "name": "GPT-Index",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Uses text-davinci-003 from OpenAI for retrieval"
    },
    {
      "name": "Gorilla",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Retrieve-aware finetuned LLaMA-7B model specifically for API calls"
    },
    {
      "name": "LLaMA-7B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Base model used for fine-tuning Gorilla"
    },
    {
      "name": "GPT-4",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: State-of-the-art LLM used as baseline, gpt-4-0314 checkpoint"
    },
    {
      "name": "GPT-3.5-turbo",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Conversational model used as baseline, gpt-3.5-turbo-0301 checkpoint"
    },
    {
      "name": "Claude",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Language model by Anthropic with lengthy context capabilities, claude-v1 checkpoint"
    },
    {
      "name": "APIBench",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Comprehensive dataset consisting of HuggingFace (925), TorchHub (94), and TensorHub (696) APIs"
    },
    {
      "name": "HuggingFace APIs",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Covers 7 domains in multimodal, 8 in CV, 12 in NLP, 5 in Audio, 2 in tabular, 2 in RL"
    },
    {
      "name": "TorchHub APIs",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: All available API calls from PyTorch Hub"
    },
    {
      "name": "TensorHub APIs",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: All API calls from TensorFlow Hub v2"
    },
    {
      "name": "Document retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Fine-tuned LLaMA model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "AST evaluation system",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FinetuningStrategy",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "AST Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: AST sub-tree matching to verify functional correctness of generated API calls"
    },
    {
      "name": "Hallucination Rate",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Percentage of API calls that invoke entirely imagined tools not present in the database"
    },
    {
      "name": "Error Rate",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Percentage of incorrect API calls that exist in database but are wrongly invoked"
    },
    {
      "name": "Constraint Satisfaction",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Ability to respect constraints like accuracy thresholds when selecting APIs"
    },
    {
      "name": "Self-Instruct",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "BM25",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "GPT-Index",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "AST parser",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Custom evaluation framework",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "API call generation",
      "type": "TaskApplication",
      "description": "Target task: API call generation"
    },
    {
      "name": "Tool usage",
      "type": "TaskApplication",
      "description": "Target task: Tool usage"
    },
    {
      "name": "Machine Learning model deployment",
      "type": "DomainApplication",
      "description": "Domain application: Machine Learning model deployment"
    },
    {
      "name": "API integration",
      "type": "DomainApplication",
      "description": "Domain application: API integration"
    },
    {
      "name": "Tool-augmented LLMs",
      "type": "DomainApplication",
      "description": "Domain application: Tool-augmented LLMs"
    },
    {
      "name": "RAFT: Adapting Language Model to Domain Specific RAG",
      "type": "Paper",
      "description": "Paper: RAFT: Adapting Language Model to Domain Specific RAG (2024)"
    },
    {
      "name": "Naman Jain",
      "type": "Author",
      "description": "Author of paper: RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "name": "Sheng Shen",
      "type": "Author",
      "description": "Author of paper: RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "name": "Matei Zaharia",
      "type": "Author",
      "description": "Author of paper: RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "name": "Ion Stoica",
      "type": "Author",
      "description": "Author of paper: RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "name": "Standard retriever",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used to retrieve top-k documents, RAFT is independent of the specific retriever used"
    },
    {
      "name": "LLaMA2-7B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Base model used for RAFT fine-tuning experiments"
    },
    {
      "name": "RAFT (LLaMA2-7B)",
      "type": "FinetunedModel",
      "description": "FinetunedModel: LLaMA2-7B fine-tuned using RAFT methodology"
    },
    {
      "name": "GPT-3.5",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used as reference baseline for comparison"
    },
    {
      "name": "GPT-4-1106",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used to generate Chain-of-Thought prompts"
    },
    {
      "name": "PubMed QA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Question-answering dataset based on medical documents"
    },
    {
      "name": "HotpotQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Multi-hop question answering dataset based on Wikipedia"
    },
    {
      "name": "Gorilla APIBench",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Includes HuggingFace Hub, Torch Hub, and TensorFlow Hub datasets for API call generation"
    },
    {
      "name": "Fine-tuned Generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Chain-of-Thought Reasoning",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Citation Mechanism",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Performance comparison",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Comparison against baselines including LLaMA2-7B, DSF, and GPT-3.5"
    },
    {
      "name": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "type": "Paper",
      "description": "Paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators (2022)"
    },
    {
      "name": "Wenhao Yu",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Dan Iter",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Shuohang Wang",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Yichong Xu",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Mingxuan Ju",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Soumya Sanyal",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Chenguang Zhu",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Michael Zeng",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Meng Jiang",
      "type": "Author",
      "description": "Author of paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "University of Notre Dame",
      "type": "Institution",
      "description": "Institution affiliated with paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Microsoft Cognitive Service Research",
      "type": "Institution",
      "description": "Institution affiliated with paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "University of Southern California",
      "type": "Institution",
      "description": "Institution affiliated with paper: Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "name": "Contriever",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: State-of-the-art unsupervised dense retrieval model"
    },
    {
      "name": "InstructGPT",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Large language model used for generating contextual documents and reading comprehension"
    },
    {
      "name": "FiD",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fusion-in-Decoder model used as reader in supervised setting"
    },
    {
      "name": "WebQuestions (WebQ)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Questions selected using Google Suggest API with answers as entities in Freebase"
    },
    {
      "name": "Document Generator (LLM)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Document Reader (LLM or FiD)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Clustering-based Prompting Module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Recall@K",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Percentage of top-K retrieved or generated documents that contain the answer"
    },
    {
      "name": "Not specified",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Not specified",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "KILT benchmark",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Fact checking",
      "type": "DomainApplication",
      "description": "Domain application: Fact checking"
    },
    {
      "name": "Knowledge-intensive dialogue systems",
      "type": "DomainApplication",
      "description": "Domain application: Knowledge-intensive dialogue systems"
    },
    {
      "name": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "type": "Paper",
      "description": "Paper: Reducing hallucination in structured outputs via Retrieval-Augmented Generation (2024)"
    },
    {
      "name": "Patrice Béchard",
      "type": "Author",
      "description": "Author of paper: Reducing hallucination in structured outputs via Retrieval-Augmented Generation"
    },
    {
      "name": "Orlando Marquez Ayala",
      "type": "Author",
      "description": "Author of paper: Reducing hallucination in structured outputs via Retrieval-Augmented Generation"
    },
    {
      "name": "ServiceNow",
      "type": "Institution",
      "description": "Institution affiliated with paper: Reducing hallucination in structured outputs via Retrieval-Augmented Generation"
    },
    {
      "name": "all-mpnet-base-v2",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Siamese transformer encoder with mean pooling and normalization layer, fine-tuned for mapping natural language to JSON objects"
    },
    {
      "name": "GTR-T5",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Off-the-shelf sentence encoders used for comparison"
    },
    {
      "name": "StarCoderBase",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Code language model pretrained on JSON and programming languages, fine-tuned for workflow generation"
    },
    {
      "name": "CodeLlama-7B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Code language model fine-tuned for comparison"
    },
    {
      "name": "Mistral-7B-v0.1",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: General language model fine-tuned for comparison"
    },
    {
      "name": "Internal Enterprise Workflows",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Deployed workflows with annotated natural language requirements"
    },
    {
      "name": "Human Eval",
      "type": "TestDataset",
      "description": "TestDataset: Expert user interactions through UI for unbiased evaluation"
    },
    {
      "name": "Out-of-Domain Splits",
      "type": "TestDataset",
      "description": "TestDataset: Cross-domain evaluation with 7-76% unseen steps"
    },
    {
      "name": "Fine-tuned retriever encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "RAG-augmented LLM",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FAISS vector index",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "JSON schema validation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Trigger Exact Match (EM)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Verifies whether the generated JSON trigger is exactly the same as the ground-truth, including table name if required"
    },
    {
      "name": "Bag of Steps (BofS)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures overlap between generated and ground-truth JSON steps in order-agnostic fashion, similar to bag-of-words"
    },
    {
      "name": "Hallucinated Tables (HT)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Percentage of generated tables that do not exist per workflow, indicating invention by LLM"
    },
    {
      "name": "Hallucinated Steps (HS)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Percentage of generated steps that do not exist per workflow, indicating invention by LLM"
    },
    {
      "name": "Recall@15",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Retrieval evaluation for steps - whether top 15 retrieved steps cover the required steps"
    },
    {
      "name": "Recall@10",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Retrieval evaluation for tables - whether top 10 retrieved tables cover the required table"
    },
    {
      "name": "SentenceTransformers",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Workflow generation",
      "type": "TaskApplication",
      "description": "Target task: Workflow generation"
    },
    {
      "name": "Natural language to structured output conversion",
      "type": "TaskApplication",
      "description": "Target task: Natural language to structured output conversion"
    },
    {
      "name": "Enterprise automation",
      "type": "DomainApplication",
      "description": "Domain application: Enterprise automation"
    },
    {
      "name": "IT workflow management",
      "type": "DomainApplication",
      "description": "Domain application: IT workflow management"
    },
    {
      "name": "Cross-domain enterprise applications (HR, Finance)",
      "type": "DomainApplication",
      "description": "Domain application: Cross-domain enterprise applications (HR, Finance)"
    },
    {
      "name": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "type": "Paper",
      "description": "Paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters (2021)"
    },
    {
      "name": "Yan Xu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "name": "Etsuko Ishii",
      "type": "Author",
      "description": "Author of paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "name": "Samuel Cahyawijaya",
      "type": "Author",
      "description": "Author of paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "name": "Zihan Liu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "name": "Dan Su",
      "type": "Author",
      "description": "Author of paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "name": "Center for Artificial Intelligence Research (CAiRE)",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "name": "Sentence-Transformers",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Pre-trained RoBERTa (125M) model pre-trained with the NLI datasets and STS Benchmark for sentence embedding"
    },
    {
      "name": "KnowExpert",
      "type": "FinetunedModel",
      "description": "FinetunedModel: GPT-2 with lightweight adapters acting as knowledge experts, guided by contextual topic model"
    },
    {
      "name": "CMU Document Grounded Conversations (CMU_DoG)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Document-grounded conversation dataset"
    },
    {
      "name": "ModularRAG",
      "type": "Method",
      "description": "Method: GPT-2 with lightweight adapters inserted into each layer, acting as knowledge experts, guided by contextual topic model"
    },
    {
      "name": "GPT-2 backbone",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Lightweight adapters",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Contextualized Topic Model",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Knowledge experts",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "No explicit retrieval - knowledge embedded in model parameters",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Three-step training paradigm",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Perplexity (PPL)",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Perplexity of generating gold responses"
    },
    {
      "name": "Unigram F1",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Unigram F1 score between generated and gold responses"
    },
    {
      "name": "DISTINCT-1/2",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Uni-gram and bi-gram diversity metrics at corpus level"
    },
    {
      "name": "Informativeness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation of knowledge content and factuality in responses"
    },
    {
      "name": "Humanness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Human evaluation of fluency and coherence of generated responses"
    },
    {
      "name": "Amazon Mechanical Turk",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Open-domain chit-chat dialogue systems",
      "type": "DomainApplication",
      "description": "Domain application: Open-domain chit-chat dialogue systems"
    },
    {
      "name": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "type": "Paper",
      "description": "Paper: Ragas: Automated Evaluation of Retrieval Augmented Generation (2023)"
    },
    {
      "name": "Shahul Es",
      "type": "Author",
      "description": "Author of paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "Jithin James",
      "type": "Author",
      "description": "Author of paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "Luis Espinosa-Anke",
      "type": "Author",
      "description": "Author of paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "Steven Schockaert",
      "type": "Author",
      "description": "Author of paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "Exploding Gradients",
      "type": "Institution",
      "description": "Institution affiliated with paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "CardiffNLP, Cardiff University, United Kingdom",
      "type": "Institution",
      "description": "Institution affiliated with paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "AMPLYFI, United Kingdom",
      "type": "Institution",
      "description": "Institution affiliated with paper: Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "name": "text-embedding-ada-002",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: OpenAI embedding model used for computing question similarity in answer relevance evaluation"
    },
    {
      "name": "gpt-3.5-turbo-16k",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Primary model used for all evaluation prompts in the Ragas framework"
    },
    {
      "name": "ChatGPT",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for generating questions and answers in WikiEval dataset creation and baseline comparisons"
    },
    {
      "name": "WikiEval",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Novel dataset created for evaluating RAG systems with human annotations for faithfulness, answer relevance, and context relevance"
    },
    {
      "name": "retrieval system",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "LLM generation module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "context database",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Answer Relevance",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluates how directly the answer addresses the question by generating potential questions from the answer and computing similarity with original question"
    },
    {
      "name": "Context Relevance",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Assesses whether retrieved context is focused and contains minimal irrelevant information by extracting crucial sentences"
    },
    {
      "name": "GPTScore",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Baseline method that asks ChatGPT to assign scores between 0-10 for quality dimensions"
    },
    {
      "name": "BERTScore",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Uses contextualized embeddings to compare similarity between generated and reference answers"
    },
    {
      "name": "BARTScore",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Estimates factuality by examining conditional probability of generated text given input"
    },
    {
      "name": "Ragas",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Corrective Retrieval Augmented Generation",
      "type": "Paper",
      "description": "Paper: Corrective Retrieval Augmented Generation (2024)"
    },
    {
      "name": "Shi-Qi Yan",
      "type": "Author",
      "description": "Author of paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "Jia-Chen Gu",
      "type": "Author",
      "description": "Author of paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "Yun Zhu",
      "type": "Author",
      "description": "Author of paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "Zhen-Hua Ling",
      "type": "Author",
      "description": "Author of paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "University of Science and Technology of China",
      "type": "Institution",
      "description": "Institution affiliated with paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "University of California, Los Angeles",
      "type": "Institution",
      "description": "Institution affiliated with paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "Google DeepMind",
      "type": "Institution",
      "description": "Institution affiliated with paper: Corrective Retrieval Augmented Generation"
    },
    {
      "name": "LLaMA2-13B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Larger base language model for generation"
    },
    {
      "name": "SelfRAG-LLaMA2-7b",
      "type": "FinetunedModel",
      "description": "FinetunedModel: LLaMA2 fine-tuned with Self-RAG approach"
    },
    {
      "name": "T5-large",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for retrieval evaluator initialization and fine-tuning"
    },
    {
      "name": "ChatGPT",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Commercial LLM used for comparison and query rewriting"
    },
    {
      "name": "Biography",
      "type": "TestDataset",
      "description": "TestDataset: Long-form generation task for detailed biography generation"
    },
    {
      "name": "Arc-Challenge",
      "type": "TestDataset",
      "description": "TestDataset: Multiple-choice questions about commonsense science phenomena"
    },
    {
      "name": "Retrieval Evaluator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Action Trigger",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Knowledge Refinement",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Web Search",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FactScore",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Fine-grained atomic evaluation of factual precision in long-form text generation for Biography dataset"
    },
    {
      "name": "Not specified",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "type": "Paper",
      "description": "Paper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems (2023)"
    },
    {
      "name": "Jon Saad-Falcon",
      "type": "Author",
      "description": "Author of paper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "name": "Omar Khattab",
      "type": "Author",
      "description": "Author of paper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "name": "Christopher Potts",
      "type": "Author",
      "description": "Author of paper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "name": "Stanford University",
      "type": "Institution",
      "description": "Institution affiliated with paper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "name": "Databricks",
      "type": "Institution",
      "description": "Institution affiliated with paper: ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "name": "OpenAI text-embedding-ada-002",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense embedding model for similarity search over in-domain passages"
    },
    {
      "name": "ColBERTv2",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense retrieval model, found to be best performing retriever in experiments"
    },
    {
      "name": "FLAN-T5 XXL",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for generating synthetic queries and answers from corpus passages"
    },
    {
      "name": "DeBERTa-v3-Large",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned as LLM judges for evaluating context relevance, answer faithfulness, and answer relevance"
    },
    {
      "name": "GPT-3.5-turbo-16k",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used as baseline for in-context learning evaluation"
    },
    {
      "name": "MPT-7b-Instruct",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: One of the generative LLMs tested in RAG system evaluation"
    },
    {
      "name": "Wizards of Wikipedia (WoW)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Evaluates dialogue agents by mapping user dialogue to relevant Wikipedia passages"
    },
    {
      "name": "MultiRC",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Multiple choice reading comprehension over various domains"
    },
    {
      "name": "ReCoRD",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Determining placeholder entity in statements from news articles"
    },
    {
      "name": "AIS attribution dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Real attribution dataset for testing answer hallucination detection"
    },
    {
      "name": "Synthetic data generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "LLM judges",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "PPI confidence interval estimator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Answer Faithfulness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Binary classification of whether response is properly grounded in retrieved passage without hallucination"
    },
    {
      "name": "Kendall's τ",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Rank correlation coefficient measuring accuracy of pairwise comparisons between RAG systems"
    },
    {
      "name": "fact-checking",
      "type": "TaskApplication",
      "description": "Target task: fact-checking"
    },
    {
      "name": "customer support",
      "type": "TaskApplication",
      "description": "Target task: customer support"
    },
    {
      "name": "dialogue systems",
      "type": "TaskApplication",
      "description": "Target task: dialogue systems"
    },
    {
      "name": "General domain",
      "type": "DomainApplication",
      "description": "Domain application: General domain"
    },
    {
      "name": "Cross-domain evaluation tested on multiple knowledge-intensive tasks",
      "type": "DomainApplication",
      "description": "Domain application: Cross-domain evaluation tested on multiple knowledge-intensive tasks"
    },
    {
      "name": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "type": "Paper",
      "description": "Paper: The Power of Noise: Redefining Retrieval for RAG Systems (2024)"
    },
    {
      "name": "Florin Cuconasu",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Giovanni Trappolini",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Federico Siciliano",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Simone Filice",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Cesare Campagnano",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Yoelle Maarek",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Nicola Tonellotto",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Fabrizio Silvestri",
      "type": "Author",
      "description": "Author of paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Sapienza University of Rome",
      "type": "Institution",
      "description": "Institution affiliated with paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "Technology Innovation Institute",
      "type": "Institution",
      "description": "Institution affiliated with paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "University of Pisa",
      "type": "Institution",
      "description": "Institution affiliated with paper: The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "name": "ADORE",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: State-of-the-art retriever trained with dynamic hard negatives"
    },
    {
      "name": "Llama2-7B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: 7B parameters version showing state-of-the-art performance on most downstream tasks"
    },
    {
      "name": "Falcon-7B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Trained on RefinedWeb dataset with multi-query attention"
    },
    {
      "name": "Phi-2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Smallest model (2.7B parameters) achieving comparable performance thanks to textbook-quality data"
    },
    {
      "name": "MPT-7B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Uses ALiBi attention for virtually unlimited context length"
    },
    {
      "name": "NQ-open",
      "type": "TestDataset",
      "description": "TestDataset: Subset of NQ dataset removing restriction of linking answers to specific Wikipedia passages"
    },
    {
      "name": "Reddit Webis-TLDR-17",
      "type": "TestDataset",
      "description": "TestDataset: Used for testing randomness with documents from different corpus in terms of tone and style"
    },
    {
      "name": "Dense retriever (Contriever)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Generative language model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FAISS indexing system",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Top-k Accuracy",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Effectiveness measure for retrieval methods based on presence of correct answers within top-k documents"
    },
    {
      "name": "Attention Entropy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measure of attention score distribution to explain model behavior with random documents"
    },
    {
      "name": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "type": "Paper",
      "description": "Paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering (2024)"
    },
    {
      "name": "Zhentao Xu",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "Mark Jerome Cruz",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "Matthew Guevara",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "Tie Wang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "Manasi Deshpande",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "Xiaofeng Wang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "Zheng Li",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "LinkedIn Corporation",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "name": "E5",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Pre-trained text-embedding model used for generating embeddings for graph node values and in experiments"
    },
    {
      "name": "LinkedIn Customer Service Dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Curated 'golden' dataset comprising typical queries, support tickets, and their authoritative solutions from LinkedIn's customer service"
    },
    {
      "name": "Knowledge Graph Construction",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Query Entity Identification",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Intent Detection",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Embedding-based Retrieval",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Sub-graph Extraction",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Answer Generation",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "MRR",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Mean Reciprocal Rank gauges the average inverse rank of the initial correct response"
    },
    {
      "name": "NDCG@K",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Appraises the rank quality by considering both position and pertinence of items"
    },
    {
      "name": "QDrant",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "CustomerServiceRAG",
      "type": "DomainApplication",
      "description": "Domain application: CustomerServiceRAG"
    },
    {
      "name": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "type": "Paper",
      "description": "Paper: A Comprehensive Survey of Scene Graphs: Generation and Application (2021)"
    },
    {
      "name": "Xiaojun Chang",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Pengzhen Ren",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Pengfei Xu",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Zhihui Li",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Xiaojiang Chen",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Alex Hauptmann",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "University of Technology Sydney",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Northwest University",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Qilu University of Technology",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Carnegie Mellon University",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "name": "Faster-RCNN",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for object detection in scene graph generation"
    },
    {
      "name": "Mask R-CNN",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for object detection and segmentation in 3D scene graph construction"
    },
    {
      "name": "Visual Genome",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Large-scale visual dataset consisting of objects, attributes, relationships, question-answer pairs"
    },
    {
      "name": "Visual Relationship Dataset (VRD)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Dataset constructed for visual relationship prediction with long-tail distribution of relationships"
    },
    {
      "name": "Scene Graph Dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Dataset designed to improve image retrieval tasks using scene graphs"
    },
    {
      "name": "Object Detection",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Relationship Prediction",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Graph Construction",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Contextualization",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Not applicable",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Recall@K",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures the proportion of correct predictions in the top K predictions"
    },
    {
      "name": "mean Recall@K",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Averages Recall@K across all predicates to address reporting bias from high-frequency predicates"
    },
    {
      "name": "Predicate Classification",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluates prediction of relationships between given object pairs"
    },
    {
      "name": "Scene Graph Detection",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluates detection of complete scene graphs from scratch"
    },
    {
      "name": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "type": "Paper",
      "description": "Paper: Autoregressive Search Engines: Generating Substrings as Document Identifiers (2022)"
    },
    {
      "name": "Michele Bevilacqua",
      "type": "Author",
      "description": "Author of paper: Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "name": "Giuseppe Ottaviano",
      "type": "Author",
      "description": "Author of paper: Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "name": "Meta AI",
      "type": "Institution",
      "description": "Institution affiliated with paper: Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "name": "FM-Index",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Compressed full-text substring index that supports efficient identification of occurring substrings and document retrieval"
    },
    {
      "name": "BART large",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Autoregressive language model used for generating ngrams conditioned on queries"
    },
    {
      "name": "NQ320k",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Restricted setting limited to union of all ground truth documents in train/dev/test sets"
    },
    {
      "name": "KILT",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Comprehensive benchmark collecting different datasets including QA, fact checking, dialogue, slot filling, and entity linking"
    },
    {
      "name": "Autoregressive language model (BART)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FM-Index data structure",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Constrained beam search decoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Scoring function",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Accuracy@k",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Fraction of instances for which at least one of the top-k retrieved passages contains the answer"
    },
    {
      "name": "Hits@k",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Fraction of instances for which at least one of the top-k retrieved passages is in the ground truth"
    },
    {
      "name": "R-precision",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Precision at rank R where R is the number of relevant documents for the query"
    },
    {
      "name": "Exact Match",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Exact string match between predicted and ground truth answers"
    },
    {
      "name": "fairseq",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "pyserini",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Knowledge-intensive language tasks",
      "type": "DomainApplication",
      "description": "Domain application: Knowledge-intensive language tasks"
    },
    {
      "name": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "type": "Paper",
      "description": "Paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES (2022)"
    },
    {
      "name": "Zhuyun Dai",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Vincent Y. Zhao",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Ji Ma",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Yi Luan",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Jianmo Ni",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Jing Lu",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Anton Bakalov",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Kelvin Guu",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Keith B. Hall",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "Ming-Wei Chang",
      "type": "Author",
      "description": "Author of paper: PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "name": "T5-base dual encoder",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: 110M parameter dual encoder initialized from T5-base, using mean pooling and 768-dimensional embeddings"
    },
    {
      "name": "FLAN",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: 137B parameter instruction-tuned language model used for prompt-based query generation"
    },
    {
      "name": "T5-base cross-attention reranker",
      "type": "FinetunedModel",
      "description": "FinetunedModel: 110M parameter cross-attention reranker for PROMPTAGATOR++"
    },
    {
      "name": "MS MARCO",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Large-scale question answering dataset used for comparison baselines"
    },
    {
      "name": "Natural Questions",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Question answering dataset excluded from main evaluation due to FLAN overlap"
    },
    {
      "name": "LLM query generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "consistency filter",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "dual encoder retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "cross-attention reranker",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "nDCG@10",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Normalized Discounted Cumulative Gain at rank 10, standard retrieval evaluation metric on BEIR"
    },
    {
      "name": "Custom implementation based on T5 and FLAN",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Not explicitly specified",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "BEIR benchmark",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "type": "Paper",
      "description": "Paper: ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT (2020)"
    },
    {
      "name": "ColBERT",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Novel ranking model based on contextualized late interaction over BERT with separate query and document encoders"
    },
    {
      "name": "BERT-base",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Bidirectional transformer-based language model used as backbone for ColBERT encoders"
    },
    {
      "name": "BERT-large",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Larger variant of BERT used for comparison baselines"
    },
    {
      "name": "MS MARCO",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Collection of passages from Web pages gathered from Bing's results to real-world queries"
    },
    {
      "name": "TREC CAR",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Synthetic dataset based on Wikipedia with queries generated by concatenating page titles with section headings"
    },
    {
      "name": "Query encoder fQ",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Document encoder fD",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Late interaction mechanism",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "MaxSim operators",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Vector similarity index",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "ExtractiveGeneration",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "MRR@10",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Mean Reciprocal Rank at 10, measuring the average reciprocal rank of the first relevant document in top-10 results"
    },
    {
      "name": "Recall@k",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Recall at various cutoffs (k=50, 200, 1000) measuring fraction of relevant documents retrieved"
    },
    {
      "name": "MAP",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Mean Average Precision used as official metric for TREC CAR evaluation"
    },
    {
      "name": "Query Latency",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Mean query processing time in milliseconds measured on Tesla V100 GPU"
    },
    {
      "name": "FLOPs per query",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Floating point operations per query measured using torchprofile library"
    },
    {
      "name": "PyTorch",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "transformers",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "faiss",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Anserini",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "torchprofile",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Web search",
      "type": "DomainApplication",
      "description": "Domain application: Web search"
    },
    {
      "name": "Academic search",
      "type": "DomainApplication",
      "description": "Domain application: Academic search"
    },
    {
      "name": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "type": "Paper",
      "description": "Paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation (2022)"
    },
    {
      "name": "Sebastian Hofstätter",
      "type": "Author",
      "description": "Author of paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "name": "Jiecao Chen",
      "type": "Author",
      "description": "Author of paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "name": "Karthik Raman",
      "type": "Author",
      "description": "Author of paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "name": "Hamed Zamani",
      "type": "Author",
      "description": "Author of paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "name": "TU Wien (Google Internship)",
      "type": "Institution",
      "description": "Institution affiliated with paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "name": "University of Massachusetts Amherst",
      "type": "Institution",
      "description": "Institution affiliated with paper: FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "name": "GTR-Base",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense retrieval model pre-trained on MSMARCO passage retrieval task"
    },
    {
      "name": "T5-Base",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: T5 v1.1 backbone for FiD-Light"
    },
    {
      "name": "T5-Large",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: T5 v1.1 backbone for FiD-Light"
    },
    {
      "name": "T5-XL",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: T5 v1.1 backbone for FiD-Light"
    },
    {
      "name": "FiD-Light",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Efficient adaptation of FiD with compressed decoder input"
    },
    {
      "name": "T-REx",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Relation extraction dataset"
    },
    {
      "name": "zsRE",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Zero-shot relation extraction dataset"
    },
    {
      "name": "Wizard of Wikipedia",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Knowledge-grounded dialogue dataset"
    },
    {
      "name": "Dense retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "T5 encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Compressed decoder input",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "T5 decoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Source pointer re-ranking",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "KILT-EM",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: KILT Exact Match score combining text generation and retrieval precision"
    },
    {
      "name": "KILT-AC",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: KILT Accuracy score for classification tasks"
    },
    {
      "name": "KILT-F1",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: KILT F1 score for dialogue tasks"
    },
    {
      "name": "R-Precision",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Retrieval precision at R relevant documents"
    },
    {
      "name": "T5X",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Open Domain QA",
      "type": "DomainApplication",
      "description": "Domain application: Open Domain QA"
    },
    {
      "name": "Fact Verification",
      "type": "DomainApplication",
      "description": "Domain application: Fact Verification"
    },
    {
      "name": "Slot Filling",
      "type": "DomainApplication",
      "description": "Domain application: Slot Filling"
    },
    {
      "name": "Dialog Systems",
      "type": "DomainApplication",
      "description": "Domain application: Dialog Systems"
    },
    {
      "name": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "type": "Paper",
      "description": "Paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via (2023)"
    },
    {
      "name": "Boyu Zhang",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Hongyang (Bruce) Yang",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Tianyu Zhou",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Ali Babar",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Xiao-Yang Liu",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Columbia University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Brown University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "name": "Similarity-based retrieval using overlap coefficient",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Uses modified overlap coefficient (Szymkiewicz-Simpson coefficient) as similarity measure for retrieval with threshold higher than 0.8"
    },
    {
      "name": "LLaMA-7B",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Open-source LLM created by Meta, instruction-tuned for financial sentiment analysis"
    },
    {
      "name": "ChatGLM2-6B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Open-source LLM crafted by Tsinghua University, supporting both English and Chinese"
    },
    {
      "name": "ChatGPT 4.0",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Cutting-edge closed-source LLM developed by OpenAI"
    },
    {
      "name": "BloombergGPT",
      "type": "DomainSpecificModel",
      "description": "DomainSpecificModel: 50 billion parameter language model trained on wide range of financial data"
    },
    {
      "name": "Twitter Financial News dataset",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Corpus of news tweets that pertain to the financial sector, annotated with Bearish, Bullish, or Neutral labels"
    },
    {
      "name": "FiQA dataset",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Each sample annotated with positive, neutral, or negative sentiment labels"
    },
    {
      "name": "Financial PhraseBank (FPB)",
      "type": "TestDataset",
      "description": "TestDataset: Samples randomly extracted from financial news articles on Lexis-Nexis database, annotated by 16 annotators with finance and business backgrounds"
    },
    {
      "name": "Twitter Val",
      "type": "TestDataset",
      "description": "TestDataset: Validation split of Twitter dataset for financial sentiment prediction from social media"
    },
    {
      "name": "Instruction-tuned LLM module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Multi-source knowledge querying",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Similarity-based retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Context augmentation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "F1 Score",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Represents the harmonic mean of precision and recall"
    },
    {
      "name": "DeepSpeed",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "type": "Paper",
      "description": "Paper: Unsupervised Dense Information Retrieval with Contrastive Learning (2021)"
    },
    {
      "name": "Gautier Izacard",
      "type": "Author",
      "description": "Author of paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Mathilde Caron",
      "type": "Author",
      "description": "Author of paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Lucas Hosseini",
      "type": "Author",
      "description": "Author of paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Piotr Bojanowski",
      "type": "Author",
      "description": "Author of paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Armand Joulin",
      "type": "Author",
      "description": "Author of paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Edouard Grave",
      "type": "Author",
      "description": "Author of paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Meta AI Research",
      "type": "Institution",
      "description": "Institution affiliated with paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Ecole normale supérieure, PSL University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Inria",
      "type": "Institution",
      "description": "Institution affiliated with paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "Université Grenoble Alpes",
      "type": "Institution",
      "description": "Institution affiliated with paper: Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "name": "mContriever",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Multilingual version of Contriever trained on 29 languages"
    },
    {
      "name": "Natural Questions",
      "type": "TestDataset",
      "description": "TestDataset: Open domain question answering dataset"
    },
    {
      "name": "TriviaQA",
      "type": "TestDataset",
      "description": "TestDataset: Question answering dataset"
    },
    {
      "name": "Mr. TyDi",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Multilingual information retrieval benchmark"
    },
    {
      "name": "Query encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Document encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Similarity computation via dot product",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Recall@100",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Number of questions for which at least one of the top-100 passages contain the answer"
    },
    {
      "name": "MRR@100",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Mean Reciprocal Rank at 100 for multilingual evaluation"
    },
    {
      "name": "Retrieval-Augmented Multimodal Language Modeling",
      "type": "Paper",
      "description": "Paper: Retrieval-Augmented Multimodal Language Modeling (2023)"
    },
    {
      "name": "Michihiro Yasunaga",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "Armen Aghajanyan",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "Weijia Shi",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "Rich James",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "Jure Leskovec",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "Percy Liang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "Luke Zettlemoyer",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "name": "CLIP-based mixed-modal encoder",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Extension of CLIP (ViT-L/14) that encodes combinations of text and images by splitting multimodal documents into text and image parts, encoding separately, and averaging with L2 normalization"
    },
    {
      "name": "RA-CM3",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Retrieval-augmented CM3 Transformer model capable of both text and image generation with 2.7B parameters"
    },
    {
      "name": "CM3",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Causal masked multimodal model that formats multimodal documents as HTML sequences and uses VQGAN for image tokenization"
    },
    {
      "name": "LAION",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Open-sourced dataset of text-image pairs collected from the web, cleaned following Stable Diffusion preprocessing"
    },
    {
      "name": "MS-COCO",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Used for evaluation of both text-to-image and image-to-text generation tasks"
    },
    {
      "name": "Dense multimodal retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "CM3-based generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "External memory of multimodal documents",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "CIDEr",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Consensus-based Image Description Evaluation for measuring caption generation quality on MS-COCO image-to-text task"
    },
    {
      "name": "CLIP Score",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Used for re-ranking generated images and captions based on relevance to input"
    },
    {
      "name": "Metaseq",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Knowledge-intensive generation",
      "type": "DomainApplication",
      "description": "Domain application: Knowledge-intensive generation"
    },
    {
      "name": "Controlled image generation",
      "type": "DomainApplication",
      "description": "Domain application: Controlled image generation"
    },
    {
      "name": "Image editing and infilling",
      "type": "DomainApplication",
      "description": "Domain application: Image editing and infilling"
    },
    {
      "name": "Expansion via Prediction of Importance with Contextualization",
      "type": "Paper",
      "description": "Paper: Expansion via Prediction of Importance with Contextualization (2020)"
    },
    {
      "name": "Sean MacAvaney",
      "type": "Author",
      "description": "Author of paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "Franco Maria Nardini",
      "type": "Author",
      "description": "Author of paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "Raffaele Perego",
      "type": "Author",
      "description": "Author of paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "Nazli Goharian",
      "type": "Author",
      "description": "Author of paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "Ophir Frieder",
      "type": "Author",
      "description": "Author of paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "IR Lab, Georgetown University, USA",
      "type": "Institution",
      "description": "Institution affiliated with paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "ISTI-CNR, Pisa, Italy",
      "type": "Institution",
      "description": "Institution affiliated with paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "University of Pisa, Italy",
      "type": "Institution",
      "description": "Institution affiliated with paper: Expansion via Prediction of Importance with Contextualization"
    },
    {
      "name": "EPIC",
      "type": "DomainSpecificModel",
      "description": "DomainSpecificModel: Representation-based ranking model that builds query and document representations using term importance modeling and expansion"
    },
    {
      "name": "MS-MARCO passage ranking dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Full ranking setting with average query length 7.5 terms and average passage length 73.1 terms"
    },
    {
      "name": "TREC CAR passage ranking benchmark",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Used for additional evaluation with automatic judgments"
    },
    {
      "name": "First-stage retriever (BM25/docTTTTTquery)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Query representation module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Document representation module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "MRR@10",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Mean Reciprocal Rank at 10, official evaluation metric for MS-MARCO passage ranking"
    },
    {
      "name": "Query latency",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Average execution time in milliseconds per query, measured on commodity hardware"
    },
    {
      "name": "OpenNIR",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "type": "Paper",
      "description": "Paper: Atlas: Few-shot Learning with Retrieval Augmented Language Models (2022)"
    },
    {
      "name": "Maria Lomeli",
      "type": "Author",
      "description": "Author of paper: Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "name": "Timo Schick",
      "type": "Author",
      "description": "Author of paper: Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "name": "Jane Dwivedi-Yu",
      "type": "Author",
      "description": "Author of paper: Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "name": "ENS, PSL University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "name": "MMLU",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Massively multitask language understanding with 57 multiple-choice QA datasets"
    },
    {
      "name": "Contriever retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "T5 Fusion-in-Decoder language model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Vector index",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Exact Match",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Exact string match between predicted and gold answers for question answering tasks"
    },
    {
      "name": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "type": "Paper",
      "description": "Paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research (2023)"
    },
    {
      "name": "Jakub Lála",
      "type": "Author",
      "description": "Author of paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Odhran O'Donoghue",
      "type": "Author",
      "description": "Author of paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Aleksandar Shtedritski",
      "type": "Author",
      "description": "Author of paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Sam Cox",
      "type": "Author",
      "description": "Author of paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Samuel G Rodriques",
      "type": "Author",
      "description": "Author of paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Andrew D White",
      "type": "Author",
      "description": "Author of paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Future House",
      "type": "Institution",
      "description": "Institution affiliated with paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Align to Innovate",
      "type": "Institution",
      "description": "Institution affiliated with paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "Francis Crick Institute",
      "type": "Institution",
      "description": "Institution affiliated with paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "University of Oxford",
      "type": "Institution",
      "description": "Institution affiliated with paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "University of Rochester",
      "type": "Institution",
      "description": "Institution affiliated with paper: PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "name": "GPT-3.5-turbo",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used as summary LLM for evidence gathering"
    },
    {
      "name": "Claude-2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Alternative model tested for answer LLM and summary LLM"
    },
    {
      "name": "LitQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: New dataset composed from recent literature after September 2021 to test retrieval and synthesis from full-text papers"
    },
    {
      "name": "PubMedQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Yes/no/maybe questions modified to closed-book setting"
    },
    {
      "name": "MedQA-USMLE",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Multiple-choice questions based on United States Medical License Exams"
    },
    {
      "name": "BioASQ",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Biomedical QA dataset"
    },
    {
      "name": "search tool",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "gather evidence tool",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "answer question tool",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "agent LLM orchestrator",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Precision",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Correct answers among all sure answers (excluding unsure responses)"
    },
    {
      "name": "Cramer's V",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Categorical correlation measure comparing human-human and human-PaperQA response agreement"
    },
    {
      "name": "ScientificResearch",
      "type": "DomainApplication",
      "description": "Domain application: ScientificResearch"
    },
    {
      "name": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "type": "Paper",
      "description": "Paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models (2024)"
    },
    {
      "name": "S.M Towhidul Islam Tonmoy",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "S M Mehedi Zaman",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Vinija Jain",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Anku Rani",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Vipula Rawte",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Aman Chadha",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Amitava Das",
      "type": "Author",
      "description": "Author of paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Islamic University of Technology, Bangladesh",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "AI Institute, University of South Carolina, USA",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Stanford University, USA",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Amazon AI, USA",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "name": "Dense Passage Retriever (DPR)",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Neural retriever that supplies relevant documents based on the input in RAG systems"
    },
    {
      "name": "LLaMA",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used in various decoding strategies and fine-tuning approaches for hallucination mitigation"
    },
    {
      "name": "HotPotQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Used for evaluating complex reasoning and hallucination mitigation in multi-hop scenarios"
    },
    {
      "name": "TruthfulQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Benchmark specifically designed to evaluate truthfulness and factuality of language models"
    },
    {
      "name": "FreshQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Dynamic QA benchmark evaluating LLMs on questions requiring current world knowledge"
    },
    {
      "name": "Retrieval systems",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Generation models",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Feedback mechanisms",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Verification systems",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Knowledge grounding",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "F1 Score",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Harmonic mean of precision and recall for retrieval and QA evaluation"
    },
    {
      "name": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "type": "Paper",
      "description": "Paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge (2024)"
    },
    {
      "name": "Norbert Tihanyi",
      "type": "Author",
      "description": "Author of paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "Mohamed Amine Ferrag",
      "type": "Author",
      "description": "Author of paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "Ridhi Jain",
      "type": "Author",
      "description": "Author of paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "Tamas Bisztray",
      "type": "Author",
      "description": "Author of paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "Merouane Debbah",
      "type": "Author",
      "description": "Author of paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "Technology Innovation Institute (TII)",
      "type": "Institution",
      "description": "Institution affiliated with paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "University of Oslo",
      "type": "Institution",
      "description": "Institution affiliated with paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "Khalifa University",
      "type": "Institution",
      "description": "Institution affiliated with paper: CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "name": "GPT-4o",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Best performing model on CyberMetric datasets"
    },
    {
      "name": "Falcon-180B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for content review and semantic checking"
    },
    {
      "name": "T5-base",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for grammar correction during question post-processing"
    },
    {
      "name": "CyberMetric-80",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Fully validated benchmark dataset for cybersecurity knowledge evaluation"
    },
    {
      "name": "CyberMetric-500",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Fully validated benchmark dataset for cybersecurity knowledge evaluation"
    },
    {
      "name": "CyberMetric-2000",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Benchmark dataset for cybersecurity knowledge evaluation"
    },
    {
      "name": "CyberMetric-10000",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Comprehensive benchmark dataset covering 9 cybersecurity domains"
    },
    {
      "name": "Data Collection",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Question Generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Question Post-processing",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Question Validation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Reference Dataset Creation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Human vs LLM Performance",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Comparative analysis between human expert performance and LLM performance on CyberMetric-80"
    },
    {
      "name": "CybersecurityRAG",
      "type": "DomainApplication",
      "description": "Domain application: CybersecurityRAG"
    },
    {
      "name": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "type": "Paper",
      "description": "Paper: REPLUG: Retrieval-Augmented Black-Box Language Models (2023)"
    },
    {
      "name": "Sewon Min",
      "type": "Author",
      "description": "Author of paper: REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "name": "Minjoon Seo",
      "type": "Author",
      "description": "Author of paper: REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "name": "KAIST",
      "type": "Institution",
      "description": "Institution affiliated with paper: REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "name": "Codex",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Code-trained language model based on GPT-3"
    },
    {
      "name": "OPT",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Open Pre-trained Transformer language models"
    },
    {
      "name": "BLOOM",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Multilingual language model"
    },
    {
      "name": "The Pile",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Language modeling benchmark consisting of text from web pages, code, academic papers"
    },
    {
      "name": "Wikitext-103",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Wikipedia-based language modeling dataset"
    },
    {
      "name": "Document prepending",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Ensemble scoring",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Black-box LM",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Bits per byte (BPB)",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Language modeling perplexity metric on UTF-8 encoded text"
    },
    {
      "name": "Language modeling",
      "type": "TaskApplication",
      "description": "Target task: Language modeling"
    },
    {
      "name": "Multiple choice QA",
      "type": "TaskApplication",
      "description": "Target task: Multiple choice QA"
    },
    {
      "name": "Code understanding",
      "type": "DomainApplication",
      "description": "Domain application: Code understanding"
    },
    {
      "name": "Academic knowledge",
      "type": "DomainApplication",
      "description": "Domain application: Academic knowledge"
    },
    {
      "name": "Generative Transformers for Design Concept Generation",
      "type": "Paper",
      "description": "Paper: Generative Transformers for Design Concept Generation (2022)"
    },
    {
      "name": "Qihao Zhu",
      "type": "Author",
      "description": "Author of paper: Generative Transformers for Design Concept Generation"
    },
    {
      "name": "Jianxi Luo",
      "type": "Author",
      "description": "Author of paper: Generative Transformers for Design Concept Generation"
    },
    {
      "name": "Singapore University of Technology and Design",
      "type": "Institution",
      "description": "Institution affiliated with paper: Generative Transformers for Design Concept Generation"
    },
    {
      "name": "Word2Vec",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Pre-trained Word2Vec model provided by Gensim for WMD evaluation"
    },
    {
      "name": "USPTO Patent Data",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Patent titles from 1974-2020 gathered via InnoGPS system for domain knowledge synthesis"
    },
    {
      "name": "RedDot Award Dataset",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Award-winning design descriptions for problem-driven concept generation"
    },
    {
      "name": "WebText",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Pre-training dataset for GPT-2 containing diverse web content"
    },
    {
      "name": "Knowledge retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Conditional text generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Concept evaluation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Word Mover's Distance (WMD)",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures semantic distance between generated concepts and reference texts using word embeddings to assess novelty"
    },
    {
      "name": "TechNet Semantic Relevancy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Calculates minimum term-term relevancy scores within generated concepts to estimate novelty based on knowledge distance"
    },
    {
      "name": "Uniqueness Percentage",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Percentage of unique concepts generated out of total attempts to measure diversity"
    },
    {
      "name": "Custom GPT implementation",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Gensim Word2Vec",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "TechNet",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "KeyBERT",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Marginalization mechanism",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "type": "Paper",
      "description": "Paper: REALM: Retrieval-Augmented Language Model Pre-Training (2020)"
    },
    {
      "name": "Kenton Lee",
      "type": "Author",
      "description": "Author of paper: REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "name": "Zora Tung",
      "type": "Author",
      "description": "Author of paper: REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "name": "Panupong Pasupat",
      "type": "Author",
      "description": "Author of paper: REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "name": "REALM Knowledge Retriever",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense inner product model using BERT-style Transformers for embedding input queries and documents"
    },
    {
      "name": "REALM Knowledge-Augmented Encoder",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Transformer model that performs cross-attention between input and retrieved documents"
    },
    {
      "name": "Natural Questions-Open",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Naturally occurring Google queries with short answers (max 5 tokens)"
    },
    {
      "name": "CC-News",
      "type": "TrainingDataset",
      "description": "TrainingDataset: English news corpus for pre-training"
    },
    {
      "name": "Knowledge Retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Knowledge-Augmented Encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "MIPS Index",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Retrieval Recall@5",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Whether gold answer appears in top-5 retrieved documents"
    },
    {
      "name": "Retrieval Utility",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Difference between log-likelihood when conditioning on retrieved document versus null document"
    },
    {
      "name": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "type": "Paper",
      "description": "Paper: Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models (2022)"
    },
    {
      "name": "Robin Rombach",
      "type": "Author",
      "description": "Author of paper: Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "name": "Andreas Blattmann",
      "type": "Author",
      "description": "Author of paper: Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "name": "Björn Ommer",
      "type": "Author",
      "description": "Author of paper: Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "name": "Ludwig-Maximilian University Munich, Germany",
      "type": "Institution",
      "description": "Institution affiliated with paper: Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "name": "CLIP-ViT-B/32",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for ImageNet model as retrieval distance and nearest neighbor encoder"
    },
    {
      "name": "CLIP-ViT-L/14",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for LAION model as retrieval distance and nearest neighbor encoder"
    },
    {
      "name": "Latent Diffusion Model",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Conditional latent diffusion model used as the base generative model in RDM"
    },
    {
      "name": "ImageNet",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Used for training the first RDM model"
    },
    {
      "name": "LAION-2B-en",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Large-scale dataset used for training the larger LAION-RDM model"
    },
    {
      "name": "WikiArt",
      "type": "TestDataset",
      "description": "TestDataset: Used as style-specific database for zero-shot stylization"
    },
    {
      "name": "ArtBench",
      "type": "TestDataset",
      "description": "TestDataset: Used for fine-grained stylization with style-specific subsets"
    },
    {
      "name": "OpenImages",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Used to build database for ImageNet model training"
    },
    {
      "name": "conditional latent diffusion model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "external image database",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "nearest neighbor sampling strategy",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "cross attention mechanism",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Style Classification Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Style classifier trained on ArtBench with 77% top-1 accuracy on validation set, used to evaluate style transfer quality"
    },
    {
      "name": "Relative Improvement",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Comparison of retrieval-based approach vs postfix-based stylization showing superior performance"
    },
    {
      "name": "Text-to-image synthesis",
      "type": "TaskApplication",
      "description": "Target task: Text-to-image synthesis"
    },
    {
      "name": "Artistic image generation",
      "type": "TaskApplication",
      "description": "Target task: Artistic image generation"
    },
    {
      "name": "Style transfer",
      "type": "TaskApplication",
      "description": "Target task: Style transfer"
    },
    {
      "name": "AI-Art generation",
      "type": "DomainApplication",
      "description": "Domain application: AI-Art generation"
    },
    {
      "name": "Visual content creation for artists",
      "type": "DomainApplication",
      "description": "Domain application: Visual content creation for artists"
    },
    {
      "name": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "type": "Paper",
      "description": "Paper: Retrieval Augmented Generation using Engineering Design Knowledge (2023)"
    },
    {
      "name": "Siddharth L.",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "name": "Blessing L.T.M.",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "name": "Wood K.L.",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "name": "Luo J.",
      "type": "Author",
      "description": "Author of paper: Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "name": "Department of Systems Engineering, City University of Hong Kong, Hong Kong",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "name": "spaCy transformers",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for noun phrase identification and entity extraction"
    },
    {
      "name": "GPT-4 Turbo",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for generating domain-specific responses in RAG scenarios"
    },
    {
      "name": "ALBERT",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned for token classification achieving 99.7% accuracy"
    },
    {
      "name": "DistilBERT",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned for relation identification"
    },
    {
      "name": "BERT",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned for token classification"
    },
    {
      "name": "SciBERT",
      "type": "DomainSpecificModel",
      "description": "DomainSpecificModel: Scientific domain BERT model for relation extraction"
    },
    {
      "name": "BART",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned for sequence-to-sequence relation elicitation"
    },
    {
      "name": "T5",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Fine-tuned for text-to-text generation task"
    },
    {
      "name": "Engineering Design Facts Dataset",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Dataset created from 44,227 sentences from 4,205 USPTO patents"
    },
    {
      "name": "Fan Systems Knowledge Base",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Knowledge base populated from fan system patents under F04D classification"
    },
    {
      "name": "Entity identification",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Relationship extraction",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Knowledge base population",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "LLM generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Relation Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Accuracy of exact relationship extraction, achieving up to 99.7% with DistilBERT"
    },
    {
      "name": "Tagger Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Token classification accuracy for entity and relationship identification"
    },
    {
      "name": "Training Loss",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Model training loss for fine-tuned language models"
    },
    {
      "name": "Validation Loss",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Model validation loss during training process"
    },
    {
      "name": "spaCy",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Engineering Design",
      "type": "DomainApplication",
      "description": "Domain application: Engineering Design"
    },
    {
      "name": "Patent Analysis",
      "type": "DomainApplication",
      "description": "Domain application: Patent Analysis"
    },
    {
      "name": "Technical Knowledge Retrieval",
      "type": "DomainApplication",
      "description": "Domain application: Technical Knowledge Retrieval"
    },
    {
      "name": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "type": "Paper",
      "description": "Paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model (2023)"
    },
    {
      "name": "Mingyuan Zhang",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Xinying Guo",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Liang Pan",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Zhongang Cai",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Fangzhou Hong",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Huirong Li",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Lei Yang",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Ziwei Liu",
      "type": "Author",
      "description": "Author of paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "S-Lab, Nanyang Technological University, Singapore",
      "type": "Institution",
      "description": "Institution affiliated with paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Sensetime, China",
      "type": "Institution",
      "description": "Institution affiliated with paper: ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "name": "Motion Diffusion Model",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Diffusion-model-based motion generation framework built on MotionDiffuse"
    },
    {
      "name": "HumanML3D",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: A scripted 3D human motion dataset that originates from and textually reannotates the HumanAct12 and AMASS datasets"
    },
    {
      "name": "KIT-ML",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: KIT Motion Language Dataset is an open dataset combining human motion and natural language"
    },
    {
      "name": "Hybrid Retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Semantics-Modulated Transformer",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Condition Mixture",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "R Precision",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures the similarity between the text description and the generated motion sequence, indicates the probability that the real text appears in the top k after sorting"
    },
    {
      "name": "MM Dist",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Multi-modal distance represents the average Euclidean distance between the motion feature and its corresponding text description feature"
    },
    {
      "name": "Diversity",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Measures the variability and richness of the generated action sequences"
    },
    {
      "name": "Multimodality",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Measures the average variance of generated motion sequences given a single text description"
    },
    {
      "name": "motion generation",
      "type": "TaskApplication",
      "description": "Target task: motion generation"
    },
    {
      "name": "text-driven synthesis",
      "type": "TaskApplication",
      "description": "Target task: text-driven synthesis"
    },
    {
      "name": "creative industry",
      "type": "DomainApplication",
      "description": "Domain application: creative industry"
    },
    {
      "name": "game production",
      "type": "DomainApplication",
      "description": "Domain application: game production"
    },
    {
      "name": "film",
      "type": "DomainApplication",
      "description": "Domain application: film"
    },
    {
      "name": "virtual reality",
      "type": "DomainApplication",
      "description": "Domain application: virtual reality"
    },
    {
      "name": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "type": "Paper",
      "description": "Paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog (2021)"
    },
    {
      "name": "David Thulke",
      "type": "Author",
      "description": "Author of paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "name": "Nico Daheim",
      "type": "Author",
      "description": "Author of paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "name": "Christian Dugast",
      "type": "Author",
      "description": "Author of paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "name": "Hermann Ney",
      "type": "Author",
      "description": "Author of paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "name": "Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany",
      "type": "Institution",
      "description": "Institution affiliated with paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "name": "AppTek GmbH, Aachen, Germany",
      "type": "Institution",
      "description": "Institution affiliated with paper: Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "name": "RoBERTa",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used as pre-trained language model for encoders in embedding models"
    },
    {
      "name": "Siamese Embedding Networks",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dialog context encoder and knowledge snippet encoder for dense retrieval"
    },
    {
      "name": "MultiWOZ 2.1",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Extended with user turns requesting information not covered by database, corresponding system responses, and knowledge snippets from FAQ websites"
    },
    {
      "name": "DSTC 9 Track 1",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Beyond Domain APIs: Task-oriented Conversational Modeling with Unstructured Knowledge Access"
    },
    {
      "name": "Turn Detection",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Knowledge Selection",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Response Generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Recall@1",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Top-1 retrieval accuracy for knowledge selection"
    },
    {
      "name": "Recall@5",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Top-5 retrieval accuracy for knowledge selection"
    },
    {
      "name": "MRR@5",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Mean Reciprocal Rank at 5 for knowledge selection"
    },
    {
      "name": "Huggingface Transformers",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Sisyphus workflow manager",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "task-oriented dialog systems",
      "type": "DomainApplication",
      "description": "Domain application: task-oriented dialog systems"
    },
    {
      "name": "restaurant booking",
      "type": "DomainApplication",
      "description": "Domain application: restaurant booking"
    },
    {
      "name": "hotel reservation",
      "type": "DomainApplication",
      "description": "Domain application: hotel reservation"
    },
    {
      "name": "taxi booking",
      "type": "DomainApplication",
      "description": "Domain application: taxi booking"
    },
    {
      "name": "train booking",
      "type": "DomainApplication",
      "description": "Domain application: train booking"
    },
    {
      "name": "attraction information",
      "type": "DomainApplication",
      "description": "Domain application: attraction information"
    },
    {
      "name": "Improving language models by retrieving from trillions of tokens",
      "type": "Paper",
      "description": "Paper: Improving language models by retrieving from trillions of tokens (2021)"
    },
    {
      "name": "Sebastian Borgeaud",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Arthur Mensch",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Jordan Hoffmann",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Trevor Cai",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Eliza Rutherford",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Katie Millican",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "George van den Driessche",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Jean-Baptiste Lespiau",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Bogdan Damoc",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Aidan Clark",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Diego de Las Casas",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Aurelia Guy",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Jacob Menick",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Roman Ring",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Tom Hennigan",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Saffron Huang",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Loren Maggiore",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Chris Jones",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Albin Cassirer",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Andy Brock",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Michela Paganini",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Geoffrey Irving",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Oriol Vinyals",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Simon Osindero",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Karen Simonyan",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Jack W. Rae",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Erich Elsen",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Laurent Sifre",
      "type": "Author",
      "description": "Author of paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "DeepMind",
      "type": "Institution",
      "description": "Institution affiliated with paper: Improving language models by retrieving from trillions of tokens"
    },
    {
      "name": "Retro",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Retrieval-Enhanced Transformer with encoder-decoder architecture and chunked cross-attention"
    },
    {
      "name": "Baseline Transformer",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Standard transformer architecture similar to GPT with RMSNorm and relative position encodings"
    },
    {
      "name": "MassiveText",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Multi-lingual dataset from web, books, news, Wikipedia, and GitHub"
    },
    {
      "name": "C4",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Common Crawl based dataset for evaluation"
    },
    {
      "name": "Wikitext103",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Wikipedia-based language modeling benchmark"
    },
    {
      "name": "The Pile",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Diverse text dataset for language modeling evaluation"
    },
    {
      "name": "Retrieval encoder",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Main decoder pathway",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Chunked cross-attention layers",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Standard transformer blocks",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Bits-per-byte",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Tokenizer-agnostic measure of language modeling performance"
    },
    {
      "name": "Exact Match Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Exact match accuracy for question answering tasks"
    },
    {
      "name": "LAMBADA Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Last word prediction accuracy requiring broad discourse context"
    },
    {
      "name": "Haiku",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "SCaNN",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "type": "Paper",
      "description": "Paper: Retrieval-Augmented Generation for Large Language Models: A Survey (2023)"
    },
    {
      "name": "Yunfan Gao",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Yun Xiong",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Xinyu Gao",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Kangxiang Jia",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Jinliu Pan",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Yuxi Bi",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Yi Dai",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Jiawei Sun",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Meng Wang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Haofen Wang",
      "type": "Author",
      "description": "Author of paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "College of Design and Innovation, Tongji University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "name": "Indexing module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Generation module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Vector database",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Embedding model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Hit Rate",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Measures whether relevant documents are retrieved in top-k results"
    },
    {
      "name": "NDCG",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Normalized Discounted Cumulative Gain for ranking evaluation"
    },
    {
      "name": "HayStack",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Qdrant",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "ARES",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "RALLE",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Information Extraction",
      "type": "TaskApplication",
      "description": "Target task: Information Extraction"
    },
    {
      "name": "Fact Checking",
      "type": "TaskApplication",
      "description": "Target task: Fact Checking"
    },
    {
      "name": "Code Search",
      "type": "TaskApplication",
      "description": "Target task: Code Search"
    },
    {
      "name": "Scientific Research",
      "type": "DomainApplication",
      "description": "Domain application: Scientific Research"
    },
    {
      "name": "Enterprise Search",
      "type": "DomainApplication",
      "description": "Domain application: Enterprise Search"
    },
    {
      "name": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "type": "Paper",
      "description": "Paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions (2024)"
    },
    {
      "name": "Guangzhi Xiong",
      "type": "Author",
      "description": "Author of paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Qiao Jin",
      "type": "Author",
      "description": "Author of paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Xiao Wang",
      "type": "Author",
      "description": "Author of paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Minjia Zhang",
      "type": "Author",
      "description": "Author of paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Zhiyong Lu",
      "type": "Author",
      "description": "Author of paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Aidong Zhang",
      "type": "Author",
      "description": "Author of paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Department of Computer Science, University of Virginia",
      "type": "Institution",
      "description": "Institution affiliated with paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "National Library of Medicine, National Institutes of Health",
      "type": "Institution",
      "description": "Institution affiliated with paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "type": "Institution",
      "description": "Institution affiliated with paper: Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "name": "MedCPT",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Text retriever that has been trained on domain-specific literature for medical document retrieval"
    },
    {
      "name": "GPT-3.5-Turbo",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Large language model used for iterative query generation and answer prediction in medical question answering"
    },
    {
      "name": "Llama-3.1-8B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Open-source large language model used to demonstrate generalizability of i-MedRAG approach"
    },
    {
      "name": "MedQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Medical questions collected from United States Medical Licensing Examination (USMLE) with complex clinical cases"
    },
    {
      "name": "MMLU-Med",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Medical questions from Massive Multitask Language Understanding dataset including anatomy, clinical knowledge, college biology, college medicine, medical genetics, professional medicine"
    },
    {
      "name": "IterativeRAG",
      "type": "IterativeRAG",
      "description": "IterativeRAG: i-MedRAG modifies the conventional RAG pipeline by replacing the information retrieval step with iterative question-answering step where LLMs iteratively generate follow-up queries based on previous information-seeking attempts"
    },
    {
      "name": "Query generation module",
      "type": "Method",
      "description": "Component in IterativeRAG"
    },
    {
      "name": "RAG system for answering queries",
      "type": "Method",
      "description": "Component in IterativeRAG"
    },
    {
      "name": "Information-seeking history tracking",
      "type": "Method",
      "description": "Component in IterativeRAG"
    },
    {
      "name": "Final answer generation",
      "type": "Method",
      "description": "Component in IterativeRAG"
    },
    {
      "name": "Medical Question Answering",
      "type": "TaskApplication",
      "description": "Target task: Medical Question Answering"
    },
    {
      "name": "Clinical decision support",
      "type": "DomainApplication",
      "description": "Domain application: Clinical decision support"
    },
    {
      "name": "Medical licensing examination preparation",
      "type": "DomainApplication",
      "description": "Domain application: Medical licensing examination preparation"
    },
    {
      "name": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "type": "Paper",
      "description": "Paper: Benchmarking Large Language Models in Retrieval-Augmented Generation (2023)"
    },
    {
      "name": "Jiawei Chen",
      "type": "Author",
      "description": "Author of paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "Hongyu Lin",
      "type": "Author",
      "description": "Author of paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "Xianpei Han",
      "type": "Author",
      "description": "Author of paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "Le Sun",
      "type": "Author",
      "description": "Author of paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "Chinese Information Processing Laboratory",
      "type": "Institution",
      "description": "Institution affiliated with paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences",
      "type": "Institution",
      "description": "Institution affiliated with paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "University of Chinese Academy of Sciences",
      "type": "Institution",
      "description": "Institution affiliated with paper: Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "name": "m3e-base",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Chinese dense retrieval model used for re-ranking text chunks"
    },
    {
      "name": "ChatGLM-6B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: 6B parameter Chinese-English bilingual language model"
    },
    {
      "name": "Vicuna-7B-v1.3",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: 7B parameter instruction-tuned model"
    },
    {
      "name": "Qwen-7B-Chat",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: 7B parameter chat-optimized model"
    },
    {
      "name": "BELLE-7B-2M",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: 7B parameter model trained on 2M instruction data"
    },
    {
      "name": "RGB (Retrieval-Augmented Generation Benchmark)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: New corpus for RAG evaluation in both English and Chinese, constructed from latest news articles"
    },
    {
      "name": "Search engine retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Dense retrieval re-ranking",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Rejection Rate",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures negative rejection ability when only noisy documents provided, expects specific rejection content"
    },
    {
      "name": "Error Detection Rate",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures whether model can detect factual errors in documents for counterfactual robustness"
    },
    {
      "name": "Error Correction Rate",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures whether model can provide correct answer after identifying errors for counterfactual robustness"
    },
    {
      "name": "Pre-training via Paraphrasing",
      "type": "Paper",
      "description": "Paper: Pre-training via Paraphrasing (2020)"
    },
    {
      "name": "Marjan Ghazvininejad",
      "type": "Author",
      "description": "Author of paper: Pre-training via Paraphrasing"
    },
    {
      "name": "Gargi Ghosh",
      "type": "Author",
      "description": "Author of paper: Pre-training via Paraphrasing"
    },
    {
      "name": "Sida Wang",
      "type": "Author",
      "description": "Author of paper: Pre-training via Paraphrasing"
    },
    {
      "name": "Facebook AI",
      "type": "Institution",
      "description": "Institution affiliated with paper: Pre-training via Paraphrasing"
    },
    {
      "name": "Document encoder g",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: 4-layer Transformer that maps documents to fixed size representations for computing relevance scores"
    },
    {
      "name": "MARGE",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Multi-source sequence-to-sequence model with 12-layer encoder and 16-layer decoder"
    },
    {
      "name": "CC-NEWS",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Multilingual news corpus used for initial pre-training"
    },
    {
      "name": "BUCC2018",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Cross-lingual sentence retrieval benchmark"
    },
    {
      "name": "Tatoeba",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Cross-lingual sentence retrieval benchmark"
    },
    {
      "name": "Document encoder for relevance scoring",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Multi-source sequence-to-sequence reconstruction model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Cross-attention mechanism with relevance score biasing",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Transformer architecture",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "FastText for language identification",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Cross-lingual transfer",
      "type": "DomainApplication",
      "description": "Domain application: Cross-lingual transfer"
    },
    {
      "name": "Document-level machine translation",
      "type": "DomainApplication",
      "description": "Domain application: Document-level machine translation"
    },
    {
      "name": "Zero-shot learning",
      "type": "DomainApplication",
      "description": "Domain application: Zero-shot learning"
    },
    {
      "name": "A Survey on Retrieval-Augmented Text Generation",
      "type": "Paper",
      "description": "Paper: A Survey on Retrieval-Augmented Text Generation (2022)"
    },
    {
      "name": "Huayang Li",
      "type": "Author",
      "description": "Author of paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "Yixuan Su",
      "type": "Author",
      "description": "Author of paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "Deng Cai",
      "type": "Author",
      "description": "Author of paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "Yan Wang",
      "type": "Author",
      "description": "Author of paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "Lemao Liu",
      "type": "Author",
      "description": "Author of paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "Nara Institute of Science and Technology",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "University of Cambridge",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "The Chinese University of Hong Kong",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "Tencent AI Lab",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "name": "BERT-based encoders",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Pre-trained language models used for encoding text to low-dimensional dense vectors"
    },
    {
      "name": "SEQ2SEQ encoder-decoder",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Standard sequence-to-sequence model extended with extra encoder for encoding retrieval results"
    },
    {
      "name": "Transformer",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Transformer-based models used as backbone for NMT with additional encoders for retrieved target sentences"
    },
    {
      "name": "RNN-based models",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: RNN-based framework using gating and attention mechanism to incorporate retrieved target sentences"
    },
    {
      "name": "Training Corpus",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Original training datasets used as retrieval sources for external memory"
    },
    {
      "name": "External Datasets",
      "type": "TrainingDataset",
      "description": "TrainingDataset: External datasets in same format as training corpus for domain adaptation and knowledge update"
    },
    {
      "name": "Unsupervised Corpus",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Large-scale unsupervised corpus without aligned input-output pairs"
    },
    {
      "name": "retrieval sources",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "retrieval metrics",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "generation models",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "integration methods",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Translation Quality",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Standard machine translation evaluation metric"
    },
    {
      "name": "Response Quality",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Evaluation of dialogue response generation quality and informativeness"
    },
    {
      "name": "Retrieval Accuracy",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Accuracy of retrieved examples in improving generation quality"
    },
    {
      "name": "dialogue response generation",
      "type": "DomainApplication",
      "description": "Domain application: dialogue response generation"
    },
    {
      "name": "machine translation",
      "type": "DomainApplication",
      "description": "Domain application: machine translation"
    },
    {
      "name": "language modeling",
      "type": "DomainApplication",
      "description": "Domain application: language modeling"
    },
    {
      "name": "paraphrase generation",
      "type": "DomainApplication",
      "description": "Domain application: paraphrase generation"
    },
    {
      "name": "text style transfer",
      "type": "DomainApplication",
      "description": "Domain application: text style transfer"
    },
    {
      "name": "data-to-text generation",
      "type": "DomainApplication",
      "description": "Domain application: data-to-text generation"
    },
    {
      "name": "code generation",
      "type": "DomainApplication",
      "description": "Domain application: code generation"
    },
    {
      "name": "abstractive summarization",
      "type": "DomainApplication",
      "description": "Domain application: abstractive summarization"
    },
    {
      "name": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "type": "Paper",
      "description": "Paper: Evaluating Retrieval Quality in Retrieval-Augmented Generation (2024)"
    },
    {
      "name": "Alireza Salemi",
      "type": "Author",
      "description": "Author of paper: Evaluating Retrieval Quality in Retrieval-Augmented Generation"
    },
    {
      "name": "T5-small",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: T5-small with Fusion-in-Decoder (FiD) used as the main LLM in RAG system"
    },
    {
      "name": "Mistral-7B",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Mistral-7B-Instruct used for document relevance annotation as baseline"
    },
    {
      "name": "Retrieval Model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Large Language Model",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Evaluation Module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Exact Match (EM)",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Used for NQ, TriviaQA, and HotpotQA datasets to measure exact string matching"
    },
    {
      "name": "Accuracy",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Used for FEVER dataset for fact verification classification"
    },
    {
      "name": "Kendall's tau",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Correlation metric to measure relationship between retrieval evaluation and downstream performance"
    },
    {
      "name": "Spearman's rho",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Correlation metric to measure relationship between retrieval evaluation and downstream performance"
    },
    {
      "name": "Pyserini",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Faiss",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Knowledge-grounded dialogue",
      "type": "DomainApplication",
      "description": "Domain application: Knowledge-grounded dialogue"
    },
    {
      "name": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "type": "Paper",
      "description": "Paper: Large Language Models Struggle to Learn Long-Tail Knowledge (2023)"
    },
    {
      "name": "Nikhil Kandpal",
      "type": "Author",
      "description": "Author of paper: Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "name": "Haikang Deng",
      "type": "Author",
      "description": "Author of paper: Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "name": "Adam Roberts",
      "type": "Author",
      "description": "Author of paper: Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "name": "Eric Wallace",
      "type": "Author",
      "description": "Author of paper: Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "name": "Colin Raffel",
      "type": "Author",
      "description": "Author of paper: Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "name": "UNC Chapel Hill",
      "type": "Institution",
      "description": "Institution affiliated with paper: Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "name": "DBpedia Spotlight Entity Linker",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Traditional entity linking method to link entities to DBpedia or Wikidata IDs"
    },
    {
      "name": "GPT-Neo",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: GPT-Neo, GPT-NeoX, and GPT-J models trained by EleutherAI on The Pile"
    },
    {
      "name": "Entity linking pipeline",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Document counting system",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "BM25 retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Language model generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "SparseRetrieval",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Top-k Recall",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Recall metric for BM25 retriever evaluation on Wikipedia knowledge corpus"
    },
    {
      "name": "Spearman Rank Correlation",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Correlation measure between relevant document counts across different pre-training datasets"
    },
    {
      "name": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "type": "Paper",
      "description": "Paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation (2024)"
    },
    {
      "name": "Hessa A. Alawwad",
      "type": "Author",
      "description": "Author of paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "Areej Alhothali",
      "type": "Author",
      "description": "Author of paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "Usman Naseem",
      "type": "Author",
      "description": "Author of paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "Ali Alkhathlan",
      "type": "Author",
      "description": "Author of paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "Amani Jamal",
      "type": "Author",
      "description": "Author of paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
      "type": "Institution",
      "description": "Institution affiliated with paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia",
      "type": "Institution",
      "description": "Institution affiliated with paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "School of Computing, Macquarie University, Australia",
      "type": "Institution",
      "description": "Institution affiliated with paper: Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "name": "Llama-2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Large language model trained on 2 trillion tokens and scaled to 70 billion parameters, fine-tuned for TQA task"
    },
    {
      "name": "CK12-QA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: TQA dataset covering life science, earth science, and physical science with multiple-choice and true/false questions"
    },
    {
      "name": "Vector embedding",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Re-ranker",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Fine-tuned LLM",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "FinetunedModel",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "SFTTrainer",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "type": "Paper",
      "description": "Paper: MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities (2023)"
    },
    {
      "name": "Markus J. Buehler",
      "type": "Author",
      "description": "Author of paper: MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities"
    },
    {
      "name": "Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology",
      "type": "Institution",
      "description": "Institution affiliated with paper: MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities"
    },
    {
      "name": "Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology",
      "type": "Institution",
      "description": "Institution affiliated with paper: MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities"
    },
    {
      "name": "Google Scholar search",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for literature retrieval and knowledge augmentation"
    },
    {
      "name": "MechGPT-13B",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Base model fine-tuned from OpenOrca-Platypus2-13B for mechanics and materials failure"
    },
    {
      "name": "MechGPT-70B",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Larger fine-tuned version based on Meta/Llama 2 70 chat model"
    },
    {
      "name": "MechGPT-70B-XL",
      "type": "FinetunedModel",
      "description": "FinetunedModel: Extended context version using dynamically scaled RoPE for large context lengths"
    },
    {
      "name": "Atomistic Modeling of Materials Failure textbook",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Primary source for domain-specific knowledge extraction and question-answer pair generation"
    },
    {
      "name": "Question-Answer pairs",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Generated from textbook using LLM distillation process for fine-tuning"
    },
    {
      "name": "Knowledge graph generator",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Multi-agent framework",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Knowledge Retrieval Accuracy",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Assessed through multiple-choice questions and domain-specific queries about mechanics and materials failure"
    },
    {
      "name": "Few-shot Learning Performance",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluated on predicting material properties like grain size-dependent flow stress and CNT modulus"
    },
    {
      "name": "Cross-domain Connection Quality",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Assessed through analogical reasoning tasks connecting mechanics with biology, music, and art"
    },
    {
      "name": "Knowledge Graph Coherence",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluated through interpretability and usefulness of generated Ontological Knowledge Graphs"
    },
    {
      "name": "Hugging Face ecosystem",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Guidance package for multi-agent modeling",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Llama Index",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Nebula Graph",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Gradio for chat interface",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "NetworkX for graph analysis",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Knowledge retrieval",
      "type": "TaskApplication",
      "description": "Target task: Knowledge retrieval"
    },
    {
      "name": "Hypothesis generation",
      "type": "TaskApplication",
      "description": "Target task: Hypothesis generation"
    },
    {
      "name": "Cross-domain reasoning",
      "type": "TaskApplication",
      "description": "Target task: Cross-domain reasoning"
    },
    {
      "name": "Research development",
      "type": "TaskApplication",
      "description": "Target task: Research development"
    },
    {
      "name": "MechanicsRAG",
      "type": "DomainApplication",
      "description": "Domain application: MechanicsRAG"
    },
    {
      "name": "Materials science research",
      "type": "DomainApplication",
      "description": "Domain application: Materials science research"
    },
    {
      "name": "Scientific literature analysis",
      "type": "DomainApplication",
      "description": "Domain application: Scientific literature analysis"
    },
    {
      "name": "Educational applications",
      "type": "DomainApplication",
      "description": "Domain application: Educational applications"
    },
    {
      "name": "Creative problem solving",
      "type": "DomainApplication",
      "description": "Domain application: Creative problem solving"
    },
    {
      "name": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "type": "Paper",
      "description": "Paper: Pretrained Transformers for Text Ranking: BERT and Beyond (2021)"
    },
    {
      "name": "Jimmy Lin",
      "type": "Author",
      "description": "Author of paper: Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "name": "Rodrigo Nogueira",
      "type": "Author",
      "description": "Author of paper: Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "name": "Andrew Yates",
      "type": "Author",
      "description": "Author of paper: Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "name": "David R. Cheriton School of Computer Science, University of Waterloo",
      "type": "Institution",
      "description": "Institution affiliated with paper: Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "name": "University of Amsterdam",
      "type": "Institution",
      "description": "Institution affiliated with paper: Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "name": "Max Planck Institute for Informatics",
      "type": "Institution",
      "description": "Institution affiliated with paper: Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "name": "ELECTRA",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: BERT variant that replaces masked language model pretraining task with replaced token detection task"
    },
    {
      "name": "Robust04",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: TREC 2004 Robust Track test collection, widely considered one of the best general purpose ad hoc retrieval test collections"
    },
    {
      "name": "TREC Deep Learning Track",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: TREC 2019/2020 Deep Learning Track providing richer test sets with graded relevance judgments"
    },
    {
      "name": "candidate generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "reranking stages",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "score aggregation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "representation learning",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "nDCG@20",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Normalized Discounted Cumulative Gain at cutoff 20, commonly used for web search evaluation"
    },
    {
      "name": "Recall@1k",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Recall at cutoff 1000, measures upper bound effectiveness of retrieve-and-rerank strategy"
    },
    {
      "name": "Transformers library by Hugging Face",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "TensorFlow",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "HNSW",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "trec_eval",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Pyserini",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "ad hoc retrieval",
      "type": "TaskApplication",
      "description": "Target task: ad hoc retrieval"
    },
    {
      "name": "passage retrieval",
      "type": "TaskApplication",
      "description": "Target task: passage retrieval"
    },
    {
      "name": "document ranking",
      "type": "TaskApplication",
      "description": "Target task: document ranking"
    },
    {
      "name": "web search",
      "type": "DomainApplication",
      "description": "Domain application: web search"
    },
    {
      "name": "scientific literature retrieval",
      "type": "DomainApplication",
      "description": "Domain application: scientific literature retrieval"
    },
    {
      "name": "biomedical search",
      "type": "DomainApplication",
      "description": "Domain application: biomedical search"
    },
    {
      "name": "legal document retrieval",
      "type": "DomainApplication",
      "description": "Domain application: legal document retrieval"
    },
    {
      "name": "news article ranking",
      "type": "DomainApplication",
      "description": "Domain application: news article ranking"
    },
    {
      "name": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "type": "Paper",
      "description": "Paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE (2024)"
    },
    {
      "name": "Angels Balaguer",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Vinamra Benara",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Renato Cunha",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Roberto Estevão",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Todd Hendry",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Daniel Holstein",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Jennifer Marsman",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Nick Mecklenburg",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Sara Malvar",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Leonardo O. Nunes",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Rafael Padilha",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Morris Sharp",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Bruno Silva",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Swati Sharma",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Vijay Aski",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Ranveer Chandra",
      "type": "Author",
      "description": "Author of paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "Microsoft",
      "type": "Institution",
      "description": "Institution affiliated with paper: RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "name": "sentence transformers",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for computing embeddings from text chunks extracted from PDF documents"
    },
    {
      "name": "Llama2-13B",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used for fine-tuning and RAG experiments"
    },
    {
      "name": "Llama2-13B-chat",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Instruction-tuned version used for answer generation and evaluation"
    },
    {
      "name": "Vicuna-13B-v1.5-16k",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Instruction-tuned on ShareGPT dataset, used for comparison"
    },
    {
      "name": "USA Agriculture Dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Documents from USDA, state agriculture agencies, and Land-Grant Institutions"
    },
    {
      "name": "Washington State Dataset",
      "type": "TestDataset",
      "description": "TestDataset: Used for benchmarking and evaluation"
    },
    {
      "name": "Brazil Embrapa Dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Questions and answers from Embrapa specialists on crop cultivation"
    },
    {
      "name": "India KVK Dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Farmer advisory data from Krishi Vigyan Kendra portal"
    },
    {
      "name": "Data acquisition",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "PDF information extraction",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Question generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Answer generation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Fine-tuning",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Evaluation",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Coverage",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures if answers can be extracted from provided context, rated 1-5 by LLMs"
    },
    {
      "name": "Fluency",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Assesses fluency and coherence using GPT-4 rating 1-5"
    },
    {
      "name": "Diversity",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Uses Word Mover's Distance to measure semantic variety among generated questions"
    },
    {
      "name": "Coherence",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: Compares coherence between ground truth and predictions, scored 1-5"
    },
    {
      "name": "Groundedness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measures whether answers follow logically from context information"
    },
    {
      "name": "Succinctness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluates conciseness vs verbosity of generated answers, scored 1-5"
    },
    {
      "name": "Guidance",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "AzureML Model Evaluation",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "type": "Paper",
      "description": "Paper: Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers (2024)"
    },
    {
      "name": "Kunal Sawarkar",
      "type": "Author",
      "description": "Author of paper: Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "name": "Abhilasha Mangal",
      "type": "Author",
      "description": "Author of paper: Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "name": "Shivam Raj Solanki",
      "type": "Author",
      "description": "Author of paper: Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "name": "IBM",
      "type": "Institution",
      "description": "Institution affiliated with paper: Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "name": "Sentence Transformers",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense vector model used to construct dense vector index that identifies proximity of vector representations derived from document and query content"
    },
    {
      "name": "Elastic Learned Sparse Encoder (ELSER)",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Sparse encoder-based semantic search model that amalgamates semantic understanding and similarity-based retrieval to capture nuanced relationships between terms"
    },
    {
      "name": "Large Language Models (LLM)",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Used as the Generator (G) component in the RAG system for answer generation"
    },
    {
      "name": "TREC-COVID",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Dataset encompassing relevancy with Score-1 and 2 denoting high relevance"
    },
    {
      "name": "Stanford Question Answering Dataset (SQuAD)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Commonly bench-marked dataset for RAG systems or Generative Q&A using LLMs"
    },
    {
      "name": "CoQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Conversational question answering dataset lacking metadata"
    },
    {
      "name": "Blended Retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Generator (LLM)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Hybrid Query Engine",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Multiple Index Types",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Top-k Retrieval Accuracy",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Measures retrieval accuracy using top-k metrics where k ∈ {5,10,20}"
    },
    {
      "name": "NDCG@10",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Normalised Discounted Cumulative Gain metric used for retriever benchmarking"
    },
    {
      "name": "Elastic Search platform",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Enterprise datasets",
      "type": "DomainApplication",
      "description": "Domain application: Enterprise datasets"
    },
    {
      "name": "Large-scale information retrieval",
      "type": "DomainApplication",
      "description": "Domain application: Large-scale information retrieval"
    },
    {
      "name": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "type": "Paper",
      "description": "Paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models (2024)"
    },
    {
      "name": "Wenqi Fan",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Yujuan Ding",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Liangbo Ning",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Shijie Wang",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Hengyun Li",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Dawei Yin",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Tat-Seng Chua",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Qing Li",
      "type": "Author",
      "description": "Author of paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "The Hong Kong Polytechnic University",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "Baidu Inc",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "National University of Singapore",
      "type": "Institution",
      "description": "Institution affiliated with paper: A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "name": "retriever",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "generator",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "augmentation module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "pre-retrieval enhancement",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "post-retrieval enhancement",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Code Generation",
      "type": "TaskApplication",
      "description": "Target task: Code Generation"
    },
    {
      "name": "Machine Translation",
      "type": "TaskApplication",
      "description": "Target task: Machine Translation"
    },
    {
      "name": "Financial Analysis",
      "type": "DomainApplication",
      "description": "Domain application: Financial Analysis"
    },
    {
      "name": "Scientific Literature Review",
      "type": "DomainApplication",
      "description": "Domain application: Scientific Literature Review"
    },
    {
      "name": "Molecular Discovery",
      "type": "DomainApplication",
      "description": "Domain application: Molecular Discovery"
    },
    {
      "name": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "type": "Paper",
      "description": "Paper: Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge (2024)"
    },
    {
      "name": "Heydar Soudani",
      "type": "Author",
      "description": "Author of paper: Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "name": "Evangelos Kanoulas",
      "type": "Author",
      "description": "Author of paper: Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "name": "Faegheh Hasibi",
      "type": "Author",
      "description": "Author of paper: Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "name": "Radboud University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "name": "FlanT5",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Encoder-decoder models ranging from small to XXL versions"
    },
    {
      "name": "TinyLlama",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Small decoder-only language model"
    },
    {
      "name": "StableLM2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Decoder-only language model"
    },
    {
      "name": "MiniCPM",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Small decoder-only language model"
    },
    {
      "name": "Mistral",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Large decoder-only language model"
    },
    {
      "name": "Zephyr",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Instruction-tuned model used for QA generation with Chain of Thought prompting"
    },
    {
      "name": "Llama2-chat",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Chat-optimized version of Llama2"
    },
    {
      "name": "Llama3-chat",
      "type": "InstructionTunedModel",
      "description": "InstructionTunedModel: Chat-optimized version of Llama3"
    },
    {
      "name": "PopQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Open-domain QA dataset about long-tail entities, constructed from 16 diverse relationship types in Wikidata"
    },
    {
      "name": "WitQA",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Entity-centric dataset that defines popularity based on co-occurrence of subject entity and relation predicate"
    },
    {
      "name": "EntityQuestion (EQ)",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Popular open-domain QA dataset covering long-tail entity distribution using Wikipedia hyperlink counts"
    },
    {
      "name": "Hint Extractor",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Less-resourced domains",
      "type": "DomainApplication",
      "description": "Domain application: Less-resourced domains"
    },
    {
      "name": "Industrial chatbots",
      "type": "DomainApplication",
      "description": "Domain application: Industrial chatbots"
    },
    {
      "name": "Company-specific knowledge systems",
      "type": "DomainApplication",
      "description": "Domain application: Company-specific knowledge systems"
    },
    {
      "name": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "type": "Paper",
      "description": "Paper: Semantic-Conditional Diffusion Networks for Image Captioning (2022)"
    },
    {
      "name": "Jianjie Luo",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Yehao Li",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Yingwei Pan",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Ting Yao",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Jianlin Feng",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Hongyang Chao",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Tao Mei",
      "type": "Author",
      "description": "Author of paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Sun Yat-sen University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "JD Explore Academy",
      "type": "Institution",
      "description": "Institution affiliated with paper: Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "name": "Cross-modal retrieval model",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Off-the-shelf cross-modal retrieval model used to search semantically relevant sentences for semantic prior extraction"
    },
    {
      "name": "Diffusion Transformer",
      "type": "DomainSpecificModel",
      "description": "DomainSpecificModel: Novel transformer architecture designed for diffusion-based image captioning with semantic conditioning"
    },
    {
      "name": "Autoregressive Transformer teacher model",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Standard autoregressive Transformer model used as teacher for guided self-critical sequence training"
    },
    {
      "name": "Karpathy split",
      "type": "TestDataset",
      "description": "TestDataset: Widely adopted split of COCO dataset for image captioning evaluation"
    },
    {
      "name": "Visual Encoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Semantic Transformer",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Sentence Decoder",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Cross-modal Retrieval Module",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "BLEU@N",
      "type": "GenerationMetrics",
      "description": "GenerationMetrics: N-gram precision based evaluation metric for text generation quality"
    },
    {
      "name": "CIDEr",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Consensus-based image description evaluation metric"
    },
    {
      "name": "SPICE",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Semantic propositional image caption evaluation metric"
    },
    {
      "name": "X-modaler",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "COCO Evaluation Server",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Image Captioning",
      "type": "TaskApplication",
      "description": "Target task: Image Captioning"
    },
    {
      "name": "Computer Vision",
      "type": "DomainApplication",
      "description": "Domain application: Computer Vision"
    },
    {
      "name": "Visual-Language Understanding",
      "type": "DomainApplication",
      "description": "Domain application: Visual-Language Understanding"
    },
    {
      "name": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "type": "Paper",
      "description": "Paper: Rethinking Search: Making Domain Experts out of Dilettantes (2021)"
    },
    {
      "name": "Donald Metzler",
      "type": "Author",
      "description": "Author of paper: Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "name": "Yi Tay",
      "type": "Author",
      "description": "Author of paper: Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "name": "Dara Bahri",
      "type": "Author",
      "description": "Author of paper: Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "name": "Marc Najork",
      "type": "Author",
      "description": "Author of paper: Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "name": "Dense vector-based indexes",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Dense vector representations that capture semantically-rich document representations to overcome vocabulary mismatch problems"
    },
    {
      "name": "Web corpus",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Web documents with rich structure and metadata for training corpus models"
    },
    {
      "name": "Corpus model",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Multi-task learning framework",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Response generation with citations",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Document identifier integration",
      "type": "Method",
      "description": "Component in End2EndRAG"
    },
    {
      "name": "Authoritativeness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Measure of how well responses draw from highly authoritative sources"
    },
    {
      "name": "Transparency",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Ability to provide provenance and primary source information"
    },
    {
      "name": "Bias mitigation",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Evaluation of societal biases and fairness in generated responses"
    },
    {
      "name": "Diverse perspectives",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Coverage of multiple viewpoints on controversial topics"
    },
    {
      "name": "Graph Retrieval-Augmented Generation: A Survey",
      "type": "Paper",
      "description": "Paper: Graph Retrieval-Augmented Generation: A Survey (2024)"
    },
    {
      "name": "Boci Peng",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Yongchao Liu",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Xiaohe Bo",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Haizhou Shi",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Chuntao Hong",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Yan Zhang",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Siliang Tang",
      "type": "Author",
      "description": "Author of paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Ant Group",
      "type": "Institution",
      "description": "Institution affiliated with paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Renmin University of China",
      "type": "Institution",
      "description": "Institution affiliated with paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "Rutgers University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "name": "SentenceBERT",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Used for text classification and sentiment analysis tasks"
    },
    {
      "name": "Qwen2",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Large language model demonstrating potential in language understanding"
    },
    {
      "name": "WebQSP",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Benchmark dataset for evaluating KBQA systems"
    },
    {
      "name": "Graph-Based Indexing",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Graph-Guided Retrieval",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Graph-Enhanced Generation",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Non-parametric Retrievers",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "LM-based Retrievers",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "GNN-based Retrievers",
      "type": "Method",
      "description": "Component in ModularRAG"
    },
    {
      "name": "Hits@K",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Measures whether correct answer appears in top-K retrieved results"
    },
    {
      "name": "KBQA",
      "type": "TaskApplication",
      "description": "Target task: KBQA"
    },
    {
      "name": "CSQA",
      "type": "TaskApplication",
      "description": "Target task: CSQA"
    },
    {
      "name": "EntityLinking",
      "type": "TaskApplication",
      "description": "Target task: EntityLinking"
    },
    {
      "name": "RelationExtraction",
      "type": "TaskApplication",
      "description": "Target task: RelationExtraction"
    },
    {
      "name": "FactVerification",
      "type": "TaskApplication",
      "description": "Target task: FactVerification"
    },
    {
      "name": "LinkPrediction",
      "type": "TaskApplication",
      "description": "Target task: LinkPrediction"
    },
    {
      "name": "E-commerce",
      "type": "DomainApplication",
      "description": "Domain application: E-commerce"
    },
    {
      "name": "Academic Research",
      "type": "DomainApplication",
      "description": "Domain application: Academic Research"
    },
    {
      "name": "Literature Analysis",
      "type": "DomainApplication",
      "description": "Domain application: Literature Analysis"
    },
    {
      "name": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "type": "Paper",
      "description": "Paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization (2024)"
    },
    {
      "name": "Darren Edge",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Ha Trinh",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Newman Cheng",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Joshua Bradley",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Alex Chao",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Apurva Mody",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Steven Truitt",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Dasha Metropolitansky",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Robert Osazuwa Ness",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Jonathan Larson",
      "type": "Author",
      "description": "Author of paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Microsoft Strategic Missions and Technologies",
      "type": "Institution",
      "description": "Institution affiliated with paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Microsoft Office of the CTO",
      "type": "Institution",
      "description": "Institution affiliated with paper: From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "name": "Vector RAG baseline",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Text embedding-based retrieval using semantic similarity in vector space"
    },
    {
      "name": "Behind the Tech podcast transcripts",
      "type": "TestDataset",
      "description": "TestDataset: Public transcripts of Behind the Tech with Kevin Scott podcast featuring conversations with thought leaders in science and technology"
    },
    {
      "name": "News articles dataset",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: News articles published from September 2013 to December 2023 across entertainment, business, sports, technology, health, and science categories"
    },
    {
      "name": "Text chunking",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Entity extraction",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Knowledge graph construction",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Community detection",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Community summarization",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Query processing",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Map-reduce answer generation",
      "type": "Method",
      "description": "Component in HierarchicalRAG"
    },
    {
      "name": "Comprehensiveness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: How much detail does the answer provide to cover all aspects and details of the question, measured through LLM-as-a-judge head-to-head comparisons"
    },
    {
      "name": "Empowerment",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: How well does the answer help the reader understand and make informed judgments about the topic without being misled"
    },
    {
      "name": "Directness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: How specifically and clearly does the answer address the question, used as a validity check"
    },
    {
      "name": "Claim-based comprehensiveness",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Average number of factual claims extracted from answers using Claimify method"
    },
    {
      "name": "Claim-based diversity",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Average number of clusters of factual claims using agglomerative clustering with ROUGE-L distance"
    },
    {
      "name": "Claimify",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "Global sensemaking over large text corpora",
      "type": "DomainApplication",
      "description": "Domain application: Global sensemaking over large text corpora"
    },
    {
      "name": "Intelligence analysis",
      "type": "DomainApplication",
      "description": "Domain application: Intelligence analysis"
    },
    {
      "name": "Scientific discovery support",
      "type": "DomainApplication",
      "description": "Domain application: Scientific discovery support"
    },
    {
      "name": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "type": "Paper",
      "description": "Paper: Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval (2021)"
    },
    {
      "name": "Craig Macdonald",
      "type": "Author",
      "description": "Author of paper: Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "name": "Iadh Ounis",
      "type": "Author",
      "description": "Author of paper: Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "name": "University of Glasgow",
      "type": "Institution",
      "description": "Institution affiliated with paper: Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "name": "BERT reranker",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: BERT-based neural reranking model"
    },
    {
      "name": "MSMARCO passage ranking",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Training dataset for ColBERT model"
    },
    {
      "name": "TREC 2019 Deep Learning track",
      "type": "TestDataset",
      "description": "TestDataset: Test queries for evaluation"
    },
    {
      "name": "TREC 2020 Deep Learning track",
      "type": "TestDataset",
      "description": "TestDataset: Test queries for evaluation"
    },
    {
      "name": "Dense retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Feedback embedding extraction",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Clustering",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Discriminative selection",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Re-ranking/Re-retrieval",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Recall@1000",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Recall at rank 1000"
    },
    {
      "name": "Mean Response Time",
      "type": "EvaluationMetric",
      "description": "EvaluationMetric: Average query processing time"
    },
    {
      "name": "PyTerrier",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "DocumentRetrieval",
      "type": "TaskApplication",
      "description": "Target task: DocumentRetrieval"
    },
    {
      "name": "PassageRanking",
      "type": "TaskApplication",
      "description": "Target task: PassageRanking"
    },
    {
      "name": "GeneralDomain",
      "type": "DomainApplication",
      "description": "Domain application: GeneralDomain"
    },
    {
      "name": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "type": "Paper",
      "description": "Paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification (2021)"
    },
    {
      "name": "Xiao Zhang",
      "type": "Author",
      "description": "Author of paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "Yixiao Ge",
      "type": "Author",
      "description": "Author of paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "Yu Qiao",
      "type": "Author",
      "description": "Author of paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "Hongsheng Li",
      "type": "Author",
      "description": "Author of paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
      "type": "Institution",
      "description": "Institution affiliated with paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
      "type": "Institution",
      "description": "Institution affiliated with paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "Shanghai AI Laboratory",
      "type": "Institution",
      "description": "Institution affiliated with paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "School of CST, Xidian University",
      "type": "Institution",
      "description": "Institution affiliated with paper: Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "name": "ResNet-50",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: ImageNet pre-trained ResNet-50 backbone for feature extraction"
    },
    {
      "name": "Market-1501",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Person re-ID dataset captured by 6 cameras"
    },
    {
      "name": "DukeMTMC-reID",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Person re-ID dataset collected from 8 cameras"
    },
    {
      "name": "MSMT17",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Large-scale person re-ID dataset collected by 15 cameras"
    },
    {
      "name": "VeRi-776",
      "type": "BenchmarkDataset",
      "description": "BenchmarkDataset: Vehicle re-ID dataset in urban surveillance scenario"
    },
    {
      "name": "Feature extraction network",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "DBSCAN clustering",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Pseudo label refinement",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "Contrastive learning",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "mAP",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Mean average precision for object retrieval evaluation"
    },
    {
      "name": "CMC",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Cumulative matching characteristic for ranking evaluation"
    },
    {
      "name": "top-1 accuracy",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Top-1 retrieval accuracy"
    },
    {
      "name": "top-5 accuracy",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Top-5 retrieval accuracy"
    },
    {
      "name": "top-10 accuracy",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Top-10 retrieval accuracy"
    },
    {
      "name": "Object Re-identification",
      "type": "TaskApplication",
      "description": "Target task: Object Re-identification"
    },
    {
      "name": "Person Re-identification",
      "type": "TaskApplication",
      "description": "Target task: Person Re-identification"
    },
    {
      "name": "Vehicle Re-identification",
      "type": "TaskApplication",
      "description": "Target task: Vehicle Re-identification"
    },
    {
      "name": "Surveillance systems",
      "type": "DomainApplication",
      "description": "Domain application: Surveillance systems"
    },
    {
      "name": "Security applications",
      "type": "DomainApplication",
      "description": "Domain application: Security applications"
    },
    {
      "name": "Urban monitoring",
      "type": "DomainApplication",
      "description": "Domain application: Urban monitoring"
    },
    {
      "name": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "type": "Paper",
      "description": "Paper: One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval (2021)"
    },
    {
      "name": "Xinyan Yu",
      "type": "Author",
      "description": "Author of paper: One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval"
    },
    {
      "name": "Jungo Kasai",
      "type": "Author",
      "description": "Author of paper: One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval"
    },
    {
      "name": "mDPR (multilingual Dense Passage Retriever)",
      "type": "EmbeddingModel",
      "description": "EmbeddingModel: Extends Dense Passage Retriever to multilingual setting using multilingual BERT base uncased to encode passages and questions separately for cross-lingual retrieval"
    },
    {
      "name": "mGEN (multilingual Answer Generator)",
      "type": "PretrainedLLM",
      "description": "PretrainedLLM: Multilingual sequence-to-sequence model using mT5-base to generate answers in target language from retrieved multilingual passages"
    },
    {
      "name": "XOR-TYDI QA",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Multilingual open QA dataset with questions from TYDI QA and answers from Wikipedia in same language or translated from English"
    },
    {
      "name": "MKQA",
      "type": "TestDataset",
      "description": "TestDataset: Evaluation dataset created by translating Natural Questions to 25 target languages for cross-lingual comparison"
    },
    {
      "name": "TYDI QA",
      "type": "TrainingDataset",
      "description": "TrainingDataset: Multilingual QA dataset used for initial training"
    },
    {
      "name": "mDPR (multilingual Dense Passage Retriever)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "mGEN (multilingual Answer Generator)",
      "type": "Method",
      "description": "Component in PipelineRAG"
    },
    {
      "name": "IterativeTraining",
      "type": "Method",
      "description": "Method: "
    },
    {
      "name": "Retrieval Recall",
      "type": "RetrievalMetrics",
      "description": "RetrievalMetrics: Percentage of questions where at least one top-10 passage contains answer string (RL@10 and Rmulti@10)"
    },
    {
      "name": "Transformers library",
      "type": "DevelopmentFramework",
      "description": "DevelopmentFramework used in paper"
    },
    {
      "name": "Local vector storage for passage embeddings",
      "type": "VectorDatabase",
      "description": "VectorDatabase used in paper"
    },
    {
      "name": "Pyserini for BM25 baseline",
      "type": "EvaluationTool",
      "description": "EvaluationTool used in paper"
    },
    {
      "name": "multilingual information seeking",
      "type": "DomainApplication",
      "description": "Domain application: multilingual information seeking"
    },
    {
      "name": "cross-lingual knowledge access",
      "type": "DomainApplication",
      "description": "Domain application: cross-lingual knowledge access"
    },
    {
      "name": "low-resource language QA",
      "type": "DomainApplication",
      "description": "Domain application: low-resource language QA"
    }
  ],
  "relationships": [
    {
      "source": "Patrick Lewis",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Patrick Lewis authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Ethan Perez",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Ethan Perez authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Aleksandra Piktus authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Fabio Petroni",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Fabio Petroni authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Vladimir Karpukhin authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Naman Goyal",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Naman Goyal authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Heinrich Küttler",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Heinrich Küttler authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Mike Lewis",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Mike Lewis authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Wen-tau Yih authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Tim Rocktäschel authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Sebastian Riedel authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Douwe Kiela",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Douwe Kiela authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Patrick Lewis",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with Facebook AI Research"
    },
    {
      "source": "Patrick Lewis",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with University College London"
    },
    {
      "source": "Patrick Lewis",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with New York University"
    },
    {
      "source": "Ethan Perez",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Ethan Perez affiliated with Facebook AI Research"
    },
    {
      "source": "Ethan Perez",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Ethan Perez affiliated with University College London"
    },
    {
      "source": "Ethan Perez",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Ethan Perez affiliated with New York University"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Aleksandra Piktus affiliated with Facebook AI Research"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Aleksandra Piktus affiliated with University College London"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Aleksandra Piktus affiliated with New York University"
    },
    {
      "source": "Fabio Petroni",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with Facebook AI Research"
    },
    {
      "source": "Fabio Petroni",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with University College London"
    },
    {
      "source": "Fabio Petroni",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with New York University"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Vladimir Karpukhin affiliated with Facebook AI Research"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Vladimir Karpukhin affiliated with University College London"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Vladimir Karpukhin affiliated with New York University"
    },
    {
      "source": "Naman Goyal",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Naman Goyal affiliated with Facebook AI Research"
    },
    {
      "source": "Naman Goyal",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Naman Goyal affiliated with University College London"
    },
    {
      "source": "Naman Goyal",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Naman Goyal affiliated with New York University"
    },
    {
      "source": "Heinrich Küttler",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Heinrich Küttler affiliated with Facebook AI Research"
    },
    {
      "source": "Heinrich Küttler",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Heinrich Küttler affiliated with University College London"
    },
    {
      "source": "Heinrich Küttler",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Heinrich Küttler affiliated with New York University"
    },
    {
      "source": "Mike Lewis",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Facebook AI Research"
    },
    {
      "source": "Mike Lewis",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with University College London"
    },
    {
      "source": "Mike Lewis",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with New York University"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Facebook AI Research"
    },
    {
      "source": "Wen-tau Yih",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with University College London"
    },
    {
      "source": "Wen-tau Yih",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with New York University"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Tim Rocktäschel affiliated with Facebook AI Research"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Tim Rocktäschel affiliated with University College London"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Tim Rocktäschel affiliated with New York University"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Facebook AI Research"
    },
    {
      "source": "Sebastian Riedel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with University College London"
    },
    {
      "source": "Sebastian Riedel",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with New York University"
    },
    {
      "source": "Douwe Kiela",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Douwe Kiela affiliated with Facebook AI Research"
    },
    {
      "source": "Douwe Kiela",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Douwe Kiela affiliated with University College London"
    },
    {
      "source": "Douwe Kiela",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Douwe Kiela affiliated with New York University"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "DPR (Dense Passage Retriever)",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses DPR (Dense Passage Retriever)"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "BERT-base",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses BERT-base"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "BART-large",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses BART-large"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses Natural Questions"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses TriviaQA"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "WebQuestions",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses WebQuestions"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "CuratedTrec",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses CuratedTrec"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses MS-MARCO"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "FEVER",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses FEVER"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "SearchQA (Jeopardy)",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses SearchQA (Jeopardy)"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes PipelineRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes DenseRetrieval"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes JointTraining"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to QA"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to DocumentSummarization"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to ConversationalAI"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Open-domain question answering",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Open-domain question answering"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Abstractive question answering",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Abstractive question answering"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Fact verification",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Fact verification"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Question generation",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Question generation"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on Natural Questions"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on TriviaQA"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on WebQuestions"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on CuratedTrec"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on MS-MARCO"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on FEVER"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "SearchQA (Jeopardy)",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on SearchQA (Jeopardy)"
    },
    {
      "source": "BERT-base",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on Natural Questions"
    },
    {
      "source": "BERT-base",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on TriviaQA"
    },
    {
      "source": "BERT-base",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on WebQuestions"
    },
    {
      "source": "BERT-base",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on CuratedTrec"
    },
    {
      "source": "BERT-base",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on MS-MARCO"
    },
    {
      "source": "BERT-base",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on FEVER"
    },
    {
      "source": "BERT-base",
      "target": "SearchQA (Jeopardy)",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on SearchQA (Jeopardy)"
    },
    {
      "source": "BART-large",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on Natural Questions"
    },
    {
      "source": "BART-large",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on TriviaQA"
    },
    {
      "source": "BART-large",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on WebQuestions"
    },
    {
      "source": "BART-large",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on CuratedTrec"
    },
    {
      "source": "BART-large",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on MS-MARCO"
    },
    {
      "source": "BART-large",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on FEVER"
    },
    {
      "source": "BART-large",
      "target": "SearchQA (Jeopardy)",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on SearchQA (Jeopardy)"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Akari Asai",
      "target": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "keywords": "authorship",
      "description": "Akari Asai authored SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "source": "Zeqiu Wu",
      "target": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "keywords": "authorship",
      "description": "Zeqiu Wu authored SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "source": "Yizhong Wang",
      "target": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "keywords": "authorship",
      "description": "Yizhong Wang authored SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "source": "Avirup Sil",
      "target": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "keywords": "authorship",
      "description": "Avirup Sil authored SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "keywords": "authorship",
      "description": "Hannaneh Hajishirzi authored SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION"
    },
    {
      "source": "Akari Asai",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Akari Asai affiliated with University of Washington"
    },
    {
      "source": "Akari Asai",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Akari Asai affiliated with Allen Institute for AI"
    },
    {
      "source": "Akari Asai",
      "target": "IBM Research AI",
      "keywords": "affiliation",
      "description": "Akari Asai affiliated with IBM Research AI"
    },
    {
      "source": "Zeqiu Wu",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Zeqiu Wu affiliated with University of Washington"
    },
    {
      "source": "Zeqiu Wu",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Zeqiu Wu affiliated with Allen Institute for AI"
    },
    {
      "source": "Zeqiu Wu",
      "target": "IBM Research AI",
      "keywords": "affiliation",
      "description": "Zeqiu Wu affiliated with IBM Research AI"
    },
    {
      "source": "Yizhong Wang",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Yizhong Wang affiliated with University of Washington"
    },
    {
      "source": "Yizhong Wang",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Yizhong Wang affiliated with Allen Institute for AI"
    },
    {
      "source": "Yizhong Wang",
      "target": "IBM Research AI",
      "keywords": "affiliation",
      "description": "Yizhong Wang affiliated with IBM Research AI"
    },
    {
      "source": "Avirup Sil",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Avirup Sil affiliated with University of Washington"
    },
    {
      "source": "Avirup Sil",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Avirup Sil affiliated with Allen Institute for AI"
    },
    {
      "source": "Avirup Sil",
      "target": "IBM Research AI",
      "keywords": "affiliation",
      "description": "Avirup Sil affiliated with IBM Research AI"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Hannaneh Hajishirzi affiliated with University of Washington"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Hannaneh Hajishirzi affiliated with Allen Institute for AI"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "IBM Research AI",
      "keywords": "affiliation",
      "description": "Hannaneh Hajishirzi affiliated with IBM Research AI"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Contriever-MS MARCO",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses Contriever-MS MARCO"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Llama2",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses Llama2"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses GPT-4"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "SELF-RAG",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses SELF-RAG"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Open-Instruct",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses Open-Instruct"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses Natural Questions"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "PopQA",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses PopQA"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "TriviaQA-unfiltered",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses TriviaQA-unfiltered"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "ASQA",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses ASQA"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "PubHealth",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses PubHealth"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "ARC-Challenge",
      "keywords": "uses",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION uses ARC-Challenge"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "AdaptiveRAG",
      "keywords": "proposes",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION proposes AdaptiveRAG"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION proposes DenseRetrieval"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "IterativeGeneration",
      "keywords": "proposes",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION proposes IterativeGeneration"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION proposes SeparateTraining"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "QA",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to QA"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to DocumentSummarization"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to ConversationalAI"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Open-domain QA",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to Open-domain QA"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Long-form generation",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to Long-form generation"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Fact verification",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to Fact verification"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Reasoning tasks",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to Reasoning tasks"
    },
    {
      "source": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION",
      "target": "Biography generation",
      "keywords": "applies_to",
      "description": "SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION applies to Biography generation"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "Open-Instruct",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on Open-Instruct"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on Natural Questions"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on PopQA"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "TriviaQA-unfiltered",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on TriviaQA-unfiltered"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "ASQA",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on ASQA"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on PubHealth"
    },
    {
      "source": "Contriever-MS MARCO",
      "target": "ARC-Challenge",
      "keywords": "trained_on",
      "description": "Contriever-MS MARCO potentially trained on ARC-Challenge"
    },
    {
      "source": "Llama2",
      "target": "Open-Instruct",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on Open-Instruct"
    },
    {
      "source": "Llama2",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on Natural Questions"
    },
    {
      "source": "Llama2",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on PopQA"
    },
    {
      "source": "Llama2",
      "target": "TriviaQA-unfiltered",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on TriviaQA-unfiltered"
    },
    {
      "source": "Llama2",
      "target": "ASQA",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on ASQA"
    },
    {
      "source": "Llama2",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on PubHealth"
    },
    {
      "source": "Llama2",
      "target": "ARC-Challenge",
      "keywords": "trained_on",
      "description": "Llama2 potentially trained on ARC-Challenge"
    },
    {
      "source": "GPT-4",
      "target": "Open-Instruct",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Open-Instruct"
    },
    {
      "source": "GPT-4",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-4",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on PopQA"
    },
    {
      "source": "GPT-4",
      "target": "TriviaQA-unfiltered",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on TriviaQA-unfiltered"
    },
    {
      "source": "GPT-4",
      "target": "ASQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on ASQA"
    },
    {
      "source": "GPT-4",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on PubHealth"
    },
    {
      "source": "GPT-4",
      "target": "ARC-Challenge",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on ARC-Challenge"
    },
    {
      "source": "SELF-RAG",
      "target": "Open-Instruct",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on Open-Instruct"
    },
    {
      "source": "SELF-RAG",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on Natural Questions"
    },
    {
      "source": "SELF-RAG",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on PopQA"
    },
    {
      "source": "SELF-RAG",
      "target": "TriviaQA-unfiltered",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on TriviaQA-unfiltered"
    },
    {
      "source": "SELF-RAG",
      "target": "ASQA",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on ASQA"
    },
    {
      "source": "SELF-RAG",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on PubHealth"
    },
    {
      "source": "SELF-RAG",
      "target": "ARC-Challenge",
      "keywords": "trained_on",
      "description": "SELF-RAG potentially trained on ARC-Challenge"
    },
    {
      "source": "AdaptiveRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "AdaptiveRAG supports QA"
    },
    {
      "source": "AdaptiveRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AdaptiveRAG supports DocumentSummarization"
    },
    {
      "source": "AdaptiveRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AdaptiveRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "IterativeGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "IterativeGeneration supports QA"
    },
    {
      "source": "IterativeGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "IterativeGeneration supports DocumentSummarization"
    },
    {
      "source": "IterativeGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "IterativeGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Jiachang Liu",
      "target": "What Makes Good In-Context Examples for GPT-3?",
      "keywords": "authorship",
      "description": "Jiachang Liu authored What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "source": "Dinghan Shen",
      "target": "What Makes Good In-Context Examples for GPT-3?",
      "keywords": "authorship",
      "description": "Dinghan Shen authored What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "source": "Yizhe Zhang",
      "target": "What Makes Good In-Context Examples for GPT-3?",
      "keywords": "authorship",
      "description": "Yizhe Zhang authored What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "source": "Bill Dolan",
      "target": "What Makes Good In-Context Examples for GPT-3?",
      "keywords": "authorship",
      "description": "Bill Dolan authored What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "source": "Lawrence Carin",
      "target": "What Makes Good In-Context Examples for GPT-3?",
      "keywords": "authorship",
      "description": "Lawrence Carin authored What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "source": "Weizhu Chen",
      "target": "What Makes Good In-Context Examples for GPT-3?",
      "keywords": "authorship",
      "description": "Weizhu Chen authored What Makes Good In-Context Examples for GPT-3?"
    },
    {
      "source": "Jiachang Liu",
      "target": "Duke University",
      "keywords": "affiliation",
      "description": "Jiachang Liu affiliated with Duke University"
    },
    {
      "source": "Jiachang Liu",
      "target": "Microsoft Dynamics 365 AI",
      "keywords": "affiliation",
      "description": "Jiachang Liu affiliated with Microsoft Dynamics 365 AI"
    },
    {
      "source": "Jiachang Liu",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Jiachang Liu affiliated with Microsoft Research"
    },
    {
      "source": "Dinghan Shen",
      "target": "Duke University",
      "keywords": "affiliation",
      "description": "Dinghan Shen affiliated with Duke University"
    },
    {
      "source": "Dinghan Shen",
      "target": "Microsoft Dynamics 365 AI",
      "keywords": "affiliation",
      "description": "Dinghan Shen affiliated with Microsoft Dynamics 365 AI"
    },
    {
      "source": "Dinghan Shen",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Dinghan Shen affiliated with Microsoft Research"
    },
    {
      "source": "Yizhe Zhang",
      "target": "Duke University",
      "keywords": "affiliation",
      "description": "Yizhe Zhang affiliated with Duke University"
    },
    {
      "source": "Yizhe Zhang",
      "target": "Microsoft Dynamics 365 AI",
      "keywords": "affiliation",
      "description": "Yizhe Zhang affiliated with Microsoft Dynamics 365 AI"
    },
    {
      "source": "Yizhe Zhang",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Yizhe Zhang affiliated with Microsoft Research"
    },
    {
      "source": "Bill Dolan",
      "target": "Duke University",
      "keywords": "affiliation",
      "description": "Bill Dolan affiliated with Duke University"
    },
    {
      "source": "Bill Dolan",
      "target": "Microsoft Dynamics 365 AI",
      "keywords": "affiliation",
      "description": "Bill Dolan affiliated with Microsoft Dynamics 365 AI"
    },
    {
      "source": "Bill Dolan",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Bill Dolan affiliated with Microsoft Research"
    },
    {
      "source": "Lawrence Carin",
      "target": "Duke University",
      "keywords": "affiliation",
      "description": "Lawrence Carin affiliated with Duke University"
    },
    {
      "source": "Lawrence Carin",
      "target": "Microsoft Dynamics 365 AI",
      "keywords": "affiliation",
      "description": "Lawrence Carin affiliated with Microsoft Dynamics 365 AI"
    },
    {
      "source": "Lawrence Carin",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Lawrence Carin affiliated with Microsoft Research"
    },
    {
      "source": "Weizhu Chen",
      "target": "Duke University",
      "keywords": "affiliation",
      "description": "Weizhu Chen affiliated with Duke University"
    },
    {
      "source": "Weizhu Chen",
      "target": "Microsoft Dynamics 365 AI",
      "keywords": "affiliation",
      "description": "Weizhu Chen affiliated with Microsoft Dynamics 365 AI"
    },
    {
      "source": "Weizhu Chen",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Weizhu Chen affiliated with Microsoft Research"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "RoBERTa-large",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses RoBERTa-large"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses RoBERTa-large fine-tuned on SNLI+MultiNLI"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses GPT-3"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "SST-2",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses SST-2"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "IMDB",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses IMDB"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "ToTTo",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses ToTTo"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses Natural Questions (NQ)"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "Web Questions (WQ)",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses Web Questions (WQ)"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "What Makes Good In-Context Examples for GPT-3? uses TriviaQA"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "What Makes Good In-Context Examples for GPT-3? proposes PipelineRAG"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "What Makes Good In-Context Examples for GPT-3? proposes DenseRetrieval"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "What Makes Good In-Context Examples for GPT-3? proposes AbstractiveGeneration"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "What Makes Good In-Context Examples for GPT-3? proposes SeparateTraining"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "QA",
      "keywords": "applies_to",
      "description": "What Makes Good In-Context Examples for GPT-3? applies to QA"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "What Makes Good In-Context Examples for GPT-3? applies to DocumentSummarization"
    },
    {
      "source": "What Makes Good In-Context Examples for GPT-3?",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "What Makes Good In-Context Examples for GPT-3? applies to ConversationalAI"
    },
    {
      "source": "RoBERTa-large",
      "target": "SST-2",
      "keywords": "trained_on",
      "description": "RoBERTa-large potentially trained on SST-2"
    },
    {
      "source": "RoBERTa-large",
      "target": "IMDB",
      "keywords": "trained_on",
      "description": "RoBERTa-large potentially trained on IMDB"
    },
    {
      "source": "RoBERTa-large",
      "target": "ToTTo",
      "keywords": "trained_on",
      "description": "RoBERTa-large potentially trained on ToTTo"
    },
    {
      "source": "RoBERTa-large",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "RoBERTa-large potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "RoBERTa-large",
      "target": "Web Questions (WQ)",
      "keywords": "trained_on",
      "description": "RoBERTa-large potentially trained on Web Questions (WQ)"
    },
    {
      "source": "RoBERTa-large",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "RoBERTa-large potentially trained on TriviaQA"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "target": "SST-2",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI potentially trained on SST-2"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "target": "IMDB",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI potentially trained on IMDB"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "target": "ToTTo",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI potentially trained on ToTTo"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "target": "Web Questions (WQ)",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI potentially trained on Web Questions (WQ)"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI potentially trained on TriviaQA"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "target": "SST-2",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B potentially trained on SST-2"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "target": "IMDB",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B potentially trained on IMDB"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "target": "ToTTo",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B potentially trained on ToTTo"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "target": "Web Questions (WQ)",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B potentially trained on Web Questions (WQ)"
    },
    {
      "source": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "RoBERTa-large fine-tuned on SNLI+MultiNLI+STS-B potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3",
      "target": "SST-2",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on SST-2"
    },
    {
      "source": "GPT-3",
      "target": "IMDB",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on IMDB"
    },
    {
      "source": "GPT-3",
      "target": "ToTTo",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on ToTTo"
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-3",
      "target": "Web Questions (WQ)",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Web Questions (WQ)"
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TriviaQA"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Alexander Long",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Alexander Long authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Wei Yin",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Wei Yin authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Thalaiyasingam Ajanthan",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Thalaiyasingam Ajanthan authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Vu Nguyen",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Vu Nguyen authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Pulak Purkait",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Pulak Purkait authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Ravi Garg",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Ravi Garg authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Alan Blair",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Alan Blair authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Chunhua Shen",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Chunhua Shen authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Anton van den Hengel",
      "target": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "keywords": "authorship",
      "description": "Anton van den Hengel authored Retrieval Augmented Classification for Long-Tail Visual Recognition"
    },
    {
      "source": "Alexander Long",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Alexander Long affiliated with Amazon"
    },
    {
      "source": "Alexander Long",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Alexander Long affiliated with The University of Adelaide"
    },
    {
      "source": "Alexander Long",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Alexander Long affiliated with University of New South Wales"
    },
    {
      "source": "Alexander Long",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Alexander Long affiliated with Zhejiang University"
    },
    {
      "source": "Wei Yin",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Wei Yin affiliated with Amazon"
    },
    {
      "source": "Wei Yin",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Wei Yin affiliated with The University of Adelaide"
    },
    {
      "source": "Wei Yin",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Wei Yin affiliated with University of New South Wales"
    },
    {
      "source": "Wei Yin",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Wei Yin affiliated with Zhejiang University"
    },
    {
      "source": "Thalaiyasingam Ajanthan",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Thalaiyasingam Ajanthan affiliated with Amazon"
    },
    {
      "source": "Thalaiyasingam Ajanthan",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Thalaiyasingam Ajanthan affiliated with The University of Adelaide"
    },
    {
      "source": "Thalaiyasingam Ajanthan",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Thalaiyasingam Ajanthan affiliated with University of New South Wales"
    },
    {
      "source": "Thalaiyasingam Ajanthan",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Thalaiyasingam Ajanthan affiliated with Zhejiang University"
    },
    {
      "source": "Vu Nguyen",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Vu Nguyen affiliated with Amazon"
    },
    {
      "source": "Vu Nguyen",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Vu Nguyen affiliated with The University of Adelaide"
    },
    {
      "source": "Vu Nguyen",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Vu Nguyen affiliated with University of New South Wales"
    },
    {
      "source": "Vu Nguyen",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Vu Nguyen affiliated with Zhejiang University"
    },
    {
      "source": "Pulak Purkait",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Pulak Purkait affiliated with Amazon"
    },
    {
      "source": "Pulak Purkait",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Pulak Purkait affiliated with The University of Adelaide"
    },
    {
      "source": "Pulak Purkait",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Pulak Purkait affiliated with University of New South Wales"
    },
    {
      "source": "Pulak Purkait",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Pulak Purkait affiliated with Zhejiang University"
    },
    {
      "source": "Ravi Garg",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Ravi Garg affiliated with Amazon"
    },
    {
      "source": "Ravi Garg",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Ravi Garg affiliated with The University of Adelaide"
    },
    {
      "source": "Ravi Garg",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Ravi Garg affiliated with University of New South Wales"
    },
    {
      "source": "Ravi Garg",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Ravi Garg affiliated with Zhejiang University"
    },
    {
      "source": "Alan Blair",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Alan Blair affiliated with Amazon"
    },
    {
      "source": "Alan Blair",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Alan Blair affiliated with The University of Adelaide"
    },
    {
      "source": "Alan Blair",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Alan Blair affiliated with University of New South Wales"
    },
    {
      "source": "Alan Blair",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Alan Blair affiliated with Zhejiang University"
    },
    {
      "source": "Chunhua Shen",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Chunhua Shen affiliated with Amazon"
    },
    {
      "source": "Chunhua Shen",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Chunhua Shen affiliated with The University of Adelaide"
    },
    {
      "source": "Chunhua Shen",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Chunhua Shen affiliated with University of New South Wales"
    },
    {
      "source": "Chunhua Shen",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Chunhua Shen affiliated with Zhejiang University"
    },
    {
      "source": "Anton van den Hengel",
      "target": "Amazon",
      "keywords": "affiliation",
      "description": "Anton van den Hengel affiliated with Amazon"
    },
    {
      "source": "Anton van den Hengel",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Anton van den Hengel affiliated with The University of Adelaide"
    },
    {
      "source": "Anton van den Hengel",
      "target": "University of New South Wales",
      "keywords": "affiliation",
      "description": "Anton van den Hengel affiliated with University of New South Wales"
    },
    {
      "source": "Anton van den Hengel",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Anton van den Hengel affiliated with Zhejiang University"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "ViT-B-16",
      "keywords": "uses",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition uses ViT-B-16"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "ViT-B-16",
      "keywords": "uses",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition uses ViT-B-16"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "BERT-like text encoder from CLIP",
      "keywords": "uses",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition uses BERT-like text encoder from CLIP"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "Places365-LT",
      "keywords": "uses",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition uses Places365-LT"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "iNaturalist-2018",
      "keywords": "uses",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition uses iNaturalist-2018"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "ImageNet21k",
      "keywords": "uses",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition uses ImageNet21k"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition proposes PipelineRAG"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition proposes DenseRetrieval"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition proposes JointTraining"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition applies to QA"
    },
    {
      "source": "Retrieval Augmented Classification for Long-Tail Visual Recognition",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Classification for Long-Tail Visual Recognition applies to MedicalRAG"
    },
    {
      "source": "ViT-B-16",
      "target": "Places365-LT",
      "keywords": "trained_on",
      "description": "ViT-B-16 potentially trained on Places365-LT"
    },
    {
      "source": "ViT-B-16",
      "target": "iNaturalist-2018",
      "keywords": "trained_on",
      "description": "ViT-B-16 potentially trained on iNaturalist-2018"
    },
    {
      "source": "ViT-B-16",
      "target": "ImageNet21k",
      "keywords": "trained_on",
      "description": "ViT-B-16 potentially trained on ImageNet21k"
    },
    {
      "source": "ViT-B-16",
      "target": "Places365-LT",
      "keywords": "trained_on",
      "description": "ViT-B-16 potentially trained on Places365-LT"
    },
    {
      "source": "ViT-B-16",
      "target": "iNaturalist-2018",
      "keywords": "trained_on",
      "description": "ViT-B-16 potentially trained on iNaturalist-2018"
    },
    {
      "source": "ViT-B-16",
      "target": "ImageNet21k",
      "keywords": "trained_on",
      "description": "ViT-B-16 potentially trained on ImageNet21k"
    },
    {
      "source": "BERT-like text encoder from CLIP",
      "target": "Places365-LT",
      "keywords": "trained_on",
      "description": "BERT-like text encoder from CLIP potentially trained on Places365-LT"
    },
    {
      "source": "BERT-like text encoder from CLIP",
      "target": "iNaturalist-2018",
      "keywords": "trained_on",
      "description": "BERT-like text encoder from CLIP potentially trained on iNaturalist-2018"
    },
    {
      "source": "BERT-like text encoder from CLIP",
      "target": "ImageNet21k",
      "keywords": "trained_on",
      "description": "BERT-like text encoder from CLIP potentially trained on ImageNet21k"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "Gemini Team",
      "target": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "keywords": "authorship",
      "description": "Gemini Team authored Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
    },
    {
      "source": "Google",
      "target": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "keywords": "authorship",
      "description": "Google authored Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context"
    },
    {
      "source": "Gemini Team",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Gemini Team affiliated with Google"
    },
    {
      "source": "Google",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Google affiliated with Google"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "Gemini 1.5 Pro",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses Gemini 1.5 Pro"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "Gemini 1.5 Flash",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses Gemini 1.5 Flash"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "Gemini 1.5 Pro",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses Gemini 1.5 Pro"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "Gemini 1.5 Flash",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses Gemini 1.5 Flash"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "Natural_Questions",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses Natural_Questions"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses MS-MARCO"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "BEIR",
      "keywords": "uses",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context uses BEIR"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "End2EndRAG",
      "keywords": "proposes",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context proposes End2EndRAG"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context proposes DenseRetrieval"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context proposes AbstractiveGeneration"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context proposes JointTraining"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context applies to QA"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context applies to DocumentSummarization"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context applies to ConversationalAI"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context applies to MedicalRAG"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context applies to LegalRAG"
    },
    {
      "source": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context applies to EducationalRAG"
    },
    {
      "source": "Gemini 1.5 Pro",
      "target": "Natural_Questions",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Pro potentially trained on Natural_Questions"
    },
    {
      "source": "Gemini 1.5 Pro",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Pro potentially trained on MS-MARCO"
    },
    {
      "source": "Gemini 1.5 Pro",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Pro potentially trained on BEIR"
    },
    {
      "source": "Gemini 1.5 Flash",
      "target": "Natural_Questions",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Flash potentially trained on Natural_Questions"
    },
    {
      "source": "Gemini 1.5 Flash",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Flash potentially trained on MS-MARCO"
    },
    {
      "source": "Gemini 1.5 Flash",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Flash potentially trained on BEIR"
    },
    {
      "source": "Gemini 1.5 Pro",
      "target": "Natural_Questions",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Pro potentially trained on Natural_Questions"
    },
    {
      "source": "Gemini 1.5 Pro",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Pro potentially trained on MS-MARCO"
    },
    {
      "source": "Gemini 1.5 Pro",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Pro potentially trained on BEIR"
    },
    {
      "source": "Gemini 1.5 Flash",
      "target": "Natural_Questions",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Flash potentially trained on Natural_Questions"
    },
    {
      "source": "Gemini 1.5 Flash",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Flash potentially trained on MS-MARCO"
    },
    {
      "source": "Gemini 1.5 Flash",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Gemini 1.5 Flash potentially trained on BEIR"
    },
    {
      "source": "End2EndRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "End2EndRAG supports QA"
    },
    {
      "source": "End2EndRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "End2EndRAG supports DocumentSummarization"
    },
    {
      "source": "End2EndRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "End2EndRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Linmei Hu",
      "target": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "keywords": "authorship",
      "description": "Linmei Hu authored A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "source": "Zeyi Liu",
      "target": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "keywords": "authorship",
      "description": "Zeyi Liu authored A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "source": "Ziwang Zhao",
      "target": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "keywords": "authorship",
      "description": "Ziwang Zhao authored A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "source": "Lei Hou",
      "target": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "keywords": "authorship",
      "description": "Lei Hou authored A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "source": "Liqiang Nie",
      "target": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "keywords": "authorship",
      "description": "Liqiang Nie authored A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "source": "Juanzi Li",
      "target": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "keywords": "authorship",
      "description": "Juanzi Li authored A Survey of Knowledge-Enhanced Pre-trained Language Models"
    },
    {
      "source": "Linmei Hu",
      "target": "Beijing Institute of Technology",
      "keywords": "affiliation",
      "description": "Linmei Hu affiliated with Beijing Institute of Technology"
    },
    {
      "source": "Linmei Hu",
      "target": "Beijing University of Posts and Telecommunications",
      "keywords": "affiliation",
      "description": "Linmei Hu affiliated with Beijing University of Posts and Telecommunications"
    },
    {
      "source": "Linmei Hu",
      "target": "Tsinghua University",
      "keywords": "affiliation",
      "description": "Linmei Hu affiliated with Tsinghua University"
    },
    {
      "source": "Linmei Hu",
      "target": "Harbin Institute of Technology (Shenzhen)",
      "keywords": "affiliation",
      "description": "Linmei Hu affiliated with Harbin Institute of Technology (Shenzhen)"
    },
    {
      "source": "Zeyi Liu",
      "target": "Beijing Institute of Technology",
      "keywords": "affiliation",
      "description": "Zeyi Liu affiliated with Beijing Institute of Technology"
    },
    {
      "source": "Zeyi Liu",
      "target": "Beijing University of Posts and Telecommunications",
      "keywords": "affiliation",
      "description": "Zeyi Liu affiliated with Beijing University of Posts and Telecommunications"
    },
    {
      "source": "Zeyi Liu",
      "target": "Tsinghua University",
      "keywords": "affiliation",
      "description": "Zeyi Liu affiliated with Tsinghua University"
    },
    {
      "source": "Zeyi Liu",
      "target": "Harbin Institute of Technology (Shenzhen)",
      "keywords": "affiliation",
      "description": "Zeyi Liu affiliated with Harbin Institute of Technology (Shenzhen)"
    },
    {
      "source": "Ziwang Zhao",
      "target": "Beijing Institute of Technology",
      "keywords": "affiliation",
      "description": "Ziwang Zhao affiliated with Beijing Institute of Technology"
    },
    {
      "source": "Ziwang Zhao",
      "target": "Beijing University of Posts and Telecommunications",
      "keywords": "affiliation",
      "description": "Ziwang Zhao affiliated with Beijing University of Posts and Telecommunications"
    },
    {
      "source": "Ziwang Zhao",
      "target": "Tsinghua University",
      "keywords": "affiliation",
      "description": "Ziwang Zhao affiliated with Tsinghua University"
    },
    {
      "source": "Ziwang Zhao",
      "target": "Harbin Institute of Technology (Shenzhen)",
      "keywords": "affiliation",
      "description": "Ziwang Zhao affiliated with Harbin Institute of Technology (Shenzhen)"
    },
    {
      "source": "Lei Hou",
      "target": "Beijing Institute of Technology",
      "keywords": "affiliation",
      "description": "Lei Hou affiliated with Beijing Institute of Technology"
    },
    {
      "source": "Lei Hou",
      "target": "Beijing University of Posts and Telecommunications",
      "keywords": "affiliation",
      "description": "Lei Hou affiliated with Beijing University of Posts and Telecommunications"
    },
    {
      "source": "Lei Hou",
      "target": "Tsinghua University",
      "keywords": "affiliation",
      "description": "Lei Hou affiliated with Tsinghua University"
    },
    {
      "source": "Lei Hou",
      "target": "Harbin Institute of Technology (Shenzhen)",
      "keywords": "affiliation",
      "description": "Lei Hou affiliated with Harbin Institute of Technology (Shenzhen)"
    },
    {
      "source": "Liqiang Nie",
      "target": "Beijing Institute of Technology",
      "keywords": "affiliation",
      "description": "Liqiang Nie affiliated with Beijing Institute of Technology"
    },
    {
      "source": "Liqiang Nie",
      "target": "Beijing University of Posts and Telecommunications",
      "keywords": "affiliation",
      "description": "Liqiang Nie affiliated with Beijing University of Posts and Telecommunications"
    },
    {
      "source": "Liqiang Nie",
      "target": "Tsinghua University",
      "keywords": "affiliation",
      "description": "Liqiang Nie affiliated with Tsinghua University"
    },
    {
      "source": "Liqiang Nie",
      "target": "Harbin Institute of Technology (Shenzhen)",
      "keywords": "affiliation",
      "description": "Liqiang Nie affiliated with Harbin Institute of Technology (Shenzhen)"
    },
    {
      "source": "Juanzi Li",
      "target": "Beijing Institute of Technology",
      "keywords": "affiliation",
      "description": "Juanzi Li affiliated with Beijing Institute of Technology"
    },
    {
      "source": "Juanzi Li",
      "target": "Beijing University of Posts and Telecommunications",
      "keywords": "affiliation",
      "description": "Juanzi Li affiliated with Beijing University of Posts and Telecommunications"
    },
    {
      "source": "Juanzi Li",
      "target": "Tsinghua University",
      "keywords": "affiliation",
      "description": "Juanzi Li affiliated with Tsinghua University"
    },
    {
      "source": "Juanzi Li",
      "target": "Harbin Institute of Technology (Shenzhen)",
      "keywords": "affiliation",
      "description": "Juanzi Li affiliated with Harbin Institute of Technology (Shenzhen)"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "REALM",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses REALM"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "BERT",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses BERT"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "GPT",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses GPT"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "T5",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses T5"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "BART",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses BART"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses Natural Questions"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "WikiText",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses WikiText"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "Wikipedia",
      "keywords": "uses",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models uses Wikipedia"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "HierarchicalRAG",
      "keywords": "proposes",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models proposes HierarchicalRAG"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models proposes HybridRetrieval"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models proposes HybridGeneration"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models proposes JointTraining"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "QA",
      "keywords": "applies_to",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models applies to QA"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models applies to DocumentSummarization"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models applies to ConversationalAI"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models applies to MedicalRAG"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models applies to LegalRAG"
    },
    {
      "source": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "A Survey of Knowledge-Enhanced Pre-trained Language Models applies to EducationalRAG"
    },
    {
      "source": "REALM",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "REALM potentially trained on Natural Questions"
    },
    {
      "source": "REALM",
      "target": "WikiText",
      "keywords": "trained_on",
      "description": "REALM potentially trained on WikiText"
    },
    {
      "source": "REALM",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "REALM potentially trained on Wikipedia"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "BERT",
      "target": "WikiText",
      "keywords": "trained_on",
      "description": "BERT potentially trained on WikiText"
    },
    {
      "source": "BERT",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Wikipedia"
    },
    {
      "source": "GPT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT potentially trained on Natural Questions"
    },
    {
      "source": "GPT",
      "target": "WikiText",
      "keywords": "trained_on",
      "description": "GPT potentially trained on WikiText"
    },
    {
      "source": "GPT",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "GPT potentially trained on Wikipedia"
    },
    {
      "source": "T5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions"
    },
    {
      "source": "T5",
      "target": "WikiText",
      "keywords": "trained_on",
      "description": "T5 potentially trained on WikiText"
    },
    {
      "source": "T5",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Wikipedia"
    },
    {
      "source": "BART",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions"
    },
    {
      "source": "BART",
      "target": "WikiText",
      "keywords": "trained_on",
      "description": "BART potentially trained on WikiText"
    },
    {
      "source": "BART",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "BART potentially trained on Wikipedia"
    },
    {
      "source": "HierarchicalRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "HierarchicalRAG supports QA"
    },
    {
      "source": "HierarchicalRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HierarchicalRAG supports DocumentSummarization"
    },
    {
      "source": "HierarchicalRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HierarchicalRAG supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Shangqing Liu",
      "target": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "keywords": "authorship",
      "description": "Shangqing Liu authored Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "source": "Yu Chen",
      "target": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "keywords": "authorship",
      "description": "Yu Chen authored Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "source": "Xiaofei Xie",
      "target": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "keywords": "authorship",
      "description": "Xiaofei Xie authored Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "source": "Jingkai Siow",
      "target": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "keywords": "authorship",
      "description": "Jingkai Siow authored Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "source": "Yang Liu",
      "target": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "keywords": "authorship",
      "description": "Yang Liu authored Retrieval-Augmented Generation for Code Summarization via Hybrid GNN"
    },
    {
      "source": "Shangqing Liu",
      "target": "Nanyang Technology University",
      "keywords": "affiliation",
      "description": "Shangqing Liu affiliated with Nanyang Technology University"
    },
    {
      "source": "Shangqing Liu",
      "target": "Rensselaer Polytechnic Institute",
      "keywords": "affiliation",
      "description": "Shangqing Liu affiliated with Rensselaer Polytechnic Institute"
    },
    {
      "source": "Yu Chen",
      "target": "Nanyang Technology University",
      "keywords": "affiliation",
      "description": "Yu Chen affiliated with Nanyang Technology University"
    },
    {
      "source": "Yu Chen",
      "target": "Rensselaer Polytechnic Institute",
      "keywords": "affiliation",
      "description": "Yu Chen affiliated with Rensselaer Polytechnic Institute"
    },
    {
      "source": "Xiaofei Xie",
      "target": "Nanyang Technology University",
      "keywords": "affiliation",
      "description": "Xiaofei Xie affiliated with Nanyang Technology University"
    },
    {
      "source": "Xiaofei Xie",
      "target": "Rensselaer Polytechnic Institute",
      "keywords": "affiliation",
      "description": "Xiaofei Xie affiliated with Rensselaer Polytechnic Institute"
    },
    {
      "source": "Jingkai Siow",
      "target": "Nanyang Technology University",
      "keywords": "affiliation",
      "description": "Jingkai Siow affiliated with Nanyang Technology University"
    },
    {
      "source": "Jingkai Siow",
      "target": "Rensselaer Polytechnic Institute",
      "keywords": "affiliation",
      "description": "Jingkai Siow affiliated with Rensselaer Polytechnic Institute"
    },
    {
      "source": "Yang Liu",
      "target": "Nanyang Technology University",
      "keywords": "affiliation",
      "description": "Yang Liu affiliated with Nanyang Technology University"
    },
    {
      "source": "Yang Liu",
      "target": "Rensselaer Polytechnic Institute",
      "keywords": "affiliation",
      "description": "Yang Liu affiliated with Rensselaer Polytechnic Institute"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "BiLSTM",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN uses BiLSTM"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "Lucene",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN uses Lucene"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "LSTM Decoder",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN uses LSTM Decoder"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "Hybrid GNN (HGNN)",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN uses Hybrid GNN (HGNN)"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "C Code Summarization Dataset (CCSD)",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN uses C Code Summarization Dataset (CCSD)"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "Python Code Summarization Dataset (PCSD)",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN uses Python Code Summarization Dataset (PCSD)"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "HierarchicalRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN proposes HierarchicalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN proposes HybridRetrieval"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN proposes HybridGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN proposes JointTraining"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN applies to DocumentSummarization"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "Code Summarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN applies to Code Summarization"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "Software Engineering",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN applies to Software Engineering"
    },
    {
      "source": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN",
      "target": "Program Comprehension",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN applies to Program Comprehension"
    },
    {
      "source": "BiLSTM",
      "target": "C Code Summarization Dataset (CCSD)",
      "keywords": "trained_on",
      "description": "BiLSTM potentially trained on C Code Summarization Dataset (CCSD)"
    },
    {
      "source": "BiLSTM",
      "target": "Python Code Summarization Dataset (PCSD)",
      "keywords": "trained_on",
      "description": "BiLSTM potentially trained on Python Code Summarization Dataset (PCSD)"
    },
    {
      "source": "Lucene",
      "target": "C Code Summarization Dataset (CCSD)",
      "keywords": "trained_on",
      "description": "Lucene potentially trained on C Code Summarization Dataset (CCSD)"
    },
    {
      "source": "Lucene",
      "target": "Python Code Summarization Dataset (PCSD)",
      "keywords": "trained_on",
      "description": "Lucene potentially trained on Python Code Summarization Dataset (PCSD)"
    },
    {
      "source": "LSTM Decoder",
      "target": "C Code Summarization Dataset (CCSD)",
      "keywords": "trained_on",
      "description": "LSTM Decoder potentially trained on C Code Summarization Dataset (CCSD)"
    },
    {
      "source": "LSTM Decoder",
      "target": "Python Code Summarization Dataset (PCSD)",
      "keywords": "trained_on",
      "description": "LSTM Decoder potentially trained on Python Code Summarization Dataset (PCSD)"
    },
    {
      "source": "Hybrid GNN (HGNN)",
      "target": "C Code Summarization Dataset (CCSD)",
      "keywords": "trained_on",
      "description": "Hybrid GNN (HGNN) potentially trained on C Code Summarization Dataset (CCSD)"
    },
    {
      "source": "Hybrid GNN (HGNN)",
      "target": "Python Code Summarization Dataset (PCSD)",
      "keywords": "trained_on",
      "description": "Hybrid GNN (HGNN) potentially trained on Python Code Summarization Dataset (PCSD)"
    },
    {
      "source": "HierarchicalRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HierarchicalRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "Andrea Madotto",
      "target": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "keywords": "authorship",
      "description": "Andrea Madotto authored Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "source": "Zhaojiang Lin",
      "target": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "keywords": "authorship",
      "description": "Zhaojiang Lin authored Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "source": "Genta Indra Winata",
      "target": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "keywords": "authorship",
      "description": "Genta Indra Winata authored Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "source": "Pascale Fung",
      "target": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "keywords": "authorship",
      "description": "Pascale Fung authored Few-Shot Bot: Prompt-Based Learning for Dialogue Systems"
    },
    {
      "source": "Andrea Madotto",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Andrea Madotto affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Zhaojiang Lin",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Zhaojiang Lin affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Genta Indra Winata",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Genta Indra Winata affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Pascale Fung",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Pascale Fung affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "DPR (Dense Passage Retriever)",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses DPR (Dense Passage Retriever)"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "TF-IDF",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses TF-IDF"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "GPT-2",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses GPT-2"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "GPT-NEO",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses GPT-NEO"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "GPT-J",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses GPT-J"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "GPT-Jurassic",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses GPT-Jurassic"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "Wizard of Internet (WiT)",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses Wizard of Internet (WiT)"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "PersonaChat",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses PersonaChat"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses Multi-Session Chat (MSC)"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "DialKG",
      "keywords": "uses",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems uses DialKG"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems proposes PipelineRAG"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems proposes HybridRetrieval"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems proposes AbstractiveGeneration"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "No training required",
      "keywords": "proposes",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems proposes No training required"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems applies to QA"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems applies to ConversationalAI"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems applies to DocumentSummarization"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "open-domain chat",
      "keywords": "applies_to",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems applies to open-domain chat"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "task-oriented dialogue",
      "keywords": "applies_to",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems applies to task-oriented dialogue"
    },
    {
      "source": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems",
      "target": "knowledge-grounded conversation",
      "keywords": "applies_to",
      "description": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems applies to knowledge-grounded conversation"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "Wizard of Internet (WiT)",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on Wizard of Internet (WiT)"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "PersonaChat",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on PersonaChat"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on Multi-Session Chat (MSC)"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "DialKG",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on DialKG"
    },
    {
      "source": "TF-IDF",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "TF-IDF",
      "target": "Wizard of Internet (WiT)",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on Wizard of Internet (WiT)"
    },
    {
      "source": "TF-IDF",
      "target": "PersonaChat",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on PersonaChat"
    },
    {
      "source": "TF-IDF",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on Multi-Session Chat (MSC)"
    },
    {
      "source": "TF-IDF",
      "target": "DialKG",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on DialKG"
    },
    {
      "source": "GPT-2",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "GPT-2",
      "target": "Wizard of Internet (WiT)",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Wizard of Internet (WiT)"
    },
    {
      "source": "GPT-2",
      "target": "PersonaChat",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on PersonaChat"
    },
    {
      "source": "GPT-2",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Multi-Session Chat (MSC)"
    },
    {
      "source": "GPT-2",
      "target": "DialKG",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on DialKG"
    },
    {
      "source": "GPT-NEO",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-NEO potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "GPT-NEO",
      "target": "Wizard of Internet (WiT)",
      "keywords": "trained_on",
      "description": "GPT-NEO potentially trained on Wizard of Internet (WiT)"
    },
    {
      "source": "GPT-NEO",
      "target": "PersonaChat",
      "keywords": "trained_on",
      "description": "GPT-NEO potentially trained on PersonaChat"
    },
    {
      "source": "GPT-NEO",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "trained_on",
      "description": "GPT-NEO potentially trained on Multi-Session Chat (MSC)"
    },
    {
      "source": "GPT-NEO",
      "target": "DialKG",
      "keywords": "trained_on",
      "description": "GPT-NEO potentially trained on DialKG"
    },
    {
      "source": "GPT-J",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-J potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "GPT-J",
      "target": "Wizard of Internet (WiT)",
      "keywords": "trained_on",
      "description": "GPT-J potentially trained on Wizard of Internet (WiT)"
    },
    {
      "source": "GPT-J",
      "target": "PersonaChat",
      "keywords": "trained_on",
      "description": "GPT-J potentially trained on PersonaChat"
    },
    {
      "source": "GPT-J",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "trained_on",
      "description": "GPT-J potentially trained on Multi-Session Chat (MSC)"
    },
    {
      "source": "GPT-J",
      "target": "DialKG",
      "keywords": "trained_on",
      "description": "GPT-J potentially trained on DialKG"
    },
    {
      "source": "GPT-Jurassic",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-Jurassic potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "GPT-Jurassic",
      "target": "Wizard of Internet (WiT)",
      "keywords": "trained_on",
      "description": "GPT-Jurassic potentially trained on Wizard of Internet (WiT)"
    },
    {
      "source": "GPT-Jurassic",
      "target": "PersonaChat",
      "keywords": "trained_on",
      "description": "GPT-Jurassic potentially trained on PersonaChat"
    },
    {
      "source": "GPT-Jurassic",
      "target": "Multi-Session Chat (MSC)",
      "keywords": "trained_on",
      "description": "GPT-Jurassic potentially trained on Multi-Session Chat (MSC)"
    },
    {
      "source": "GPT-Jurassic",
      "target": "DialKG",
      "keywords": "trained_on",
      "description": "GPT-Jurassic potentially trained on DialKG"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "No training required",
      "target": "QA",
      "keywords": "supports",
      "description": "No training required supports QA"
    },
    {
      "source": "No training required",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "No training required supports ConversationalAI"
    },
    {
      "source": "No training required",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "No training required supports DocumentSummarization"
    },
    {
      "source": "Wenhu Chen",
      "target": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "keywords": "authorship",
      "description": "Wenhu Chen authored Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "source": "Hexiang Hu",
      "target": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "keywords": "authorship",
      "description": "Hexiang Hu authored Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "source": "Chitwan Saharia",
      "target": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "keywords": "authorship",
      "description": "Chitwan Saharia authored Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "source": "William W. Cohen",
      "target": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "keywords": "authorship",
      "description": "William W. Cohen authored Re-Imagen: Retrieval-Augmented Text-to-Image Generator"
    },
    {
      "source": "Wenhu Chen",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Wenhu Chen affiliated with Google Research"
    },
    {
      "source": "Hexiang Hu",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Hexiang Hu affiliated with Google Research"
    },
    {
      "source": "Chitwan Saharia",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Chitwan Saharia affiliated with Google Research"
    },
    {
      "source": "William W. Cohen",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "William W. Cohen affiliated with Google Research"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "BM25",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses BM25"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "CLIP",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses CLIP"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Re-Imagen",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses Re-Imagen"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "T5",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses T5"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "KNN-ImageText",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses KNN-ImageText"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "COCO",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses COCO"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "WikiImages",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses WikiImages"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "EntityDrawBench",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses EntityDrawBench"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "LAION-400M",
      "keywords": "uses",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator uses LAION-400M"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator proposes PipelineRAG"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator proposes DenseRetrieval"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator proposes AbstractiveGeneration"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator proposes JointTraining"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Text-to-image generation",
      "keywords": "applies_to",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator applies to Text-to-image generation"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Rare entity visualization",
      "keywords": "applies_to",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator applies to Rare entity visualization"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Multi-modal content generation",
      "keywords": "applies_to",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator applies to Multi-modal content generation"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Visual content creation",
      "keywords": "applies_to",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator applies to Visual content creation"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Educational visualization",
      "keywords": "applies_to",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator applies to Educational visualization"
    },
    {
      "source": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
      "target": "Cultural artifact generation",
      "keywords": "applies_to",
      "description": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator applies to Cultural artifact generation"
    },
    {
      "source": "BM25",
      "target": "KNN-ImageText",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on KNN-ImageText"
    },
    {
      "source": "BM25",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on COCO"
    },
    {
      "source": "BM25",
      "target": "WikiImages",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on WikiImages"
    },
    {
      "source": "BM25",
      "target": "EntityDrawBench",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on EntityDrawBench"
    },
    {
      "source": "BM25",
      "target": "LAION-400M",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on LAION-400M"
    },
    {
      "source": "CLIP",
      "target": "KNN-ImageText",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on KNN-ImageText"
    },
    {
      "source": "CLIP",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on COCO"
    },
    {
      "source": "CLIP",
      "target": "WikiImages",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on WikiImages"
    },
    {
      "source": "CLIP",
      "target": "EntityDrawBench",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on EntityDrawBench"
    },
    {
      "source": "CLIP",
      "target": "LAION-400M",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on LAION-400M"
    },
    {
      "source": "Re-Imagen",
      "target": "KNN-ImageText",
      "keywords": "trained_on",
      "description": "Re-Imagen potentially trained on KNN-ImageText"
    },
    {
      "source": "Re-Imagen",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "Re-Imagen potentially trained on COCO"
    },
    {
      "source": "Re-Imagen",
      "target": "WikiImages",
      "keywords": "trained_on",
      "description": "Re-Imagen potentially trained on WikiImages"
    },
    {
      "source": "Re-Imagen",
      "target": "EntityDrawBench",
      "keywords": "trained_on",
      "description": "Re-Imagen potentially trained on EntityDrawBench"
    },
    {
      "source": "Re-Imagen",
      "target": "LAION-400M",
      "keywords": "trained_on",
      "description": "Re-Imagen potentially trained on LAION-400M"
    },
    {
      "source": "T5",
      "target": "KNN-ImageText",
      "keywords": "trained_on",
      "description": "T5 potentially trained on KNN-ImageText"
    },
    {
      "source": "T5",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "T5 potentially trained on COCO"
    },
    {
      "source": "T5",
      "target": "WikiImages",
      "keywords": "trained_on",
      "description": "T5 potentially trained on WikiImages"
    },
    {
      "source": "T5",
      "target": "EntityDrawBench",
      "keywords": "trained_on",
      "description": "T5 potentially trained on EntityDrawBench"
    },
    {
      "source": "T5",
      "target": "LAION-400M",
      "keywords": "trained_on",
      "description": "T5 potentially trained on LAION-400M"
    },
    {
      "source": "PipelineRAG",
      "target": "Text-to-image generation",
      "keywords": "supports",
      "description": "PipelineRAG supports Text-to-image generation"
    },
    {
      "source": "PipelineRAG",
      "target": "Rare entity visualization",
      "keywords": "supports",
      "description": "PipelineRAG supports Rare entity visualization"
    },
    {
      "source": "PipelineRAG",
      "target": "Multi-modal content generation",
      "keywords": "supports",
      "description": "PipelineRAG supports Multi-modal content generation"
    },
    {
      "source": "DenseRetrieval",
      "target": "Text-to-image generation",
      "keywords": "supports",
      "description": "DenseRetrieval supports Text-to-image generation"
    },
    {
      "source": "DenseRetrieval",
      "target": "Rare entity visualization",
      "keywords": "supports",
      "description": "DenseRetrieval supports Rare entity visualization"
    },
    {
      "source": "DenseRetrieval",
      "target": "Multi-modal content generation",
      "keywords": "supports",
      "description": "DenseRetrieval supports Multi-modal content generation"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Text-to-image generation",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Text-to-image generation"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Rare entity visualization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Rare entity visualization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Multi-modal content generation",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Multi-modal content generation"
    },
    {
      "source": "JointTraining",
      "target": "Text-to-image generation",
      "keywords": "supports",
      "description": "JointTraining supports Text-to-image generation"
    },
    {
      "source": "JointTraining",
      "target": "Rare entity visualization",
      "keywords": "supports",
      "description": "JointTraining supports Rare entity visualization"
    },
    {
      "source": "JointTraining",
      "target": "Multi-modal content generation",
      "keywords": "supports",
      "description": "JointTraining supports Multi-modal content generation"
    },
    {
      "source": "Penghao Zhao",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Penghao Zhao authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Hailin Zhang",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Hailin Zhang authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Qinhan Yu",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Qinhan Yu authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Zhengren Wang",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Zhengren Wang authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Yunteng Geng",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Yunteng Geng authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Fangcheng Fu",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Fangcheng Fu authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Ling Yang",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Ling Yang authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Wentao Zhang",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Wentao Zhang authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Jie Jiang",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Jie Jiang authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Bin Cui",
      "target": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "keywords": "authorship",
      "description": "Bin Cui authored Retrieval-Augmented Generation for AI-Generated Content: A Survey"
    },
    {
      "source": "Penghao Zhao",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Penghao Zhao affiliated with Peking University"
    },
    {
      "source": "Hailin Zhang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Hailin Zhang affiliated with Peking University"
    },
    {
      "source": "Qinhan Yu",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Qinhan Yu affiliated with Peking University"
    },
    {
      "source": "Zhengren Wang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Zhengren Wang affiliated with Peking University"
    },
    {
      "source": "Yunteng Geng",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Yunteng Geng affiliated with Peking University"
    },
    {
      "source": "Fangcheng Fu",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Fangcheng Fu affiliated with Peking University"
    },
    {
      "source": "Ling Yang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Ling Yang affiliated with Peking University"
    },
    {
      "source": "Wentao Zhang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Wentao Zhang affiliated with Peking University"
    },
    {
      "source": "Jie Jiang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Jie Jiang affiliated with Peking University"
    },
    {
      "source": "Bin Cui",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Bin Cui affiliated with Peking University"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "BERT",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses BERT"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "CLIP",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses CLIP"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "DPR",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses DPR"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "GPT series",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses GPT series"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "LLAMA series",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses LLAMA series"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "BART",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses BART"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "T5",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses T5"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "Stable Diffusion",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses Stable Diffusion"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses Natural Questions"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses MS-MARCO"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "BEIR",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey uses BEIR"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey proposes PipelineRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey proposes HybridRetrieval"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey proposes SeparateTraining"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to QA"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to DocumentSummarization"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to ConversationalAI"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "CodeGeneration",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to CodeGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "ImageCaptioning",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to ImageCaptioning"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "VideoQA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to VideoQA"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "AudioGeneration",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to AudioGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to MedicalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to LegalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to EducationalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for AI-Generated Content: A Survey",
      "target": "ScientificRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for AI-Generated Content: A Survey applies to ScientificRAG"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "BERT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MS-MARCO"
    },
    {
      "source": "BERT",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BERT potentially trained on BEIR"
    },
    {
      "source": "CLIP",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on Natural Questions"
    },
    {
      "source": "CLIP",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on MS-MARCO"
    },
    {
      "source": "CLIP",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on BEIR"
    },
    {
      "source": "DPR",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "DPR potentially trained on Natural Questions"
    },
    {
      "source": "DPR",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "DPR potentially trained on MS-MARCO"
    },
    {
      "source": "DPR",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "DPR potentially trained on BEIR"
    },
    {
      "source": "GPT series",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT series potentially trained on Natural Questions"
    },
    {
      "source": "GPT series",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "GPT series potentially trained on MS-MARCO"
    },
    {
      "source": "GPT series",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "GPT series potentially trained on BEIR"
    },
    {
      "source": "LLAMA series",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "LLAMA series potentially trained on Natural Questions"
    },
    {
      "source": "LLAMA series",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "LLAMA series potentially trained on MS-MARCO"
    },
    {
      "source": "LLAMA series",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "LLAMA series potentially trained on BEIR"
    },
    {
      "source": "BART",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions"
    },
    {
      "source": "BART",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BART potentially trained on MS-MARCO"
    },
    {
      "source": "BART",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BART potentially trained on BEIR"
    },
    {
      "source": "T5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions"
    },
    {
      "source": "T5",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "T5 potentially trained on MS-MARCO"
    },
    {
      "source": "T5",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "T5 potentially trained on BEIR"
    },
    {
      "source": "Stable Diffusion",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Stable Diffusion potentially trained on Natural Questions"
    },
    {
      "source": "Stable Diffusion",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Stable Diffusion potentially trained on MS-MARCO"
    },
    {
      "source": "Stable Diffusion",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Stable Diffusion potentially trained on BEIR"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "PipelineRAG",
      "target": "CodeGeneration",
      "keywords": "supports",
      "description": "PipelineRAG supports CodeGeneration"
    },
    {
      "source": "PipelineRAG",
      "target": "ImageCaptioning",
      "keywords": "supports",
      "description": "PipelineRAG supports ImageCaptioning"
    },
    {
      "source": "PipelineRAG",
      "target": "VideoQA",
      "keywords": "supports",
      "description": "PipelineRAG supports VideoQA"
    },
    {
      "source": "PipelineRAG",
      "target": "AudioGeneration",
      "keywords": "supports",
      "description": "PipelineRAG supports AudioGeneration"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "CodeGeneration",
      "keywords": "supports",
      "description": "HybridRetrieval supports CodeGeneration"
    },
    {
      "source": "HybridRetrieval",
      "target": "ImageCaptioning",
      "keywords": "supports",
      "description": "HybridRetrieval supports ImageCaptioning"
    },
    {
      "source": "HybridRetrieval",
      "target": "VideoQA",
      "keywords": "supports",
      "description": "HybridRetrieval supports VideoQA"
    },
    {
      "source": "HybridRetrieval",
      "target": "AudioGeneration",
      "keywords": "supports",
      "description": "HybridRetrieval supports AudioGeneration"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "CodeGeneration",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports CodeGeneration"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ImageCaptioning",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ImageCaptioning"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "VideoQA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports VideoQA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "AudioGeneration",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports AudioGeneration"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "CodeGeneration",
      "keywords": "supports",
      "description": "SeparateTraining supports CodeGeneration"
    },
    {
      "source": "SeparateTraining",
      "target": "ImageCaptioning",
      "keywords": "supports",
      "description": "SeparateTraining supports ImageCaptioning"
    },
    {
      "source": "SeparateTraining",
      "target": "VideoQA",
      "keywords": "supports",
      "description": "SeparateTraining supports VideoQA"
    },
    {
      "source": "SeparateTraining",
      "target": "AudioGeneration",
      "keywords": "supports",
      "description": "SeparateTraining supports AudioGeneration"
    },
    {
      "source": "Shishir G. Patil",
      "target": "Gorilla: Large Language Model Connected with Massive APIs",
      "keywords": "authorship",
      "description": "Shishir G. Patil authored Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "source": "Tianjun Zhang",
      "target": "Gorilla: Large Language Model Connected with Massive APIs",
      "keywords": "authorship",
      "description": "Tianjun Zhang authored Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "source": "Xin Wang",
      "target": "Gorilla: Large Language Model Connected with Massive APIs",
      "keywords": "authorship",
      "description": "Xin Wang authored Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "source": "Joseph E. Gonzalez",
      "target": "Gorilla: Large Language Model Connected with Massive APIs",
      "keywords": "authorship",
      "description": "Joseph E. Gonzalez authored Gorilla: Large Language Model Connected with Massive APIs"
    },
    {
      "source": "Shishir G. Patil",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Shishir G. Patil affiliated with UC Berkeley"
    },
    {
      "source": "Shishir G. Patil",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Shishir G. Patil affiliated with Microsoft Research"
    },
    {
      "source": "Tianjun Zhang",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Tianjun Zhang affiliated with UC Berkeley"
    },
    {
      "source": "Tianjun Zhang",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Tianjun Zhang affiliated with Microsoft Research"
    },
    {
      "source": "Xin Wang",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Xin Wang affiliated with UC Berkeley"
    },
    {
      "source": "Xin Wang",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Xin Wang affiliated with Microsoft Research"
    },
    {
      "source": "Joseph E. Gonzalez",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Joseph E. Gonzalez affiliated with UC Berkeley"
    },
    {
      "source": "Joseph E. Gonzalez",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Joseph E. Gonzalez affiliated with Microsoft Research"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "BM25",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses BM25"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "GPT-Index",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses GPT-Index"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "Gorilla",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses Gorilla"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "LLaMA-7B",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses LLaMA-7B"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses GPT-4"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "GPT-3.5-turbo",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses GPT-3.5-turbo"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "Claude",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses Claude"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "APIBench",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses APIBench"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "HuggingFace APIs",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses HuggingFace APIs"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "TorchHub APIs",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses TorchHub APIs"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "TensorHub APIs",
      "keywords": "uses",
      "description": "Gorilla: Large Language Model Connected with Massive APIs uses TensorHub APIs"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Gorilla: Large Language Model Connected with Massive APIs proposes PipelineRAG"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Gorilla: Large Language Model Connected with Massive APIs proposes HybridRetrieval"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Gorilla: Large Language Model Connected with Massive APIs proposes AbstractiveGeneration"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Gorilla: Large Language Model Connected with Massive APIs proposes FinetuningStrategy"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Gorilla: Large Language Model Connected with Massive APIs applies to QA"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "API call generation",
      "keywords": "applies_to",
      "description": "Gorilla: Large Language Model Connected with Massive APIs applies to API call generation"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "Tool usage",
      "keywords": "applies_to",
      "description": "Gorilla: Large Language Model Connected with Massive APIs applies to Tool usage"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "Machine Learning model deployment",
      "keywords": "applies_to",
      "description": "Gorilla: Large Language Model Connected with Massive APIs applies to Machine Learning model deployment"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "API integration",
      "keywords": "applies_to",
      "description": "Gorilla: Large Language Model Connected with Massive APIs applies to API integration"
    },
    {
      "source": "Gorilla: Large Language Model Connected with Massive APIs",
      "target": "Tool-augmented LLMs",
      "keywords": "applies_to",
      "description": "Gorilla: Large Language Model Connected with Massive APIs applies to Tool-augmented LLMs"
    },
    {
      "source": "BM25",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on APIBench"
    },
    {
      "source": "BM25",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on HuggingFace APIs"
    },
    {
      "source": "BM25",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TorchHub APIs"
    },
    {
      "source": "BM25",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TensorHub APIs"
    },
    {
      "source": "GPT-Index",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "GPT-Index potentially trained on APIBench"
    },
    {
      "source": "GPT-Index",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "GPT-Index potentially trained on HuggingFace APIs"
    },
    {
      "source": "GPT-Index",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "GPT-Index potentially trained on TorchHub APIs"
    },
    {
      "source": "GPT-Index",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "GPT-Index potentially trained on TensorHub APIs"
    },
    {
      "source": "Gorilla",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "Gorilla potentially trained on APIBench"
    },
    {
      "source": "Gorilla",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "Gorilla potentially trained on HuggingFace APIs"
    },
    {
      "source": "Gorilla",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "Gorilla potentially trained on TorchHub APIs"
    },
    {
      "source": "Gorilla",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "Gorilla potentially trained on TensorHub APIs"
    },
    {
      "source": "LLaMA-7B",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on APIBench"
    },
    {
      "source": "LLaMA-7B",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on HuggingFace APIs"
    },
    {
      "source": "LLaMA-7B",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on TorchHub APIs"
    },
    {
      "source": "LLaMA-7B",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on TensorHub APIs"
    },
    {
      "source": "GPT-4",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on APIBench"
    },
    {
      "source": "GPT-4",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on HuggingFace APIs"
    },
    {
      "source": "GPT-4",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on TorchHub APIs"
    },
    {
      "source": "GPT-4",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on TensorHub APIs"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on APIBench"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on HuggingFace APIs"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on TorchHub APIs"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on TensorHub APIs"
    },
    {
      "source": "Claude",
      "target": "APIBench",
      "keywords": "trained_on",
      "description": "Claude potentially trained on APIBench"
    },
    {
      "source": "Claude",
      "target": "HuggingFace APIs",
      "keywords": "trained_on",
      "description": "Claude potentially trained on HuggingFace APIs"
    },
    {
      "source": "Claude",
      "target": "TorchHub APIs",
      "keywords": "trained_on",
      "description": "Claude potentially trained on TorchHub APIs"
    },
    {
      "source": "Claude",
      "target": "TensorHub APIs",
      "keywords": "trained_on",
      "description": "Claude potentially trained on TensorHub APIs"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "API call generation",
      "keywords": "supports",
      "description": "PipelineRAG supports API call generation"
    },
    {
      "source": "PipelineRAG",
      "target": "Tool usage",
      "keywords": "supports",
      "description": "PipelineRAG supports Tool usage"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "API call generation",
      "keywords": "supports",
      "description": "HybridRetrieval supports API call generation"
    },
    {
      "source": "HybridRetrieval",
      "target": "Tool usage",
      "keywords": "supports",
      "description": "HybridRetrieval supports Tool usage"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "API call generation",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports API call generation"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Tool usage",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Tool usage"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "API call generation",
      "keywords": "supports",
      "description": "FinetuningStrategy supports API call generation"
    },
    {
      "source": "FinetuningStrategy",
      "target": "Tool usage",
      "keywords": "supports",
      "description": "FinetuningStrategy supports Tool usage"
    },
    {
      "source": "Tianjun Zhang",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Tianjun Zhang authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Shishir G. Patil",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Shishir G. Patil authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Naman Jain",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Naman Jain authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Sheng Shen",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Sheng Shen authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Matei Zaharia",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Matei Zaharia authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Ion Stoica",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Ion Stoica authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Joseph E. Gonzalez",
      "target": "RAFT: Adapting Language Model to Domain Specific RAG",
      "keywords": "authorship",
      "description": "Joseph E. Gonzalez authored RAFT: Adapting Language Model to Domain Specific RAG"
    },
    {
      "source": "Tianjun Zhang",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Tianjun Zhang affiliated with UC Berkeley"
    },
    {
      "source": "Shishir G. Patil",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Shishir G. Patil affiliated with UC Berkeley"
    },
    {
      "source": "Naman Jain",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Naman Jain affiliated with UC Berkeley"
    },
    {
      "source": "Sheng Shen",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Sheng Shen affiliated with UC Berkeley"
    },
    {
      "source": "Matei Zaharia",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Matei Zaharia affiliated with UC Berkeley"
    },
    {
      "source": "Ion Stoica",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Ion Stoica affiliated with UC Berkeley"
    },
    {
      "source": "Joseph E. Gonzalez",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Joseph E. Gonzalez affiliated with UC Berkeley"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "Standard retriever",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses Standard retriever"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "LLaMA2-7B",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses LLaMA2-7B"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "RAFT (LLaMA2-7B)",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses RAFT (LLaMA2-7B)"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "GPT-3.5",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses GPT-3.5"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "GPT-4-1106",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses GPT-4-1106"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "PubMed QA",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses PubMed QA"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "HotpotQA",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses HotpotQA"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "Gorilla APIBench",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses Gorilla APIBench"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses Natural Questions"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG uses TriviaQA"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG proposes PipelineRAG"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG proposes DenseRetrieval"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG proposes AbstractiveGeneration"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG proposes FinetuningStrategy"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "QA",
      "keywords": "applies_to",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG applies to QA"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG applies to DocumentSummarization"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG applies to MedicalRAG"
    },
    {
      "source": "RAFT: Adapting Language Model to Domain Specific RAG",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "RAFT: Adapting Language Model to Domain Specific RAG applies to EducationalRAG"
    },
    {
      "source": "Standard retriever",
      "target": "PubMed QA",
      "keywords": "trained_on",
      "description": "Standard retriever potentially trained on PubMed QA"
    },
    {
      "source": "Standard retriever",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "Standard retriever potentially trained on HotpotQA"
    },
    {
      "source": "Standard retriever",
      "target": "Gorilla APIBench",
      "keywords": "trained_on",
      "description": "Standard retriever potentially trained on Gorilla APIBench"
    },
    {
      "source": "Standard retriever",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Standard retriever potentially trained on Natural Questions"
    },
    {
      "source": "Standard retriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Standard retriever potentially trained on TriviaQA"
    },
    {
      "source": "LLaMA2-7B",
      "target": "PubMed QA",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on PubMed QA"
    },
    {
      "source": "LLaMA2-7B",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on HotpotQA"
    },
    {
      "source": "LLaMA2-7B",
      "target": "Gorilla APIBench",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on Gorilla APIBench"
    },
    {
      "source": "LLaMA2-7B",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on Natural Questions"
    },
    {
      "source": "LLaMA2-7B",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on TriviaQA"
    },
    {
      "source": "RAFT (LLaMA2-7B)",
      "target": "PubMed QA",
      "keywords": "trained_on",
      "description": "RAFT (LLaMA2-7B) potentially trained on PubMed QA"
    },
    {
      "source": "RAFT (LLaMA2-7B)",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "RAFT (LLaMA2-7B) potentially trained on HotpotQA"
    },
    {
      "source": "RAFT (LLaMA2-7B)",
      "target": "Gorilla APIBench",
      "keywords": "trained_on",
      "description": "RAFT (LLaMA2-7B) potentially trained on Gorilla APIBench"
    },
    {
      "source": "RAFT (LLaMA2-7B)",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "RAFT (LLaMA2-7B) potentially trained on Natural Questions"
    },
    {
      "source": "RAFT (LLaMA2-7B)",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "RAFT (LLaMA2-7B) potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3.5",
      "target": "PubMed QA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on PubMed QA"
    },
    {
      "source": "GPT-3.5",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on HotpotQA"
    },
    {
      "source": "GPT-3.5",
      "target": "Gorilla APIBench",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on Gorilla APIBench"
    },
    {
      "source": "GPT-3.5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-3.5",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-4-1106",
      "target": "PubMed QA",
      "keywords": "trained_on",
      "description": "GPT-4-1106 potentially trained on PubMed QA"
    },
    {
      "source": "GPT-4-1106",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "GPT-4-1106 potentially trained on HotpotQA"
    },
    {
      "source": "GPT-4-1106",
      "target": "Gorilla APIBench",
      "keywords": "trained_on",
      "description": "GPT-4-1106 potentially trained on Gorilla APIBench"
    },
    {
      "source": "GPT-4-1106",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-4-1106 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-4-1106",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-4-1106 potentially trained on TriviaQA"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "Wenhao Yu",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Wenhao Yu authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Dan Iter",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Dan Iter authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Shuohang Wang",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Shuohang Wang authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Yichong Xu",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Yichong Xu authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Mingxuan Ju",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Mingxuan Ju authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Soumya Sanyal",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Soumya Sanyal authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Chenguang Zhu",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Chenguang Zhu authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Michael Zeng",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Michael Zeng authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Meng Jiang",
      "target": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "keywords": "authorship",
      "description": "Meng Jiang authored Generate rather than Retrieve: Large Language Models are Strong Context Generators"
    },
    {
      "source": "Wenhao Yu",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Wenhao Yu affiliated with University of Notre Dame"
    },
    {
      "source": "Wenhao Yu",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Wenhao Yu affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Wenhao Yu",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Wenhao Yu affiliated with University of Southern California"
    },
    {
      "source": "Dan Iter",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Dan Iter affiliated with University of Notre Dame"
    },
    {
      "source": "Dan Iter",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Dan Iter affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Dan Iter",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Dan Iter affiliated with University of Southern California"
    },
    {
      "source": "Shuohang Wang",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Shuohang Wang affiliated with University of Notre Dame"
    },
    {
      "source": "Shuohang Wang",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Shuohang Wang affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Shuohang Wang",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Shuohang Wang affiliated with University of Southern California"
    },
    {
      "source": "Yichong Xu",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Yichong Xu affiliated with University of Notre Dame"
    },
    {
      "source": "Yichong Xu",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Yichong Xu affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Yichong Xu",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Yichong Xu affiliated with University of Southern California"
    },
    {
      "source": "Mingxuan Ju",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Mingxuan Ju affiliated with University of Notre Dame"
    },
    {
      "source": "Mingxuan Ju",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Mingxuan Ju affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Mingxuan Ju",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Mingxuan Ju affiliated with University of Southern California"
    },
    {
      "source": "Soumya Sanyal",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Soumya Sanyal affiliated with University of Notre Dame"
    },
    {
      "source": "Soumya Sanyal",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Soumya Sanyal affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Soumya Sanyal",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Soumya Sanyal affiliated with University of Southern California"
    },
    {
      "source": "Chenguang Zhu",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Chenguang Zhu affiliated with University of Notre Dame"
    },
    {
      "source": "Chenguang Zhu",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Chenguang Zhu affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Chenguang Zhu",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Chenguang Zhu affiliated with University of Southern California"
    },
    {
      "source": "Michael Zeng",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Michael Zeng affiliated with University of Notre Dame"
    },
    {
      "source": "Michael Zeng",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Michael Zeng affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Michael Zeng",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Michael Zeng affiliated with University of Southern California"
    },
    {
      "source": "Meng Jiang",
      "target": "University of Notre Dame",
      "keywords": "affiliation",
      "description": "Meng Jiang affiliated with University of Notre Dame"
    },
    {
      "source": "Meng Jiang",
      "target": "Microsoft Cognitive Service Research",
      "keywords": "affiliation",
      "description": "Meng Jiang affiliated with Microsoft Cognitive Service Research"
    },
    {
      "source": "Meng Jiang",
      "target": "University of Southern California",
      "keywords": "affiliation",
      "description": "Meng Jiang affiliated with University of Southern California"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "DPR",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses DPR"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "BM25",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses BM25"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "Contriever",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses Contriever"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "InstructGPT",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses InstructGPT"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses GPT-3"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "FiD",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses FiD"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses Natural Questions (NQ)"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses TriviaQA"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "WebQuestions (WebQ)",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses WebQuestions (WebQ)"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "FEVER",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses FEVER"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "uses",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators uses Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators proposes PipelineRAG"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators proposes DenseRetrieval"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators proposes AbstractiveGeneration"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators proposes SeparateTraining"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators applies to QA"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators applies to DocumentSummarization"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators applies to ConversationalAI"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "Open-domain question answering",
      "keywords": "applies_to",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators applies to Open-domain question answering"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "Fact checking",
      "keywords": "applies_to",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators applies to Fact checking"
    },
    {
      "source": "Generate rather than Retrieve: Large Language Models are Strong Context Generators",
      "target": "Knowledge-intensive dialogue systems",
      "keywords": "applies_to",
      "description": "Generate rather than Retrieve: Large Language Models are Strong Context Generators applies to Knowledge-intensive dialogue systems"
    },
    {
      "source": "DPR",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "DPR potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "DPR",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "DPR potentially trained on TriviaQA"
    },
    {
      "source": "DPR",
      "target": "WebQuestions (WebQ)",
      "keywords": "trained_on",
      "description": "DPR potentially trained on WebQuestions (WebQ)"
    },
    {
      "source": "DPR",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "DPR potentially trained on FEVER"
    },
    {
      "source": "DPR",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "DPR potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "BM25",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BM25",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TriviaQA"
    },
    {
      "source": "BM25",
      "target": "WebQuestions (WebQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on WebQuestions (WebQ)"
    },
    {
      "source": "BM25",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on FEVER"
    },
    {
      "source": "BM25",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Contriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on TriviaQA"
    },
    {
      "source": "Contriever",
      "target": "WebQuestions (WebQ)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on WebQuestions (WebQ)"
    },
    {
      "source": "Contriever",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on FEVER"
    },
    {
      "source": "Contriever",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "InstructGPT",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "InstructGPT potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "InstructGPT",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "InstructGPT potentially trained on TriviaQA"
    },
    {
      "source": "InstructGPT",
      "target": "WebQuestions (WebQ)",
      "keywords": "trained_on",
      "description": "InstructGPT potentially trained on WebQuestions (WebQ)"
    },
    {
      "source": "InstructGPT",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "InstructGPT potentially trained on FEVER"
    },
    {
      "source": "InstructGPT",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "InstructGPT potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3",
      "target": "WebQuestions (WebQ)",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on WebQuestions (WebQ)"
    },
    {
      "source": "GPT-3",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on FEVER"
    },
    {
      "source": "GPT-3",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "FiD",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "FiD potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "FiD",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "FiD potentially trained on TriviaQA"
    },
    {
      "source": "FiD",
      "target": "WebQuestions (WebQ)",
      "keywords": "trained_on",
      "description": "FiD potentially trained on WebQuestions (WebQ)"
    },
    {
      "source": "FiD",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "FiD potentially trained on FEVER"
    },
    {
      "source": "FiD",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "FiD potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Patrice Béchard",
      "target": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Patrice Béchard authored Reducing hallucination in structured outputs via Retrieval-Augmented Generation"
    },
    {
      "source": "Orlando Marquez Ayala",
      "target": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Orlando Marquez Ayala authored Reducing hallucination in structured outputs via Retrieval-Augmented Generation"
    },
    {
      "source": "Patrice Béchard",
      "target": "ServiceNow",
      "keywords": "affiliation",
      "description": "Patrice Béchard affiliated with ServiceNow"
    },
    {
      "source": "Orlando Marquez Ayala",
      "target": "ServiceNow",
      "keywords": "affiliation",
      "description": "Orlando Marquez Ayala affiliated with ServiceNow"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "all-mpnet-base-v2",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses all-mpnet-base-v2"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "GTR-T5",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses GTR-T5"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "StarCoderBase",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses StarCoderBase"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "CodeLlama-7B",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses CodeLlama-7B"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Mistral-7B-v0.1",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses Mistral-7B-v0.1"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Internal Enterprise Workflows",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses Internal Enterprise Workflows"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Human Eval",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses Human Eval"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Out-of-Domain Splits",
      "keywords": "uses",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation uses Out-of-Domain Splits"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation proposes PipelineRAG"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation proposes DenseRetrieval"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation proposes AbstractiveGeneration"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation proposes SeparateTraining"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Workflow generation",
      "keywords": "applies_to",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation applies to Workflow generation"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Natural language to structured output conversion",
      "keywords": "applies_to",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation applies to Natural language to structured output conversion"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Enterprise automation",
      "keywords": "applies_to",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation applies to Enterprise automation"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "IT workflow management",
      "keywords": "applies_to",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation applies to IT workflow management"
    },
    {
      "source": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
      "target": "Cross-domain enterprise applications (HR, Finance)",
      "keywords": "applies_to",
      "description": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation applies to Cross-domain enterprise applications (HR, Finance)"
    },
    {
      "source": "all-mpnet-base-v2",
      "target": "Internal Enterprise Workflows",
      "keywords": "trained_on",
      "description": "all-mpnet-base-v2 potentially trained on Internal Enterprise Workflows"
    },
    {
      "source": "all-mpnet-base-v2",
      "target": "Human Eval",
      "keywords": "trained_on",
      "description": "all-mpnet-base-v2 potentially trained on Human Eval"
    },
    {
      "source": "all-mpnet-base-v2",
      "target": "Out-of-Domain Splits",
      "keywords": "trained_on",
      "description": "all-mpnet-base-v2 potentially trained on Out-of-Domain Splits"
    },
    {
      "source": "GTR-T5",
      "target": "Internal Enterprise Workflows",
      "keywords": "trained_on",
      "description": "GTR-T5 potentially trained on Internal Enterprise Workflows"
    },
    {
      "source": "GTR-T5",
      "target": "Human Eval",
      "keywords": "trained_on",
      "description": "GTR-T5 potentially trained on Human Eval"
    },
    {
      "source": "GTR-T5",
      "target": "Out-of-Domain Splits",
      "keywords": "trained_on",
      "description": "GTR-T5 potentially trained on Out-of-Domain Splits"
    },
    {
      "source": "StarCoderBase",
      "target": "Internal Enterprise Workflows",
      "keywords": "trained_on",
      "description": "StarCoderBase potentially trained on Internal Enterprise Workflows"
    },
    {
      "source": "StarCoderBase",
      "target": "Human Eval",
      "keywords": "trained_on",
      "description": "StarCoderBase potentially trained on Human Eval"
    },
    {
      "source": "StarCoderBase",
      "target": "Out-of-Domain Splits",
      "keywords": "trained_on",
      "description": "StarCoderBase potentially trained on Out-of-Domain Splits"
    },
    {
      "source": "CodeLlama-7B",
      "target": "Internal Enterprise Workflows",
      "keywords": "trained_on",
      "description": "CodeLlama-7B potentially trained on Internal Enterprise Workflows"
    },
    {
      "source": "CodeLlama-7B",
      "target": "Human Eval",
      "keywords": "trained_on",
      "description": "CodeLlama-7B potentially trained on Human Eval"
    },
    {
      "source": "CodeLlama-7B",
      "target": "Out-of-Domain Splits",
      "keywords": "trained_on",
      "description": "CodeLlama-7B potentially trained on Out-of-Domain Splits"
    },
    {
      "source": "Mistral-7B-v0.1",
      "target": "Internal Enterprise Workflows",
      "keywords": "trained_on",
      "description": "Mistral-7B-v0.1 potentially trained on Internal Enterprise Workflows"
    },
    {
      "source": "Mistral-7B-v0.1",
      "target": "Human Eval",
      "keywords": "trained_on",
      "description": "Mistral-7B-v0.1 potentially trained on Human Eval"
    },
    {
      "source": "Mistral-7B-v0.1",
      "target": "Out-of-Domain Splits",
      "keywords": "trained_on",
      "description": "Mistral-7B-v0.1 potentially trained on Out-of-Domain Splits"
    },
    {
      "source": "PipelineRAG",
      "target": "Workflow generation",
      "keywords": "supports",
      "description": "PipelineRAG supports Workflow generation"
    },
    {
      "source": "PipelineRAG",
      "target": "Natural language to structured output conversion",
      "keywords": "supports",
      "description": "PipelineRAG supports Natural language to structured output conversion"
    },
    {
      "source": "DenseRetrieval",
      "target": "Workflow generation",
      "keywords": "supports",
      "description": "DenseRetrieval supports Workflow generation"
    },
    {
      "source": "DenseRetrieval",
      "target": "Natural language to structured output conversion",
      "keywords": "supports",
      "description": "DenseRetrieval supports Natural language to structured output conversion"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Workflow generation",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Workflow generation"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Natural language to structured output conversion",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Natural language to structured output conversion"
    },
    {
      "source": "SeparateTraining",
      "target": "Workflow generation",
      "keywords": "supports",
      "description": "SeparateTraining supports Workflow generation"
    },
    {
      "source": "SeparateTraining",
      "target": "Natural language to structured output conversion",
      "keywords": "supports",
      "description": "SeparateTraining supports Natural language to structured output conversion"
    },
    {
      "source": "Yan Xu",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Yan Xu authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Etsuko Ishii",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Etsuko Ishii authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Samuel Cahyawijaya",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Samuel Cahyawijaya authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Zihan Liu",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Zihan Liu authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Genta Indra Winata",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Genta Indra Winata authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Andrea Madotto",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Andrea Madotto authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Dan Su",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Dan Su authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Pascale Fung",
      "target": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "keywords": "authorship",
      "description": "Pascale Fung authored Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters"
    },
    {
      "source": "Yan Xu",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Yan Xu affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Yan Xu",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Yan Xu affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Etsuko Ishii",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Etsuko Ishii affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Etsuko Ishii",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Etsuko Ishii affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Samuel Cahyawijaya",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Samuel Cahyawijaya affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Samuel Cahyawijaya",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Samuel Cahyawijaya affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Zihan Liu",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Zihan Liu affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Zihan Liu",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Zihan Liu affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Genta Indra Winata",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Genta Indra Winata affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Genta Indra Winata",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Genta Indra Winata affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Andrea Madotto",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Andrea Madotto affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Andrea Madotto",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Andrea Madotto affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Dan Su",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Dan Su affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Dan Su",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Dan Su affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Pascale Fung",
      "target": "Center for Artificial Intelligence Research (CAiRE)",
      "keywords": "affiliation",
      "description": "Pascale Fung affiliated with Center for Artificial Intelligence Research (CAiRE)"
    },
    {
      "source": "Pascale Fung",
      "target": "The Hong Kong University of Science and Technology",
      "keywords": "affiliation",
      "description": "Pascale Fung affiliated with The Hong Kong University of Science and Technology"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "Sentence-Transformers",
      "keywords": "uses",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters uses Sentence-Transformers"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "GPT-2",
      "keywords": "uses",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters uses GPT-2"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "KnowExpert",
      "keywords": "uses",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters uses KnowExpert"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "uses",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters uses Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "CMU Document Grounded Conversations (CMU_DoG)",
      "keywords": "uses",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters uses CMU Document Grounded Conversations (CMU_DoG)"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "ModularRAG",
      "keywords": "proposes",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters proposes ModularRAG"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "No explicit retrieval - knowledge embedded in model parameters",
      "keywords": "proposes",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters proposes No explicit retrieval - knowledge embedded in model parameters"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "Three-step training paradigm",
      "keywords": "proposes",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters proposes Three-step training paradigm"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters applies to ConversationalAI"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters applies to QA"
    },
    {
      "source": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters",
      "target": "Open-domain chit-chat dialogue systems",
      "keywords": "applies_to",
      "description": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters applies to Open-domain chit-chat dialogue systems"
    },
    {
      "source": "Sentence-Transformers",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "Sentence-Transformers potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Sentence-Transformers",
      "target": "CMU Document Grounded Conversations (CMU_DoG)",
      "keywords": "trained_on",
      "description": "Sentence-Transformers potentially trained on CMU Document Grounded Conversations (CMU_DoG)"
    },
    {
      "source": "GPT-2",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "GPT-2",
      "target": "CMU Document Grounded Conversations (CMU_DoG)",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on CMU Document Grounded Conversations (CMU_DoG)"
    },
    {
      "source": "KnowExpert",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "KnowExpert potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "KnowExpert",
      "target": "CMU Document Grounded Conversations (CMU_DoG)",
      "keywords": "trained_on",
      "description": "KnowExpert potentially trained on CMU Document Grounded Conversations (CMU_DoG)"
    },
    {
      "source": "ModularRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "ModularRAG supports ConversationalAI"
    },
    {
      "source": "ModularRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "ModularRAG supports QA"
    },
    {
      "source": "No explicit retrieval - knowledge embedded in model parameters",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "No explicit retrieval - knowledge embedded in model parameters supports ConversationalAI"
    },
    {
      "source": "No explicit retrieval - knowledge embedded in model parameters",
      "target": "QA",
      "keywords": "supports",
      "description": "No explicit retrieval - knowledge embedded in model parameters supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "Three-step training paradigm",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "Three-step training paradigm supports ConversationalAI"
    },
    {
      "source": "Three-step training paradigm",
      "target": "QA",
      "keywords": "supports",
      "description": "Three-step training paradigm supports QA"
    },
    {
      "source": "Shahul Es",
      "target": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Shahul Es authored Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "source": "Jithin James",
      "target": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Jithin James authored Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "source": "Luis Espinosa-Anke",
      "target": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Luis Espinosa-Anke authored Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "source": "Steven Schockaert",
      "target": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Steven Schockaert authored Ragas: Automated Evaluation of Retrieval Augmented Generation"
    },
    {
      "source": "Shahul Es",
      "target": "Exploding Gradients",
      "keywords": "affiliation",
      "description": "Shahul Es affiliated with Exploding Gradients"
    },
    {
      "source": "Shahul Es",
      "target": "CardiffNLP, Cardiff University, United Kingdom",
      "keywords": "affiliation",
      "description": "Shahul Es affiliated with CardiffNLP, Cardiff University, United Kingdom"
    },
    {
      "source": "Shahul Es",
      "target": "AMPLYFI, United Kingdom",
      "keywords": "affiliation",
      "description": "Shahul Es affiliated with AMPLYFI, United Kingdom"
    },
    {
      "source": "Jithin James",
      "target": "Exploding Gradients",
      "keywords": "affiliation",
      "description": "Jithin James affiliated with Exploding Gradients"
    },
    {
      "source": "Jithin James",
      "target": "CardiffNLP, Cardiff University, United Kingdom",
      "keywords": "affiliation",
      "description": "Jithin James affiliated with CardiffNLP, Cardiff University, United Kingdom"
    },
    {
      "source": "Jithin James",
      "target": "AMPLYFI, United Kingdom",
      "keywords": "affiliation",
      "description": "Jithin James affiliated with AMPLYFI, United Kingdom"
    },
    {
      "source": "Luis Espinosa-Anke",
      "target": "Exploding Gradients",
      "keywords": "affiliation",
      "description": "Luis Espinosa-Anke affiliated with Exploding Gradients"
    },
    {
      "source": "Luis Espinosa-Anke",
      "target": "CardiffNLP, Cardiff University, United Kingdom",
      "keywords": "affiliation",
      "description": "Luis Espinosa-Anke affiliated with CardiffNLP, Cardiff University, United Kingdom"
    },
    {
      "source": "Luis Espinosa-Anke",
      "target": "AMPLYFI, United Kingdom",
      "keywords": "affiliation",
      "description": "Luis Espinosa-Anke affiliated with AMPLYFI, United Kingdom"
    },
    {
      "source": "Steven Schockaert",
      "target": "Exploding Gradients",
      "keywords": "affiliation",
      "description": "Steven Schockaert affiliated with Exploding Gradients"
    },
    {
      "source": "Steven Schockaert",
      "target": "CardiffNLP, Cardiff University, United Kingdom",
      "keywords": "affiliation",
      "description": "Steven Schockaert affiliated with CardiffNLP, Cardiff University, United Kingdom"
    },
    {
      "source": "Steven Schockaert",
      "target": "AMPLYFI, United Kingdom",
      "keywords": "affiliation",
      "description": "Steven Schockaert affiliated with AMPLYFI, United Kingdom"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "text-embedding-ada-002",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses text-embedding-ada-002"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "gpt-3.5-turbo-16k",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses gpt-3.5-turbo-16k"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "ChatGPT",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses ChatGPT"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses GPT-4"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "BERT",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses BERT"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "BART",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses BART"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "WikiEval",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses WikiEval"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses Natural Questions"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation uses MS-MARCO"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation proposes PipelineRAG"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation proposes DenseRetrieval"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation proposes AbstractiveGeneration"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation proposes SeparateTraining"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation applies to QA"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation applies to DocumentSummarization"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation applies to LegalRAG"
    },
    {
      "source": "Ragas: Automated Evaluation of Retrieval Augmented Generation",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Ragas: Automated Evaluation of Retrieval Augmented Generation applies to MedicalRAG"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "WikiEval",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on WikiEval"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on Natural Questions"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on MS-MARCO"
    },
    {
      "source": "gpt-3.5-turbo-16k",
      "target": "WikiEval",
      "keywords": "trained_on",
      "description": "gpt-3.5-turbo-16k potentially trained on WikiEval"
    },
    {
      "source": "gpt-3.5-turbo-16k",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "gpt-3.5-turbo-16k potentially trained on Natural Questions"
    },
    {
      "source": "gpt-3.5-turbo-16k",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "gpt-3.5-turbo-16k potentially trained on MS-MARCO"
    },
    {
      "source": "ChatGPT",
      "target": "WikiEval",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on WikiEval"
    },
    {
      "source": "ChatGPT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on Natural Questions"
    },
    {
      "source": "ChatGPT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on MS-MARCO"
    },
    {
      "source": "GPT-4",
      "target": "WikiEval",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on WikiEval"
    },
    {
      "source": "GPT-4",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-4",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on MS-MARCO"
    },
    {
      "source": "BERT",
      "target": "WikiEval",
      "keywords": "trained_on",
      "description": "BERT potentially trained on WikiEval"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "BERT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MS-MARCO"
    },
    {
      "source": "BART",
      "target": "WikiEval",
      "keywords": "trained_on",
      "description": "BART potentially trained on WikiEval"
    },
    {
      "source": "BART",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions"
    },
    {
      "source": "BART",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BART potentially trained on MS-MARCO"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Shi-Qi Yan",
      "target": "Corrective Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Shi-Qi Yan authored Corrective Retrieval Augmented Generation"
    },
    {
      "source": "Jia-Chen Gu",
      "target": "Corrective Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Jia-Chen Gu authored Corrective Retrieval Augmented Generation"
    },
    {
      "source": "Yun Zhu",
      "target": "Corrective Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Yun Zhu authored Corrective Retrieval Augmented Generation"
    },
    {
      "source": "Zhen-Hua Ling",
      "target": "Corrective Retrieval Augmented Generation",
      "keywords": "authorship",
      "description": "Zhen-Hua Ling authored Corrective Retrieval Augmented Generation"
    },
    {
      "source": "Shi-Qi Yan",
      "target": "University of Science and Technology of China",
      "keywords": "affiliation",
      "description": "Shi-Qi Yan affiliated with University of Science and Technology of China"
    },
    {
      "source": "Shi-Qi Yan",
      "target": "University of California, Los Angeles",
      "keywords": "affiliation",
      "description": "Shi-Qi Yan affiliated with University of California, Los Angeles"
    },
    {
      "source": "Shi-Qi Yan",
      "target": "Google DeepMind",
      "keywords": "affiliation",
      "description": "Shi-Qi Yan affiliated with Google DeepMind"
    },
    {
      "source": "Jia-Chen Gu",
      "target": "University of Science and Technology of China",
      "keywords": "affiliation",
      "description": "Jia-Chen Gu affiliated with University of Science and Technology of China"
    },
    {
      "source": "Jia-Chen Gu",
      "target": "University of California, Los Angeles",
      "keywords": "affiliation",
      "description": "Jia-Chen Gu affiliated with University of California, Los Angeles"
    },
    {
      "source": "Jia-Chen Gu",
      "target": "Google DeepMind",
      "keywords": "affiliation",
      "description": "Jia-Chen Gu affiliated with Google DeepMind"
    },
    {
      "source": "Yun Zhu",
      "target": "University of Science and Technology of China",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with University of Science and Technology of China"
    },
    {
      "source": "Yun Zhu",
      "target": "University of California, Los Angeles",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with University of California, Los Angeles"
    },
    {
      "source": "Yun Zhu",
      "target": "Google DeepMind",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with Google DeepMind"
    },
    {
      "source": "Zhen-Hua Ling",
      "target": "University of Science and Technology of China",
      "keywords": "affiliation",
      "description": "Zhen-Hua Ling affiliated with University of Science and Technology of China"
    },
    {
      "source": "Zhen-Hua Ling",
      "target": "University of California, Los Angeles",
      "keywords": "affiliation",
      "description": "Zhen-Hua Ling affiliated with University of California, Los Angeles"
    },
    {
      "source": "Zhen-Hua Ling",
      "target": "Google DeepMind",
      "keywords": "affiliation",
      "description": "Zhen-Hua Ling affiliated with Google DeepMind"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "Contriever",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses Contriever"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "LLaMA2-7B",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses LLaMA2-7B"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "LLaMA2-13B",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses LLaMA2-13B"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "SelfRAG-LLaMA2-7b",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses SelfRAG-LLaMA2-7b"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "T5-large",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses T5-large"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "ChatGPT",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses ChatGPT"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "PopQA",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses PopQA"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "Biography",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses Biography"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "PubHealth",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses PubHealth"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "Arc-Challenge",
      "keywords": "uses",
      "description": "Corrective Retrieval Augmented Generation uses Arc-Challenge"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Corrective Retrieval Augmented Generation proposes PipelineRAG"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Corrective Retrieval Augmented Generation proposes DenseRetrieval"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Corrective Retrieval Augmented Generation proposes AbstractiveGeneration"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Corrective Retrieval Augmented Generation proposes SeparateTraining"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Corrective Retrieval Augmented Generation applies to QA"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Corrective Retrieval Augmented Generation applies to DocumentSummarization"
    },
    {
      "source": "Corrective Retrieval Augmented Generation",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Corrective Retrieval Augmented Generation applies to MedicalRAG"
    },
    {
      "source": "Contriever",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on PopQA"
    },
    {
      "source": "Contriever",
      "target": "Biography",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Biography"
    },
    {
      "source": "Contriever",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on PubHealth"
    },
    {
      "source": "Contriever",
      "target": "Arc-Challenge",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Arc-Challenge"
    },
    {
      "source": "LLaMA2-7B",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on PopQA"
    },
    {
      "source": "LLaMA2-7B",
      "target": "Biography",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on Biography"
    },
    {
      "source": "LLaMA2-7B",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on PubHealth"
    },
    {
      "source": "LLaMA2-7B",
      "target": "Arc-Challenge",
      "keywords": "trained_on",
      "description": "LLaMA2-7B potentially trained on Arc-Challenge"
    },
    {
      "source": "LLaMA2-13B",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "LLaMA2-13B potentially trained on PopQA"
    },
    {
      "source": "LLaMA2-13B",
      "target": "Biography",
      "keywords": "trained_on",
      "description": "LLaMA2-13B potentially trained on Biography"
    },
    {
      "source": "LLaMA2-13B",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "LLaMA2-13B potentially trained on PubHealth"
    },
    {
      "source": "LLaMA2-13B",
      "target": "Arc-Challenge",
      "keywords": "trained_on",
      "description": "LLaMA2-13B potentially trained on Arc-Challenge"
    },
    {
      "source": "SelfRAG-LLaMA2-7b",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "SelfRAG-LLaMA2-7b potentially trained on PopQA"
    },
    {
      "source": "SelfRAG-LLaMA2-7b",
      "target": "Biography",
      "keywords": "trained_on",
      "description": "SelfRAG-LLaMA2-7b potentially trained on Biography"
    },
    {
      "source": "SelfRAG-LLaMA2-7b",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "SelfRAG-LLaMA2-7b potentially trained on PubHealth"
    },
    {
      "source": "SelfRAG-LLaMA2-7b",
      "target": "Arc-Challenge",
      "keywords": "trained_on",
      "description": "SelfRAG-LLaMA2-7b potentially trained on Arc-Challenge"
    },
    {
      "source": "T5-large",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "T5-large potentially trained on PopQA"
    },
    {
      "source": "T5-large",
      "target": "Biography",
      "keywords": "trained_on",
      "description": "T5-large potentially trained on Biography"
    },
    {
      "source": "T5-large",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "T5-large potentially trained on PubHealth"
    },
    {
      "source": "T5-large",
      "target": "Arc-Challenge",
      "keywords": "trained_on",
      "description": "T5-large potentially trained on Arc-Challenge"
    },
    {
      "source": "ChatGPT",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on PopQA"
    },
    {
      "source": "ChatGPT",
      "target": "Biography",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on Biography"
    },
    {
      "source": "ChatGPT",
      "target": "PubHealth",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on PubHealth"
    },
    {
      "source": "ChatGPT",
      "target": "Arc-Challenge",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on Arc-Challenge"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Jon Saad-Falcon",
      "target": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "keywords": "authorship",
      "description": "Jon Saad-Falcon authored ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "source": "Omar Khattab",
      "target": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "keywords": "authorship",
      "description": "Omar Khattab authored ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "source": "Christopher Potts",
      "target": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "keywords": "authorship",
      "description": "Christopher Potts authored ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "source": "Matei Zaharia",
      "target": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "keywords": "authorship",
      "description": "Matei Zaharia authored ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems"
    },
    {
      "source": "Jon Saad-Falcon",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Jon Saad-Falcon affiliated with Stanford University"
    },
    {
      "source": "Jon Saad-Falcon",
      "target": "Databricks",
      "keywords": "affiliation",
      "description": "Jon Saad-Falcon affiliated with Databricks"
    },
    {
      "source": "Jon Saad-Falcon",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Jon Saad-Falcon affiliated with UC Berkeley"
    },
    {
      "source": "Omar Khattab",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Omar Khattab affiliated with Stanford University"
    },
    {
      "source": "Omar Khattab",
      "target": "Databricks",
      "keywords": "affiliation",
      "description": "Omar Khattab affiliated with Databricks"
    },
    {
      "source": "Omar Khattab",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Omar Khattab affiliated with UC Berkeley"
    },
    {
      "source": "Christopher Potts",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Christopher Potts affiliated with Stanford University"
    },
    {
      "source": "Christopher Potts",
      "target": "Databricks",
      "keywords": "affiliation",
      "description": "Christopher Potts affiliated with Databricks"
    },
    {
      "source": "Christopher Potts",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Christopher Potts affiliated with UC Berkeley"
    },
    {
      "source": "Matei Zaharia",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Matei Zaharia affiliated with Stanford University"
    },
    {
      "source": "Matei Zaharia",
      "target": "Databricks",
      "keywords": "affiliation",
      "description": "Matei Zaharia affiliated with Databricks"
    },
    {
      "source": "Matei Zaharia",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Matei Zaharia affiliated with UC Berkeley"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "BM25",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses BM25"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "OpenAI text-embedding-ada-002",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses OpenAI text-embedding-ada-002"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "ColBERTv2",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses ColBERTv2"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "DPR",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses DPR"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "FLAN-T5 XXL",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses FLAN-T5 XXL"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "DeBERTa-v3-Large",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses DeBERTa-v3-Large"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "GPT-3.5-turbo-16k",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses GPT-3.5-turbo-16k"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses GPT-4"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "MPT-7b-Instruct",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses MPT-7b-Instruct"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "BART",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses BART"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses Natural Questions (NQ)"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "HotpotQA",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses HotpotQA"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "FEVER",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses FEVER"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses Wizards of Wikipedia (WoW)"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "MultiRC",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses MultiRC"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "ReCoRD",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses ReCoRD"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "AIS attribution dataset",
      "keywords": "uses",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems uses AIS attribution dataset"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems proposes PipelineRAG"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems proposes HybridRetrieval"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems proposes AbstractiveGeneration"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems proposes SeparateTraining"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "QA",
      "keywords": "applies_to",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems applies to QA"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "fact-checking",
      "keywords": "applies_to",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems applies to fact-checking"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "customer support",
      "keywords": "applies_to",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems applies to customer support"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "dialogue systems",
      "keywords": "applies_to",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems applies to dialogue systems"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "General domain",
      "keywords": "applies_to",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems applies to General domain"
    },
    {
      "source": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems",
      "target": "Cross-domain evaluation tested on multiple knowledge-intensive tasks",
      "keywords": "applies_to",
      "description": "ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems applies to Cross-domain evaluation tested on multiple knowledge-intensive tasks"
    },
    {
      "source": "BM25",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BM25",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on HotpotQA"
    },
    {
      "source": "BM25",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on FEVER"
    },
    {
      "source": "BM25",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "BM25",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on MultiRC"
    },
    {
      "source": "BM25",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on ReCoRD"
    },
    {
      "source": "BM25",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on AIS attribution dataset"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on HotpotQA"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on FEVER"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on MultiRC"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on ReCoRD"
    },
    {
      "source": "OpenAI text-embedding-ada-002",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "OpenAI text-embedding-ada-002 potentially trained on AIS attribution dataset"
    },
    {
      "source": "ColBERTv2",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "ColBERTv2",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on HotpotQA"
    },
    {
      "source": "ColBERTv2",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on FEVER"
    },
    {
      "source": "ColBERTv2",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "ColBERTv2",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on MultiRC"
    },
    {
      "source": "ColBERTv2",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on ReCoRD"
    },
    {
      "source": "ColBERTv2",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "ColBERTv2 potentially trained on AIS attribution dataset"
    },
    {
      "source": "DPR",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "DPR potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "DPR",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "DPR potentially trained on HotpotQA"
    },
    {
      "source": "DPR",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "DPR potentially trained on FEVER"
    },
    {
      "source": "DPR",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "DPR potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "DPR",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "DPR potentially trained on MultiRC"
    },
    {
      "source": "DPR",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "DPR potentially trained on ReCoRD"
    },
    {
      "source": "DPR",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "DPR potentially trained on AIS attribution dataset"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on HotpotQA"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on FEVER"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on MultiRC"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on ReCoRD"
    },
    {
      "source": "FLAN-T5 XXL",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "FLAN-T5 XXL potentially trained on AIS attribution dataset"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on HotpotQA"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on FEVER"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on MultiRC"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on ReCoRD"
    },
    {
      "source": "DeBERTa-v3-Large",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "DeBERTa-v3-Large potentially trained on AIS attribution dataset"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on HotpotQA"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on FEVER"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on MultiRC"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on ReCoRD"
    },
    {
      "source": "GPT-3.5-turbo-16k",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo-16k potentially trained on AIS attribution dataset"
    },
    {
      "source": "GPT-4",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-4",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on HotpotQA"
    },
    {
      "source": "GPT-4",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on FEVER"
    },
    {
      "source": "GPT-4",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "GPT-4",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on MultiRC"
    },
    {
      "source": "GPT-4",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on ReCoRD"
    },
    {
      "source": "GPT-4",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on AIS attribution dataset"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on HotpotQA"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on FEVER"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on MultiRC"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on ReCoRD"
    },
    {
      "source": "MPT-7b-Instruct",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "MPT-7b-Instruct potentially trained on AIS attribution dataset"
    },
    {
      "source": "BART",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BART",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on HotpotQA"
    },
    {
      "source": "BART",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BART potentially trained on FEVER"
    },
    {
      "source": "BART",
      "target": "Wizards of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "BART potentially trained on Wizards of Wikipedia (WoW)"
    },
    {
      "source": "BART",
      "target": "MultiRC",
      "keywords": "trained_on",
      "description": "BART potentially trained on MultiRC"
    },
    {
      "source": "BART",
      "target": "ReCoRD",
      "keywords": "trained_on",
      "description": "BART potentially trained on ReCoRD"
    },
    {
      "source": "BART",
      "target": "AIS attribution dataset",
      "keywords": "trained_on",
      "description": "BART potentially trained on AIS attribution dataset"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "fact-checking",
      "keywords": "supports",
      "description": "PipelineRAG supports fact-checking"
    },
    {
      "source": "PipelineRAG",
      "target": "customer support",
      "keywords": "supports",
      "description": "PipelineRAG supports customer support"
    },
    {
      "source": "PipelineRAG",
      "target": "dialogue systems",
      "keywords": "supports",
      "description": "PipelineRAG supports dialogue systems"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "fact-checking",
      "keywords": "supports",
      "description": "HybridRetrieval supports fact-checking"
    },
    {
      "source": "HybridRetrieval",
      "target": "customer support",
      "keywords": "supports",
      "description": "HybridRetrieval supports customer support"
    },
    {
      "source": "HybridRetrieval",
      "target": "dialogue systems",
      "keywords": "supports",
      "description": "HybridRetrieval supports dialogue systems"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "fact-checking",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports fact-checking"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "customer support",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports customer support"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "dialogue systems",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports dialogue systems"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "fact-checking",
      "keywords": "supports",
      "description": "SeparateTraining supports fact-checking"
    },
    {
      "source": "SeparateTraining",
      "target": "customer support",
      "keywords": "supports",
      "description": "SeparateTraining supports customer support"
    },
    {
      "source": "SeparateTraining",
      "target": "dialogue systems",
      "keywords": "supports",
      "description": "SeparateTraining supports dialogue systems"
    },
    {
      "source": "Florin Cuconasu",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Florin Cuconasu authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Giovanni Trappolini",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Giovanni Trappolini authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Federico Siciliano",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Federico Siciliano authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Simone Filice",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Simone Filice authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Cesare Campagnano",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Cesare Campagnano authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Yoelle Maarek",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Yoelle Maarek authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Nicola Tonellotto authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Fabrizio Silvestri",
      "target": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "keywords": "authorship",
      "description": "Fabrizio Silvestri authored The Power of Noise: Redefining Retrieval for RAG Systems"
    },
    {
      "source": "Florin Cuconasu",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Florin Cuconasu affiliated with Sapienza University of Rome"
    },
    {
      "source": "Florin Cuconasu",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Florin Cuconasu affiliated with Technology Innovation Institute"
    },
    {
      "source": "Florin Cuconasu",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Florin Cuconasu affiliated with University of Pisa"
    },
    {
      "source": "Giovanni Trappolini",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Giovanni Trappolini affiliated with Sapienza University of Rome"
    },
    {
      "source": "Giovanni Trappolini",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Giovanni Trappolini affiliated with Technology Innovation Institute"
    },
    {
      "source": "Giovanni Trappolini",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Giovanni Trappolini affiliated with University of Pisa"
    },
    {
      "source": "Federico Siciliano",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Federico Siciliano affiliated with Sapienza University of Rome"
    },
    {
      "source": "Federico Siciliano",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Federico Siciliano affiliated with Technology Innovation Institute"
    },
    {
      "source": "Federico Siciliano",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Federico Siciliano affiliated with University of Pisa"
    },
    {
      "source": "Simone Filice",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Simone Filice affiliated with Sapienza University of Rome"
    },
    {
      "source": "Simone Filice",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Simone Filice affiliated with Technology Innovation Institute"
    },
    {
      "source": "Simone Filice",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Simone Filice affiliated with University of Pisa"
    },
    {
      "source": "Cesare Campagnano",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Cesare Campagnano affiliated with Sapienza University of Rome"
    },
    {
      "source": "Cesare Campagnano",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Cesare Campagnano affiliated with Technology Innovation Institute"
    },
    {
      "source": "Cesare Campagnano",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Cesare Campagnano affiliated with University of Pisa"
    },
    {
      "source": "Yoelle Maarek",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Yoelle Maarek affiliated with Sapienza University of Rome"
    },
    {
      "source": "Yoelle Maarek",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Yoelle Maarek affiliated with Technology Innovation Institute"
    },
    {
      "source": "Yoelle Maarek",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Yoelle Maarek affiliated with University of Pisa"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with Sapienza University of Rome"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with Technology Innovation Institute"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with University of Pisa"
    },
    {
      "source": "Fabrizio Silvestri",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Fabrizio Silvestri affiliated with Sapienza University of Rome"
    },
    {
      "source": "Fabrizio Silvestri",
      "target": "Technology Innovation Institute",
      "keywords": "affiliation",
      "description": "Fabrizio Silvestri affiliated with Technology Innovation Institute"
    },
    {
      "source": "Fabrizio Silvestri",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Fabrizio Silvestri affiliated with University of Pisa"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "Contriever",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses Contriever"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "ADORE",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses ADORE"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "BM25",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses BM25"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "Llama2-7B",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses Llama2-7B"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "Falcon-7B",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses Falcon-7B"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "Phi-2",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses Phi-2"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "MPT-7B",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses MPT-7B"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses Natural Questions (NQ)"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "NQ-open",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses NQ-open"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "uses",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems uses Reddit Webis-TLDR-17"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems proposes PipelineRAG"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems proposes DenseRetrieval"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems proposes AbstractiveGeneration"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems proposes SeparateTraining"
    },
    {
      "source": "The Power of Noise: Redefining Retrieval for RAG Systems",
      "target": "QA",
      "keywords": "applies_to",
      "description": "The Power of Noise: Redefining Retrieval for RAG Systems applies to QA"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Contriever",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on NQ-open"
    },
    {
      "source": "Contriever",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "ADORE",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "ADORE potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "ADORE",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "ADORE potentially trained on NQ-open"
    },
    {
      "source": "ADORE",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "ADORE potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "BM25",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BM25",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on NQ-open"
    },
    {
      "source": "BM25",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "Llama2-7B",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Llama2-7B potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Llama2-7B",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "Llama2-7B potentially trained on NQ-open"
    },
    {
      "source": "Llama2-7B",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "Llama2-7B potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "Falcon-7B",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Falcon-7B potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Falcon-7B",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "Falcon-7B potentially trained on NQ-open"
    },
    {
      "source": "Falcon-7B",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "Falcon-7B potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "Phi-2",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Phi-2 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Phi-2",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "Phi-2 potentially trained on NQ-open"
    },
    {
      "source": "Phi-2",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "Phi-2 potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "MPT-7B",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "MPT-7B potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "MPT-7B",
      "target": "NQ-open",
      "keywords": "trained_on",
      "description": "MPT-7B potentially trained on NQ-open"
    },
    {
      "source": "MPT-7B",
      "target": "Reddit Webis-TLDR-17",
      "keywords": "trained_on",
      "description": "MPT-7B potentially trained on Reddit Webis-TLDR-17"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "Zhentao Xu",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Zhentao Xu authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Mark Jerome Cruz",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Mark Jerome Cruz authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Matthew Guevara",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Matthew Guevara authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Tie Wang",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Tie Wang authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Manasi Deshpande",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Manasi Deshpande authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Xiaofeng Wang",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Xiaofeng Wang authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Zheng Li",
      "target": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "keywords": "authorship",
      "description": "Zheng Li authored Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering"
    },
    {
      "source": "Zhentao Xu",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Zhentao Xu affiliated with LinkedIn Corporation"
    },
    {
      "source": "Mark Jerome Cruz",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Mark Jerome Cruz affiliated with LinkedIn Corporation"
    },
    {
      "source": "Matthew Guevara",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Matthew Guevara affiliated with LinkedIn Corporation"
    },
    {
      "source": "Tie Wang",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Tie Wang affiliated with LinkedIn Corporation"
    },
    {
      "source": "Manasi Deshpande",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Manasi Deshpande affiliated with LinkedIn Corporation"
    },
    {
      "source": "Xiaofeng Wang",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Xiaofeng Wang affiliated with LinkedIn Corporation"
    },
    {
      "source": "Zheng Li",
      "target": "LinkedIn Corporation",
      "keywords": "affiliation",
      "description": "Zheng Li affiliated with LinkedIn Corporation"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "BERT",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering uses BERT"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "E5",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering uses E5"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering uses GPT-4"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "LinkedIn Customer Service Dataset",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering uses LinkedIn Customer Service Dataset"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "HierarchicalRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering proposes HierarchicalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering proposes HybridRetrieval"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering proposes SeparateTraining"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering applies to QA"
    },
    {
      "source": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
      "target": "CustomerServiceRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering applies to CustomerServiceRAG"
    },
    {
      "source": "BERT",
      "target": "LinkedIn Customer Service Dataset",
      "keywords": "trained_on",
      "description": "BERT potentially trained on LinkedIn Customer Service Dataset"
    },
    {
      "source": "E5",
      "target": "LinkedIn Customer Service Dataset",
      "keywords": "trained_on",
      "description": "E5 potentially trained on LinkedIn Customer Service Dataset"
    },
    {
      "source": "GPT-4",
      "target": "LinkedIn Customer Service Dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on LinkedIn Customer Service Dataset"
    },
    {
      "source": "HierarchicalRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "HierarchicalRAG supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "Xiaojun Chang",
      "target": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "keywords": "authorship",
      "description": "Xiaojun Chang authored A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "source": "Pengzhen Ren",
      "target": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "keywords": "authorship",
      "description": "Pengzhen Ren authored A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "source": "Pengfei Xu",
      "target": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "keywords": "authorship",
      "description": "Pengfei Xu authored A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "source": "Zhihui Li",
      "target": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "keywords": "authorship",
      "description": "Zhihui Li authored A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "source": "Xiaojiang Chen",
      "target": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "keywords": "authorship",
      "description": "Xiaojiang Chen authored A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "source": "Alex Hauptmann",
      "target": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "keywords": "authorship",
      "description": "Alex Hauptmann authored A Comprehensive Survey of Scene Graphs: Generation and Application"
    },
    {
      "source": "Xiaojun Chang",
      "target": "University of Technology Sydney",
      "keywords": "affiliation",
      "description": "Xiaojun Chang affiliated with University of Technology Sydney"
    },
    {
      "source": "Xiaojun Chang",
      "target": "Northwest University",
      "keywords": "affiliation",
      "description": "Xiaojun Chang affiliated with Northwest University"
    },
    {
      "source": "Xiaojun Chang",
      "target": "Qilu University of Technology",
      "keywords": "affiliation",
      "description": "Xiaojun Chang affiliated with Qilu University of Technology"
    },
    {
      "source": "Xiaojun Chang",
      "target": "Carnegie Mellon University",
      "keywords": "affiliation",
      "description": "Xiaojun Chang affiliated with Carnegie Mellon University"
    },
    {
      "source": "Pengzhen Ren",
      "target": "University of Technology Sydney",
      "keywords": "affiliation",
      "description": "Pengzhen Ren affiliated with University of Technology Sydney"
    },
    {
      "source": "Pengzhen Ren",
      "target": "Northwest University",
      "keywords": "affiliation",
      "description": "Pengzhen Ren affiliated with Northwest University"
    },
    {
      "source": "Pengzhen Ren",
      "target": "Qilu University of Technology",
      "keywords": "affiliation",
      "description": "Pengzhen Ren affiliated with Qilu University of Technology"
    },
    {
      "source": "Pengzhen Ren",
      "target": "Carnegie Mellon University",
      "keywords": "affiliation",
      "description": "Pengzhen Ren affiliated with Carnegie Mellon University"
    },
    {
      "source": "Pengfei Xu",
      "target": "University of Technology Sydney",
      "keywords": "affiliation",
      "description": "Pengfei Xu affiliated with University of Technology Sydney"
    },
    {
      "source": "Pengfei Xu",
      "target": "Northwest University",
      "keywords": "affiliation",
      "description": "Pengfei Xu affiliated with Northwest University"
    },
    {
      "source": "Pengfei Xu",
      "target": "Qilu University of Technology",
      "keywords": "affiliation",
      "description": "Pengfei Xu affiliated with Qilu University of Technology"
    },
    {
      "source": "Pengfei Xu",
      "target": "Carnegie Mellon University",
      "keywords": "affiliation",
      "description": "Pengfei Xu affiliated with Carnegie Mellon University"
    },
    {
      "source": "Zhihui Li",
      "target": "University of Technology Sydney",
      "keywords": "affiliation",
      "description": "Zhihui Li affiliated with University of Technology Sydney"
    },
    {
      "source": "Zhihui Li",
      "target": "Northwest University",
      "keywords": "affiliation",
      "description": "Zhihui Li affiliated with Northwest University"
    },
    {
      "source": "Zhihui Li",
      "target": "Qilu University of Technology",
      "keywords": "affiliation",
      "description": "Zhihui Li affiliated with Qilu University of Technology"
    },
    {
      "source": "Zhihui Li",
      "target": "Carnegie Mellon University",
      "keywords": "affiliation",
      "description": "Zhihui Li affiliated with Carnegie Mellon University"
    },
    {
      "source": "Xiaojiang Chen",
      "target": "University of Technology Sydney",
      "keywords": "affiliation",
      "description": "Xiaojiang Chen affiliated with University of Technology Sydney"
    },
    {
      "source": "Xiaojiang Chen",
      "target": "Northwest University",
      "keywords": "affiliation",
      "description": "Xiaojiang Chen affiliated with Northwest University"
    },
    {
      "source": "Xiaojiang Chen",
      "target": "Qilu University of Technology",
      "keywords": "affiliation",
      "description": "Xiaojiang Chen affiliated with Qilu University of Technology"
    },
    {
      "source": "Xiaojiang Chen",
      "target": "Carnegie Mellon University",
      "keywords": "affiliation",
      "description": "Xiaojiang Chen affiliated with Carnegie Mellon University"
    },
    {
      "source": "Alex Hauptmann",
      "target": "University of Technology Sydney",
      "keywords": "affiliation",
      "description": "Alex Hauptmann affiliated with University of Technology Sydney"
    },
    {
      "source": "Alex Hauptmann",
      "target": "Northwest University",
      "keywords": "affiliation",
      "description": "Alex Hauptmann affiliated with Northwest University"
    },
    {
      "source": "Alex Hauptmann",
      "target": "Qilu University of Technology",
      "keywords": "affiliation",
      "description": "Alex Hauptmann affiliated with Qilu University of Technology"
    },
    {
      "source": "Alex Hauptmann",
      "target": "Carnegie Mellon University",
      "keywords": "affiliation",
      "description": "Alex Hauptmann affiliated with Carnegie Mellon University"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "Faster-RCNN",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application uses Faster-RCNN"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "Mask R-CNN",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application uses Mask R-CNN"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "Visual Genome",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application uses Visual Genome"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "Visual Relationship Dataset (VRD)",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application uses Visual Relationship Dataset (VRD)"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "Scene Graph Dataset",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application uses Scene Graph Dataset"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application proposes PipelineRAG"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "Not applicable",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application proposes Not applicable"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application proposes HybridGeneration"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application proposes SeparateTraining"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "QA",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application applies to QA"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application applies to DocumentSummarization"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application applies to ConversationalAI"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application applies to MedicalRAG"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application applies to LegalRAG"
    },
    {
      "source": "A Comprehensive Survey of Scene Graphs: Generation and Application",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Scene Graphs: Generation and Application applies to EducationalRAG"
    },
    {
      "source": "Faster-RCNN",
      "target": "Visual Genome",
      "keywords": "trained_on",
      "description": "Faster-RCNN potentially trained on Visual Genome"
    },
    {
      "source": "Faster-RCNN",
      "target": "Visual Relationship Dataset (VRD)",
      "keywords": "trained_on",
      "description": "Faster-RCNN potentially trained on Visual Relationship Dataset (VRD)"
    },
    {
      "source": "Faster-RCNN",
      "target": "Scene Graph Dataset",
      "keywords": "trained_on",
      "description": "Faster-RCNN potentially trained on Scene Graph Dataset"
    },
    {
      "source": "Mask R-CNN",
      "target": "Visual Genome",
      "keywords": "trained_on",
      "description": "Mask R-CNN potentially trained on Visual Genome"
    },
    {
      "source": "Mask R-CNN",
      "target": "Visual Relationship Dataset (VRD)",
      "keywords": "trained_on",
      "description": "Mask R-CNN potentially trained on Visual Relationship Dataset (VRD)"
    },
    {
      "source": "Mask R-CNN",
      "target": "Scene Graph Dataset",
      "keywords": "trained_on",
      "description": "Mask R-CNN potentially trained on Scene Graph Dataset"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "Not applicable",
      "target": "QA",
      "keywords": "supports",
      "description": "Not applicable supports QA"
    },
    {
      "source": "Not applicable",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "Not applicable supports DocumentSummarization"
    },
    {
      "source": "Not applicable",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "Not applicable supports ConversationalAI"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Michele Bevilacqua",
      "target": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "keywords": "authorship",
      "description": "Michele Bevilacqua authored Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "source": "Giuseppe Ottaviano",
      "target": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "keywords": "authorship",
      "description": "Giuseppe Ottaviano authored Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "source": "Patrick Lewis",
      "target": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "keywords": "authorship",
      "description": "Patrick Lewis authored Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "keywords": "authorship",
      "description": "Wen-tau Yih authored Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "keywords": "authorship",
      "description": "Sebastian Riedel authored Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "source": "Fabio Petroni",
      "target": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "keywords": "authorship",
      "description": "Fabio Petroni authored Autoregressive Search Engines: Generating Substrings as Document Identifiers"
    },
    {
      "source": "Michele Bevilacqua",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Michele Bevilacqua affiliated with Sapienza University of Rome"
    },
    {
      "source": "Michele Bevilacqua",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Michele Bevilacqua affiliated with Meta AI"
    },
    {
      "source": "Michele Bevilacqua",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Michele Bevilacqua affiliated with University College London"
    },
    {
      "source": "Giuseppe Ottaviano",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Giuseppe Ottaviano affiliated with Sapienza University of Rome"
    },
    {
      "source": "Giuseppe Ottaviano",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Giuseppe Ottaviano affiliated with Meta AI"
    },
    {
      "source": "Giuseppe Ottaviano",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Giuseppe Ottaviano affiliated with University College London"
    },
    {
      "source": "Patrick Lewis",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with Sapienza University of Rome"
    },
    {
      "source": "Patrick Lewis",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with Meta AI"
    },
    {
      "source": "Patrick Lewis",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with University College London"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Sapienza University of Rome"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Meta AI"
    },
    {
      "source": "Wen-tau Yih",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with University College London"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Sapienza University of Rome"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Meta AI"
    },
    {
      "source": "Sebastian Riedel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with University College London"
    },
    {
      "source": "Fabio Petroni",
      "target": "Sapienza University of Rome",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with Sapienza University of Rome"
    },
    {
      "source": "Fabio Petroni",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with Meta AI"
    },
    {
      "source": "Fabio Petroni",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with University College London"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "FM-Index",
      "keywords": "uses",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers uses FM-Index"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "BART large",
      "keywords": "uses",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers uses BART large"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers uses Natural Questions"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "NQ320k",
      "keywords": "uses",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers uses NQ320k"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "KILT",
      "keywords": "uses",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers uses KILT"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers proposes PipelineRAG"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers proposes HybridRetrieval"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers proposes AbstractiveGeneration"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers proposes FinetuningStrategy"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers applies to QA"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers applies to DocumentSummarization"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "Open-domain question answering",
      "keywords": "applies_to",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers applies to Open-domain question answering"
    },
    {
      "source": "Autoregressive Search Engines: Generating Substrings as Document Identifiers",
      "target": "Knowledge-intensive language tasks",
      "keywords": "applies_to",
      "description": "Autoregressive Search Engines: Generating Substrings as Document Identifiers applies to Knowledge-intensive language tasks"
    },
    {
      "source": "FM-Index",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "FM-Index potentially trained on Natural Questions"
    },
    {
      "source": "FM-Index",
      "target": "NQ320k",
      "keywords": "trained_on",
      "description": "FM-Index potentially trained on NQ320k"
    },
    {
      "source": "FM-Index",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "FM-Index potentially trained on KILT"
    },
    {
      "source": "BART large",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART large potentially trained on Natural Questions"
    },
    {
      "source": "BART large",
      "target": "NQ320k",
      "keywords": "trained_on",
      "description": "BART large potentially trained on NQ320k"
    },
    {
      "source": "BART large",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "BART large potentially trained on KILT"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "Zhuyun Dai",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Zhuyun Dai authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Vincent Y. Zhao",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Vincent Y. Zhao authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Ji Ma",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Ji Ma authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Yi Luan",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Yi Luan authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Jianmo Ni",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Jianmo Ni authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Jing Lu",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Jing Lu authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Anton Bakalov",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Anton Bakalov authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Kelvin Guu",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Kelvin Guu authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Keith B. Hall",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Keith B. Hall authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Ming-Wei Chang",
      "target": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "keywords": "authorship",
      "description": "Ming-Wei Chang authored PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES"
    },
    {
      "source": "Zhuyun Dai",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Zhuyun Dai affiliated with Google Research"
    },
    {
      "source": "Vincent Y. Zhao",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Vincent Y. Zhao affiliated with Google Research"
    },
    {
      "source": "Ji Ma",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Ji Ma affiliated with Google Research"
    },
    {
      "source": "Yi Luan",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Yi Luan affiliated with Google Research"
    },
    {
      "source": "Jianmo Ni",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Jianmo Ni affiliated with Google Research"
    },
    {
      "source": "Jing Lu",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Jing Lu affiliated with Google Research"
    },
    {
      "source": "Anton Bakalov",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Anton Bakalov affiliated with Google Research"
    },
    {
      "source": "Kelvin Guu",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Kelvin Guu affiliated with Google Research"
    },
    {
      "source": "Keith B. Hall",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Keith B. Hall affiliated with Google Research"
    },
    {
      "source": "Ming-Wei Chang",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Ming-Wei Chang affiliated with Google Research"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "T5-base dual encoder",
      "keywords": "uses",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES uses T5-base dual encoder"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "FLAN",
      "keywords": "uses",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES uses FLAN"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "T5-base cross-attention reranker",
      "keywords": "uses",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES uses T5-base cross-attention reranker"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "BEIR",
      "keywords": "uses",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES uses BEIR"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "MS MARCO",
      "keywords": "uses",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES uses MS MARCO"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES uses Natural Questions"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES proposes PipelineRAG"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES proposes DenseRetrieval"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES proposes AbstractiveGeneration"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES proposes SeparateTraining"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "QA",
      "keywords": "applies_to",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES applies to QA"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES applies to DocumentSummarization"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES applies to ConversationalAI"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES applies to MedicalRAG"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES applies to LegalRAG"
    },
    {
      "source": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "PROMPTAGATOR: FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES applies to EducationalRAG"
    },
    {
      "source": "T5-base dual encoder",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "T5-base dual encoder potentially trained on BEIR"
    },
    {
      "source": "T5-base dual encoder",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "T5-base dual encoder potentially trained on MS MARCO"
    },
    {
      "source": "T5-base dual encoder",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5-base dual encoder potentially trained on Natural Questions"
    },
    {
      "source": "FLAN",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "FLAN potentially trained on BEIR"
    },
    {
      "source": "FLAN",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "FLAN potentially trained on MS MARCO"
    },
    {
      "source": "FLAN",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "FLAN potentially trained on Natural Questions"
    },
    {
      "source": "T5-base cross-attention reranker",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "T5-base cross-attention reranker potentially trained on BEIR"
    },
    {
      "source": "T5-base cross-attention reranker",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "T5-base cross-attention reranker potentially trained on MS MARCO"
    },
    {
      "source": "T5-base cross-attention reranker",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5-base cross-attention reranker potentially trained on Natural Questions"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Omar Khattab",
      "target": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "keywords": "authorship",
      "description": "Omar Khattab authored ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT"
    },
    {
      "source": "Matei Zaharia",
      "target": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "keywords": "authorship",
      "description": "Matei Zaharia authored ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT"
    },
    {
      "source": "Omar Khattab",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Omar Khattab affiliated with Stanford University"
    },
    {
      "source": "Matei Zaharia",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Matei Zaharia affiliated with Stanford University"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "ColBERT",
      "keywords": "uses",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT uses ColBERT"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "BERT-base",
      "keywords": "uses",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT uses BERT-base"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "BERT-large",
      "keywords": "uses",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT uses BERT-large"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "MS MARCO",
      "keywords": "uses",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT uses MS MARCO"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "TREC CAR",
      "keywords": "uses",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT uses TREC CAR"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT proposes PipelineRAG"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT proposes DenseRetrieval"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "ExtractiveGeneration",
      "keywords": "proposes",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT proposes ExtractiveGeneration"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT proposes FinetuningStrategy"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "QA",
      "keywords": "applies_to",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT applies to QA"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT applies to DocumentSummarization"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "Web search",
      "keywords": "applies_to",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT applies to Web search"
    },
    {
      "source": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT",
      "target": "Academic search",
      "keywords": "applies_to",
      "description": "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT applies to Academic search"
    },
    {
      "source": "ColBERT",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "ColBERT potentially trained on MS MARCO"
    },
    {
      "source": "ColBERT",
      "target": "TREC CAR",
      "keywords": "trained_on",
      "description": "ColBERT potentially trained on TREC CAR"
    },
    {
      "source": "BERT-base",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on MS MARCO"
    },
    {
      "source": "BERT-base",
      "target": "TREC CAR",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on TREC CAR"
    },
    {
      "source": "BERT-large",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "BERT-large potentially trained on MS MARCO"
    },
    {
      "source": "BERT-large",
      "target": "TREC CAR",
      "keywords": "trained_on",
      "description": "BERT-large potentially trained on TREC CAR"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "ExtractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "ExtractiveGeneration supports QA"
    },
    {
      "source": "ExtractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "ExtractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "Sebastian Hofstätter",
      "target": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Sebastian Hofstätter authored FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "source": "Jiecao Chen",
      "target": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Jiecao Chen authored FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "source": "Karthik Raman",
      "target": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Karthik Raman authored FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "source": "Hamed Zamani",
      "target": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Hamed Zamani authored FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation"
    },
    {
      "source": "Sebastian Hofstätter",
      "target": "TU Wien (Google Internship)",
      "keywords": "affiliation",
      "description": "Sebastian Hofstätter affiliated with TU Wien (Google Internship)"
    },
    {
      "source": "Sebastian Hofstätter",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Sebastian Hofstätter affiliated with Google"
    },
    {
      "source": "Sebastian Hofstätter",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Sebastian Hofstätter affiliated with Google"
    },
    {
      "source": "Sebastian Hofstätter",
      "target": "University of Massachusetts Amherst",
      "keywords": "affiliation",
      "description": "Sebastian Hofstätter affiliated with University of Massachusetts Amherst"
    },
    {
      "source": "Jiecao Chen",
      "target": "TU Wien (Google Internship)",
      "keywords": "affiliation",
      "description": "Jiecao Chen affiliated with TU Wien (Google Internship)"
    },
    {
      "source": "Jiecao Chen",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Jiecao Chen affiliated with Google"
    },
    {
      "source": "Jiecao Chen",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Jiecao Chen affiliated with Google"
    },
    {
      "source": "Jiecao Chen",
      "target": "University of Massachusetts Amherst",
      "keywords": "affiliation",
      "description": "Jiecao Chen affiliated with University of Massachusetts Amherst"
    },
    {
      "source": "Karthik Raman",
      "target": "TU Wien (Google Internship)",
      "keywords": "affiliation",
      "description": "Karthik Raman affiliated with TU Wien (Google Internship)"
    },
    {
      "source": "Karthik Raman",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Karthik Raman affiliated with Google"
    },
    {
      "source": "Karthik Raman",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Karthik Raman affiliated with Google"
    },
    {
      "source": "Karthik Raman",
      "target": "University of Massachusetts Amherst",
      "keywords": "affiliation",
      "description": "Karthik Raman affiliated with University of Massachusetts Amherst"
    },
    {
      "source": "Hamed Zamani",
      "target": "TU Wien (Google Internship)",
      "keywords": "affiliation",
      "description": "Hamed Zamani affiliated with TU Wien (Google Internship)"
    },
    {
      "source": "Hamed Zamani",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Hamed Zamani affiliated with Google"
    },
    {
      "source": "Hamed Zamani",
      "target": "Google",
      "keywords": "affiliation",
      "description": "Hamed Zamani affiliated with Google"
    },
    {
      "source": "Hamed Zamani",
      "target": "University of Massachusetts Amherst",
      "keywords": "affiliation",
      "description": "Hamed Zamani affiliated with University of Massachusetts Amherst"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "GTR-Base",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses GTR-Base"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "T5-Base",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses T5-Base"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "T5-Large",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses T5-Large"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "T5-XL",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses T5-XL"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "FiD",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses FiD"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "FiD-Light",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses FiD-Light"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "HotpotQA",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses HotpotQA"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses TriviaQA"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses Natural Questions"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "FEVER",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses FEVER"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "T-REx",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses T-REx"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "zsRE",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses zsRE"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "Wizard of Wikipedia",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses Wizard of Wikipedia"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "KILT",
      "keywords": "uses",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation uses KILT"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation proposes PipelineRAG"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation proposes DenseRetrieval"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation proposes AbstractiveGeneration"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation proposes SeparateTraining"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to QA"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to DocumentSummarization"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to ConversationalAI"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "Open Domain QA",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to Open Domain QA"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "Fact Verification",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to Fact Verification"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "Slot Filling",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to Slot Filling"
    },
    {
      "source": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation",
      "target": "Dialog Systems",
      "keywords": "applies_to",
      "description": "FiD-Light: Efficient and Effective Retrieval-Augmented Text Generation applies to Dialog Systems"
    },
    {
      "source": "GTR-Base",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on HotpotQA"
    },
    {
      "source": "GTR-Base",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on TriviaQA"
    },
    {
      "source": "GTR-Base",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on Natural Questions"
    },
    {
      "source": "GTR-Base",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on FEVER"
    },
    {
      "source": "GTR-Base",
      "target": "T-REx",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on T-REx"
    },
    {
      "source": "GTR-Base",
      "target": "zsRE",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on zsRE"
    },
    {
      "source": "GTR-Base",
      "target": "Wizard of Wikipedia",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on Wizard of Wikipedia"
    },
    {
      "source": "GTR-Base",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "GTR-Base potentially trained on KILT"
    },
    {
      "source": "T5-Base",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on HotpotQA"
    },
    {
      "source": "T5-Base",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on TriviaQA"
    },
    {
      "source": "T5-Base",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on Natural Questions"
    },
    {
      "source": "T5-Base",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on FEVER"
    },
    {
      "source": "T5-Base",
      "target": "T-REx",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on T-REx"
    },
    {
      "source": "T5-Base",
      "target": "zsRE",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on zsRE"
    },
    {
      "source": "T5-Base",
      "target": "Wizard of Wikipedia",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on Wizard of Wikipedia"
    },
    {
      "source": "T5-Base",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "T5-Base potentially trained on KILT"
    },
    {
      "source": "T5-Large",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on HotpotQA"
    },
    {
      "source": "T5-Large",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on TriviaQA"
    },
    {
      "source": "T5-Large",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on Natural Questions"
    },
    {
      "source": "T5-Large",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on FEVER"
    },
    {
      "source": "T5-Large",
      "target": "T-REx",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on T-REx"
    },
    {
      "source": "T5-Large",
      "target": "zsRE",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on zsRE"
    },
    {
      "source": "T5-Large",
      "target": "Wizard of Wikipedia",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on Wizard of Wikipedia"
    },
    {
      "source": "T5-Large",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "T5-Large potentially trained on KILT"
    },
    {
      "source": "T5-XL",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on HotpotQA"
    },
    {
      "source": "T5-XL",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on TriviaQA"
    },
    {
      "source": "T5-XL",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on Natural Questions"
    },
    {
      "source": "T5-XL",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on FEVER"
    },
    {
      "source": "T5-XL",
      "target": "T-REx",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on T-REx"
    },
    {
      "source": "T5-XL",
      "target": "zsRE",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on zsRE"
    },
    {
      "source": "T5-XL",
      "target": "Wizard of Wikipedia",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on Wizard of Wikipedia"
    },
    {
      "source": "T5-XL",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "T5-XL potentially trained on KILT"
    },
    {
      "source": "FiD",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "FiD potentially trained on HotpotQA"
    },
    {
      "source": "FiD",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "FiD potentially trained on TriviaQA"
    },
    {
      "source": "FiD",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "FiD potentially trained on Natural Questions"
    },
    {
      "source": "FiD",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "FiD potentially trained on FEVER"
    },
    {
      "source": "FiD",
      "target": "T-REx",
      "keywords": "trained_on",
      "description": "FiD potentially trained on T-REx"
    },
    {
      "source": "FiD",
      "target": "zsRE",
      "keywords": "trained_on",
      "description": "FiD potentially trained on zsRE"
    },
    {
      "source": "FiD",
      "target": "Wizard of Wikipedia",
      "keywords": "trained_on",
      "description": "FiD potentially trained on Wizard of Wikipedia"
    },
    {
      "source": "FiD",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "FiD potentially trained on KILT"
    },
    {
      "source": "FiD-Light",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on HotpotQA"
    },
    {
      "source": "FiD-Light",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on TriviaQA"
    },
    {
      "source": "FiD-Light",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on Natural Questions"
    },
    {
      "source": "FiD-Light",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on FEVER"
    },
    {
      "source": "FiD-Light",
      "target": "T-REx",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on T-REx"
    },
    {
      "source": "FiD-Light",
      "target": "zsRE",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on zsRE"
    },
    {
      "source": "FiD-Light",
      "target": "Wizard of Wikipedia",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on Wizard of Wikipedia"
    },
    {
      "source": "FiD-Light",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "FiD-Light potentially trained on KILT"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Boyu Zhang",
      "target": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "keywords": "authorship",
      "description": "Boyu Zhang authored Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "source": "Hongyang (Bruce) Yang",
      "target": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "keywords": "authorship",
      "description": "Hongyang (Bruce) Yang authored Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "source": "Tianyu Zhou",
      "target": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "keywords": "authorship",
      "description": "Tianyu Zhou authored Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "source": "Ali Babar",
      "target": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "keywords": "authorship",
      "description": "Ali Babar authored Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "source": "Xiao-Yang Liu",
      "target": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "keywords": "authorship",
      "description": "Xiao-Yang Liu authored Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via"
    },
    {
      "source": "Boyu Zhang",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Boyu Zhang affiliated with The University of Adelaide"
    },
    {
      "source": "Boyu Zhang",
      "target": "Columbia University",
      "keywords": "affiliation",
      "description": "Boyu Zhang affiliated with Columbia University"
    },
    {
      "source": "Boyu Zhang",
      "target": "Brown University",
      "keywords": "affiliation",
      "description": "Boyu Zhang affiliated with Brown University"
    },
    {
      "source": "Hongyang (Bruce) Yang",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Hongyang (Bruce) Yang affiliated with The University of Adelaide"
    },
    {
      "source": "Hongyang (Bruce) Yang",
      "target": "Columbia University",
      "keywords": "affiliation",
      "description": "Hongyang (Bruce) Yang affiliated with Columbia University"
    },
    {
      "source": "Hongyang (Bruce) Yang",
      "target": "Brown University",
      "keywords": "affiliation",
      "description": "Hongyang (Bruce) Yang affiliated with Brown University"
    },
    {
      "source": "Tianyu Zhou",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Tianyu Zhou affiliated with The University of Adelaide"
    },
    {
      "source": "Tianyu Zhou",
      "target": "Columbia University",
      "keywords": "affiliation",
      "description": "Tianyu Zhou affiliated with Columbia University"
    },
    {
      "source": "Tianyu Zhou",
      "target": "Brown University",
      "keywords": "affiliation",
      "description": "Tianyu Zhou affiliated with Brown University"
    },
    {
      "source": "Ali Babar",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Ali Babar affiliated with The University of Adelaide"
    },
    {
      "source": "Ali Babar",
      "target": "Columbia University",
      "keywords": "affiliation",
      "description": "Ali Babar affiliated with Columbia University"
    },
    {
      "source": "Ali Babar",
      "target": "Brown University",
      "keywords": "affiliation",
      "description": "Ali Babar affiliated with Brown University"
    },
    {
      "source": "Xiao-Yang Liu",
      "target": "The University of Adelaide",
      "keywords": "affiliation",
      "description": "Xiao-Yang Liu affiliated with The University of Adelaide"
    },
    {
      "source": "Xiao-Yang Liu",
      "target": "Columbia University",
      "keywords": "affiliation",
      "description": "Xiao-Yang Liu affiliated with Columbia University"
    },
    {
      "source": "Xiao-Yang Liu",
      "target": "Brown University",
      "keywords": "affiliation",
      "description": "Xiao-Yang Liu affiliated with Brown University"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "Similarity-based retrieval using overlap coefficient",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses Similarity-based retrieval using overlap coefficient"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "LLaMA-7B",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses LLaMA-7B"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "ChatGLM2-6B",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses ChatGLM2-6B"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "ChatGPT 4.0",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses ChatGPT 4.0"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "BloombergGPT",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses BloombergGPT"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "Twitter Financial News dataset",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses Twitter Financial News dataset"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "FiQA dataset",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses FiQA dataset"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "Financial PhraseBank (FPB)",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses Financial PhraseBank (FPB)"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "Twitter Val",
      "keywords": "uses",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via uses Twitter Val"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via proposes PipelineRAG"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via proposes HybridRetrieval"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via proposes FinetuningStrategy"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via applies to QA"
    },
    {
      "source": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Large Language Models: Enhancing Financial Sentiment Analysis via applies to MedicalRAG"
    },
    {
      "source": "Similarity-based retrieval using overlap coefficient",
      "target": "Twitter Financial News dataset",
      "keywords": "trained_on",
      "description": "Similarity-based retrieval using overlap coefficient potentially trained on Twitter Financial News dataset"
    },
    {
      "source": "Similarity-based retrieval using overlap coefficient",
      "target": "FiQA dataset",
      "keywords": "trained_on",
      "description": "Similarity-based retrieval using overlap coefficient potentially trained on FiQA dataset"
    },
    {
      "source": "Similarity-based retrieval using overlap coefficient",
      "target": "Financial PhraseBank (FPB)",
      "keywords": "trained_on",
      "description": "Similarity-based retrieval using overlap coefficient potentially trained on Financial PhraseBank (FPB)"
    },
    {
      "source": "Similarity-based retrieval using overlap coefficient",
      "target": "Twitter Val",
      "keywords": "trained_on",
      "description": "Similarity-based retrieval using overlap coefficient potentially trained on Twitter Val"
    },
    {
      "source": "LLaMA-7B",
      "target": "Twitter Financial News dataset",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on Twitter Financial News dataset"
    },
    {
      "source": "LLaMA-7B",
      "target": "FiQA dataset",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on FiQA dataset"
    },
    {
      "source": "LLaMA-7B",
      "target": "Financial PhraseBank (FPB)",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on Financial PhraseBank (FPB)"
    },
    {
      "source": "LLaMA-7B",
      "target": "Twitter Val",
      "keywords": "trained_on",
      "description": "LLaMA-7B potentially trained on Twitter Val"
    },
    {
      "source": "ChatGLM2-6B",
      "target": "Twitter Financial News dataset",
      "keywords": "trained_on",
      "description": "ChatGLM2-6B potentially trained on Twitter Financial News dataset"
    },
    {
      "source": "ChatGLM2-6B",
      "target": "FiQA dataset",
      "keywords": "trained_on",
      "description": "ChatGLM2-6B potentially trained on FiQA dataset"
    },
    {
      "source": "ChatGLM2-6B",
      "target": "Financial PhraseBank (FPB)",
      "keywords": "trained_on",
      "description": "ChatGLM2-6B potentially trained on Financial PhraseBank (FPB)"
    },
    {
      "source": "ChatGLM2-6B",
      "target": "Twitter Val",
      "keywords": "trained_on",
      "description": "ChatGLM2-6B potentially trained on Twitter Val"
    },
    {
      "source": "ChatGPT 4.0",
      "target": "Twitter Financial News dataset",
      "keywords": "trained_on",
      "description": "ChatGPT 4.0 potentially trained on Twitter Financial News dataset"
    },
    {
      "source": "ChatGPT 4.0",
      "target": "FiQA dataset",
      "keywords": "trained_on",
      "description": "ChatGPT 4.0 potentially trained on FiQA dataset"
    },
    {
      "source": "ChatGPT 4.0",
      "target": "Financial PhraseBank (FPB)",
      "keywords": "trained_on",
      "description": "ChatGPT 4.0 potentially trained on Financial PhraseBank (FPB)"
    },
    {
      "source": "ChatGPT 4.0",
      "target": "Twitter Val",
      "keywords": "trained_on",
      "description": "ChatGPT 4.0 potentially trained on Twitter Val"
    },
    {
      "source": "BloombergGPT",
      "target": "Twitter Financial News dataset",
      "keywords": "trained_on",
      "description": "BloombergGPT potentially trained on Twitter Financial News dataset"
    },
    {
      "source": "BloombergGPT",
      "target": "FiQA dataset",
      "keywords": "trained_on",
      "description": "BloombergGPT potentially trained on FiQA dataset"
    },
    {
      "source": "BloombergGPT",
      "target": "Financial PhraseBank (FPB)",
      "keywords": "trained_on",
      "description": "BloombergGPT potentially trained on Financial PhraseBank (FPB)"
    },
    {
      "source": "BloombergGPT",
      "target": "Twitter Val",
      "keywords": "trained_on",
      "description": "BloombergGPT potentially trained on Twitter Val"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "Gautier Izacard",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Gautier Izacard authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Mathilde Caron",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Mathilde Caron authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Lucas Hosseini authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Sebastian Riedel authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Piotr Bojanowski",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Piotr Bojanowski authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Armand Joulin",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Armand Joulin authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Edouard Grave",
      "target": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "keywords": "authorship",
      "description": "Edouard Grave authored Unsupervised Dense Information Retrieval with Contrastive Learning"
    },
    {
      "source": "Gautier Izacard",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with Meta AI Research"
    },
    {
      "source": "Gautier Izacard",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Gautier Izacard",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with Inria"
    },
    {
      "source": "Gautier Izacard",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Gautier Izacard",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with University College London"
    },
    {
      "source": "Mathilde Caron",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Mathilde Caron affiliated with Meta AI Research"
    },
    {
      "source": "Mathilde Caron",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Mathilde Caron affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Mathilde Caron",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Mathilde Caron affiliated with Inria"
    },
    {
      "source": "Mathilde Caron",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Mathilde Caron affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Mathilde Caron",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Mathilde Caron affiliated with University College London"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with Meta AI Research"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with Inria"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Lucas Hosseini",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with University College London"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Meta AI Research"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Inria"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Sebastian Riedel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with University College London"
    },
    {
      "source": "Piotr Bojanowski",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Piotr Bojanowski affiliated with Meta AI Research"
    },
    {
      "source": "Piotr Bojanowski",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Piotr Bojanowski affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Piotr Bojanowski",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Piotr Bojanowski affiliated with Inria"
    },
    {
      "source": "Piotr Bojanowski",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Piotr Bojanowski affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Piotr Bojanowski",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Piotr Bojanowski affiliated with University College London"
    },
    {
      "source": "Armand Joulin",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with Meta AI Research"
    },
    {
      "source": "Armand Joulin",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Armand Joulin",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with Inria"
    },
    {
      "source": "Armand Joulin",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Armand Joulin",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with University College London"
    },
    {
      "source": "Edouard Grave",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with Meta AI Research"
    },
    {
      "source": "Edouard Grave",
      "target": "Ecole normale supérieure, PSL University",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with Ecole normale supérieure, PSL University"
    },
    {
      "source": "Edouard Grave",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with Inria"
    },
    {
      "source": "Edouard Grave",
      "target": "Université Grenoble Alpes",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with Université Grenoble Alpes"
    },
    {
      "source": "Edouard Grave",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with University College London"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "Contriever",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses Contriever"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "mContriever",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses mContriever"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "BERT",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses BERT"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "BEIR",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses BEIR"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses Natural Questions"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses TriviaQA"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "MS MARCO",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses MS MARCO"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "Mr. TyDi",
      "keywords": "uses",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning uses Mr. TyDi"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning proposes PipelineRAG"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning proposes DenseRetrieval"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "Not applicable",
      "keywords": "proposes",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning proposes Not applicable"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning proposes SeparateTraining"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning applies to QA"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning applies to DocumentSummarization"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning applies to MedicalRAG"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning applies to LegalRAG"
    },
    {
      "source": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Unsupervised Dense Information Retrieval with Contrastive Learning applies to EducationalRAG"
    },
    {
      "source": "Contriever",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on BEIR"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions"
    },
    {
      "source": "Contriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on TriviaQA"
    },
    {
      "source": "Contriever",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on MS MARCO"
    },
    {
      "source": "Contriever",
      "target": "Mr. TyDi",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Mr. TyDi"
    },
    {
      "source": "mContriever",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "mContriever potentially trained on BEIR"
    },
    {
      "source": "mContriever",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "mContriever potentially trained on Natural Questions"
    },
    {
      "source": "mContriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "mContriever potentially trained on TriviaQA"
    },
    {
      "source": "mContriever",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "mContriever potentially trained on MS MARCO"
    },
    {
      "source": "mContriever",
      "target": "Mr. TyDi",
      "keywords": "trained_on",
      "description": "mContriever potentially trained on Mr. TyDi"
    },
    {
      "source": "BERT",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BERT potentially trained on BEIR"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "BERT",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TriviaQA"
    },
    {
      "source": "BERT",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MS MARCO"
    },
    {
      "source": "BERT",
      "target": "Mr. TyDi",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Mr. TyDi"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "Not applicable",
      "target": "QA",
      "keywords": "supports",
      "description": "Not applicable supports QA"
    },
    {
      "source": "Not applicable",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "Not applicable supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Michihiro Yasunaga authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Armen Aghajanyan",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Armen Aghajanyan authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Weijia Shi",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Weijia Shi authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Rich James",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Rich James authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Jure Leskovec",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Jure Leskovec authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Percy Liang",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Percy Liang authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Mike Lewis",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Mike Lewis authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Luke Zettlemoyer authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Retrieval-Augmented Multimodal Language Modeling",
      "keywords": "authorship",
      "description": "Wen-tau Yih authored Retrieval-Augmented Multimodal Language Modeling"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with Stanford University"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with Meta AI"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with University of Washington"
    },
    {
      "source": "Armen Aghajanyan",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Armen Aghajanyan affiliated with Stanford University"
    },
    {
      "source": "Armen Aghajanyan",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Armen Aghajanyan affiliated with Meta AI"
    },
    {
      "source": "Armen Aghajanyan",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Armen Aghajanyan affiliated with University of Washington"
    },
    {
      "source": "Weijia Shi",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with Stanford University"
    },
    {
      "source": "Weijia Shi",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with Meta AI"
    },
    {
      "source": "Weijia Shi",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with University of Washington"
    },
    {
      "source": "Rich James",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Rich James affiliated with Stanford University"
    },
    {
      "source": "Rich James",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Rich James affiliated with Meta AI"
    },
    {
      "source": "Rich James",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Rich James affiliated with University of Washington"
    },
    {
      "source": "Jure Leskovec",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Jure Leskovec affiliated with Stanford University"
    },
    {
      "source": "Jure Leskovec",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Jure Leskovec affiliated with Meta AI"
    },
    {
      "source": "Jure Leskovec",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Jure Leskovec affiliated with University of Washington"
    },
    {
      "source": "Percy Liang",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Percy Liang affiliated with Stanford University"
    },
    {
      "source": "Percy Liang",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Percy Liang affiliated with Meta AI"
    },
    {
      "source": "Percy Liang",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Percy Liang affiliated with University of Washington"
    },
    {
      "source": "Mike Lewis",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Stanford University"
    },
    {
      "source": "Mike Lewis",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Meta AI"
    },
    {
      "source": "Mike Lewis",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with University of Washington"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with Stanford University"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with Meta AI"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with University of Washington"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Stanford University"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Meta AI"
    },
    {
      "source": "Wen-tau Yih",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with University of Washington"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "CLIP-based mixed-modal encoder",
      "keywords": "uses",
      "description": "Retrieval-Augmented Multimodal Language Modeling uses CLIP-based mixed-modal encoder"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "RA-CM3",
      "keywords": "uses",
      "description": "Retrieval-Augmented Multimodal Language Modeling uses RA-CM3"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "CM3",
      "keywords": "uses",
      "description": "Retrieval-Augmented Multimodal Language Modeling uses CM3"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "LAION",
      "keywords": "uses",
      "description": "Retrieval-Augmented Multimodal Language Modeling uses LAION"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "MS-COCO",
      "keywords": "uses",
      "description": "Retrieval-Augmented Multimodal Language Modeling uses MS-COCO"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Multimodal Language Modeling proposes PipelineRAG"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Multimodal Language Modeling proposes DenseRetrieval"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Multimodal Language Modeling proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Multimodal Language Modeling proposes JointTraining"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Multimodal Language Modeling applies to QA"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Multimodal Language Modeling applies to DocumentSummarization"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Multimodal Language Modeling applies to ConversationalAI"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "Knowledge-intensive generation",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Multimodal Language Modeling applies to Knowledge-intensive generation"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "Controlled image generation",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Multimodal Language Modeling applies to Controlled image generation"
    },
    {
      "source": "Retrieval-Augmented Multimodal Language Modeling",
      "target": "Image editing and infilling",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Multimodal Language Modeling applies to Image editing and infilling"
    },
    {
      "source": "CLIP-based mixed-modal encoder",
      "target": "LAION",
      "keywords": "trained_on",
      "description": "CLIP-based mixed-modal encoder potentially trained on LAION"
    },
    {
      "source": "CLIP-based mixed-modal encoder",
      "target": "MS-COCO",
      "keywords": "trained_on",
      "description": "CLIP-based mixed-modal encoder potentially trained on MS-COCO"
    },
    {
      "source": "RA-CM3",
      "target": "LAION",
      "keywords": "trained_on",
      "description": "RA-CM3 potentially trained on LAION"
    },
    {
      "source": "RA-CM3",
      "target": "MS-COCO",
      "keywords": "trained_on",
      "description": "RA-CM3 potentially trained on MS-COCO"
    },
    {
      "source": "CM3",
      "target": "LAION",
      "keywords": "trained_on",
      "description": "CM3 potentially trained on LAION"
    },
    {
      "source": "CM3",
      "target": "MS-COCO",
      "keywords": "trained_on",
      "description": "CM3 potentially trained on MS-COCO"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Sean MacAvaney",
      "target": "Expansion via Prediction of Importance with Contextualization",
      "keywords": "authorship",
      "description": "Sean MacAvaney authored Expansion via Prediction of Importance with Contextualization"
    },
    {
      "source": "Franco Maria Nardini",
      "target": "Expansion via Prediction of Importance with Contextualization",
      "keywords": "authorship",
      "description": "Franco Maria Nardini authored Expansion via Prediction of Importance with Contextualization"
    },
    {
      "source": "Raffaele Perego",
      "target": "Expansion via Prediction of Importance with Contextualization",
      "keywords": "authorship",
      "description": "Raffaele Perego authored Expansion via Prediction of Importance with Contextualization"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "Expansion via Prediction of Importance with Contextualization",
      "keywords": "authorship",
      "description": "Nicola Tonellotto authored Expansion via Prediction of Importance with Contextualization"
    },
    {
      "source": "Nazli Goharian",
      "target": "Expansion via Prediction of Importance with Contextualization",
      "keywords": "authorship",
      "description": "Nazli Goharian authored Expansion via Prediction of Importance with Contextualization"
    },
    {
      "source": "Ophir Frieder",
      "target": "Expansion via Prediction of Importance with Contextualization",
      "keywords": "authorship",
      "description": "Ophir Frieder authored Expansion via Prediction of Importance with Contextualization"
    },
    {
      "source": "Sean MacAvaney",
      "target": "IR Lab, Georgetown University, USA",
      "keywords": "affiliation",
      "description": "Sean MacAvaney affiliated with IR Lab, Georgetown University, USA"
    },
    {
      "source": "Sean MacAvaney",
      "target": "ISTI-CNR, Pisa, Italy",
      "keywords": "affiliation",
      "description": "Sean MacAvaney affiliated with ISTI-CNR, Pisa, Italy"
    },
    {
      "source": "Sean MacAvaney",
      "target": "University of Pisa, Italy",
      "keywords": "affiliation",
      "description": "Sean MacAvaney affiliated with University of Pisa, Italy"
    },
    {
      "source": "Franco Maria Nardini",
      "target": "IR Lab, Georgetown University, USA",
      "keywords": "affiliation",
      "description": "Franco Maria Nardini affiliated with IR Lab, Georgetown University, USA"
    },
    {
      "source": "Franco Maria Nardini",
      "target": "ISTI-CNR, Pisa, Italy",
      "keywords": "affiliation",
      "description": "Franco Maria Nardini affiliated with ISTI-CNR, Pisa, Italy"
    },
    {
      "source": "Franco Maria Nardini",
      "target": "University of Pisa, Italy",
      "keywords": "affiliation",
      "description": "Franco Maria Nardini affiliated with University of Pisa, Italy"
    },
    {
      "source": "Raffaele Perego",
      "target": "IR Lab, Georgetown University, USA",
      "keywords": "affiliation",
      "description": "Raffaele Perego affiliated with IR Lab, Georgetown University, USA"
    },
    {
      "source": "Raffaele Perego",
      "target": "ISTI-CNR, Pisa, Italy",
      "keywords": "affiliation",
      "description": "Raffaele Perego affiliated with ISTI-CNR, Pisa, Italy"
    },
    {
      "source": "Raffaele Perego",
      "target": "University of Pisa, Italy",
      "keywords": "affiliation",
      "description": "Raffaele Perego affiliated with University of Pisa, Italy"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "IR Lab, Georgetown University, USA",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with IR Lab, Georgetown University, USA"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "ISTI-CNR, Pisa, Italy",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with ISTI-CNR, Pisa, Italy"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "University of Pisa, Italy",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with University of Pisa, Italy"
    },
    {
      "source": "Nazli Goharian",
      "target": "IR Lab, Georgetown University, USA",
      "keywords": "affiliation",
      "description": "Nazli Goharian affiliated with IR Lab, Georgetown University, USA"
    },
    {
      "source": "Nazli Goharian",
      "target": "ISTI-CNR, Pisa, Italy",
      "keywords": "affiliation",
      "description": "Nazli Goharian affiliated with ISTI-CNR, Pisa, Italy"
    },
    {
      "source": "Nazli Goharian",
      "target": "University of Pisa, Italy",
      "keywords": "affiliation",
      "description": "Nazli Goharian affiliated with University of Pisa, Italy"
    },
    {
      "source": "Ophir Frieder",
      "target": "IR Lab, Georgetown University, USA",
      "keywords": "affiliation",
      "description": "Ophir Frieder affiliated with IR Lab, Georgetown University, USA"
    },
    {
      "source": "Ophir Frieder",
      "target": "ISTI-CNR, Pisa, Italy",
      "keywords": "affiliation",
      "description": "Ophir Frieder affiliated with ISTI-CNR, Pisa, Italy"
    },
    {
      "source": "Ophir Frieder",
      "target": "University of Pisa, Italy",
      "keywords": "affiliation",
      "description": "Ophir Frieder affiliated with University of Pisa, Italy"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "BERT-base",
      "keywords": "uses",
      "description": "Expansion via Prediction of Importance with Contextualization uses BERT-base"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "EPIC",
      "keywords": "uses",
      "description": "Expansion via Prediction of Importance with Contextualization uses EPIC"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "MS-MARCO passage ranking dataset",
      "keywords": "uses",
      "description": "Expansion via Prediction of Importance with Contextualization uses MS-MARCO passage ranking dataset"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "TREC CAR passage ranking benchmark",
      "keywords": "uses",
      "description": "Expansion via Prediction of Importance with Contextualization uses TREC CAR passage ranking benchmark"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Expansion via Prediction of Importance with Contextualization proposes PipelineRAG"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Expansion via Prediction of Importance with Contextualization proposes HybridRetrieval"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Expansion via Prediction of Importance with Contextualization proposes AbstractiveGeneration"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Expansion via Prediction of Importance with Contextualization proposes FinetuningStrategy"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Expansion via Prediction of Importance with Contextualization applies to QA"
    },
    {
      "source": "Expansion via Prediction of Importance with Contextualization",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Expansion via Prediction of Importance with Contextualization applies to DocumentSummarization"
    },
    {
      "source": "BERT-base",
      "target": "MS-MARCO passage ranking dataset",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on MS-MARCO passage ranking dataset"
    },
    {
      "source": "BERT-base",
      "target": "TREC CAR passage ranking benchmark",
      "keywords": "trained_on",
      "description": "BERT-base potentially trained on TREC CAR passage ranking benchmark"
    },
    {
      "source": "EPIC",
      "target": "MS-MARCO passage ranking dataset",
      "keywords": "trained_on",
      "description": "EPIC potentially trained on MS-MARCO passage ranking dataset"
    },
    {
      "source": "EPIC",
      "target": "TREC CAR passage ranking benchmark",
      "keywords": "trained_on",
      "description": "EPIC potentially trained on TREC CAR passage ranking benchmark"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "Gautier Izacard",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Gautier Izacard authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Patrick Lewis",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Patrick Lewis authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Maria Lomeli",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Maria Lomeli authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Lucas Hosseini authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Fabio Petroni",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Fabio Petroni authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Timo Schick",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Timo Schick authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Jane Dwivedi-Yu",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Jane Dwivedi-Yu authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Armand Joulin",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Armand Joulin authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Sebastian Riedel authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Edouard Grave",
      "target": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "keywords": "authorship",
      "description": "Edouard Grave authored Atlas: Few-shot Learning with Retrieval Augmented Language Models"
    },
    {
      "source": "Gautier Izacard",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with Meta AI Research"
    },
    {
      "source": "Gautier Izacard",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with ENS, PSL University"
    },
    {
      "source": "Gautier Izacard",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with Inria"
    },
    {
      "source": "Gautier Izacard",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Gautier Izacard affiliated with University College London"
    },
    {
      "source": "Patrick Lewis",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with Meta AI Research"
    },
    {
      "source": "Patrick Lewis",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with ENS, PSL University"
    },
    {
      "source": "Patrick Lewis",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with Inria"
    },
    {
      "source": "Patrick Lewis",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with University College London"
    },
    {
      "source": "Maria Lomeli",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Maria Lomeli affiliated with Meta AI Research"
    },
    {
      "source": "Maria Lomeli",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Maria Lomeli affiliated with ENS, PSL University"
    },
    {
      "source": "Maria Lomeli",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Maria Lomeli affiliated with Inria"
    },
    {
      "source": "Maria Lomeli",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Maria Lomeli affiliated with University College London"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with Meta AI Research"
    },
    {
      "source": "Lucas Hosseini",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with ENS, PSL University"
    },
    {
      "source": "Lucas Hosseini",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with Inria"
    },
    {
      "source": "Lucas Hosseini",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Lucas Hosseini affiliated with University College London"
    },
    {
      "source": "Fabio Petroni",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with Meta AI Research"
    },
    {
      "source": "Fabio Petroni",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with ENS, PSL University"
    },
    {
      "source": "Fabio Petroni",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with Inria"
    },
    {
      "source": "Fabio Petroni",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with University College London"
    },
    {
      "source": "Timo Schick",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Timo Schick affiliated with Meta AI Research"
    },
    {
      "source": "Timo Schick",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Timo Schick affiliated with ENS, PSL University"
    },
    {
      "source": "Timo Schick",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Timo Schick affiliated with Inria"
    },
    {
      "source": "Timo Schick",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Timo Schick affiliated with University College London"
    },
    {
      "source": "Jane Dwivedi-Yu",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Jane Dwivedi-Yu affiliated with Meta AI Research"
    },
    {
      "source": "Jane Dwivedi-Yu",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Jane Dwivedi-Yu affiliated with ENS, PSL University"
    },
    {
      "source": "Jane Dwivedi-Yu",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Jane Dwivedi-Yu affiliated with Inria"
    },
    {
      "source": "Jane Dwivedi-Yu",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Jane Dwivedi-Yu affiliated with University College London"
    },
    {
      "source": "Armand Joulin",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with Meta AI Research"
    },
    {
      "source": "Armand Joulin",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with ENS, PSL University"
    },
    {
      "source": "Armand Joulin",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with Inria"
    },
    {
      "source": "Armand Joulin",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Armand Joulin affiliated with University College London"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Meta AI Research"
    },
    {
      "source": "Sebastian Riedel",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with ENS, PSL University"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Inria"
    },
    {
      "source": "Sebastian Riedel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with University College London"
    },
    {
      "source": "Edouard Grave",
      "target": "Meta AI Research",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with Meta AI Research"
    },
    {
      "source": "Edouard Grave",
      "target": "ENS, PSL University",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with ENS, PSL University"
    },
    {
      "source": "Edouard Grave",
      "target": "Inria",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with Inria"
    },
    {
      "source": "Edouard Grave",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Edouard Grave affiliated with University College London"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "Contriever",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses Contriever"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "T5",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses T5"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses Natural Questions"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses TriviaQA"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "FEVER",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses FEVER"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "MMLU",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses MMLU"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "KILT",
      "keywords": "uses",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models uses KILT"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models proposes PipelineRAG"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models proposes DenseRetrieval"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models proposes AbstractiveGeneration"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models proposes JointTraining"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models applies to QA"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models applies to DocumentSummarization"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models applies to ConversationalAI"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models applies to MedicalRAG"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models applies to LegalRAG"
    },
    {
      "source": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Atlas: Few-shot Learning with Retrieval Augmented Language Models applies to EducationalRAG"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions"
    },
    {
      "source": "Contriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on TriviaQA"
    },
    {
      "source": "Contriever",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on FEVER"
    },
    {
      "source": "Contriever",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on MMLU"
    },
    {
      "source": "Contriever",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on KILT"
    },
    {
      "source": "T5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions"
    },
    {
      "source": "T5",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on TriviaQA"
    },
    {
      "source": "T5",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "T5 potentially trained on FEVER"
    },
    {
      "source": "T5",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "T5 potentially trained on MMLU"
    },
    {
      "source": "T5",
      "target": "KILT",
      "keywords": "trained_on",
      "description": "T5 potentially trained on KILT"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Jakub Lála",
      "target": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "keywords": "authorship",
      "description": "Jakub Lála authored PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "source": "Odhran O'Donoghue",
      "target": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "keywords": "authorship",
      "description": "Odhran O'Donoghue authored PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "source": "Aleksandar Shtedritski",
      "target": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "keywords": "authorship",
      "description": "Aleksandar Shtedritski authored PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "source": "Sam Cox",
      "target": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "keywords": "authorship",
      "description": "Sam Cox authored PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "source": "Samuel G Rodriques",
      "target": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "keywords": "authorship",
      "description": "Samuel G Rodriques authored PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "source": "Andrew D White",
      "target": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "keywords": "authorship",
      "description": "Andrew D White authored PaperQA: Retrieval-Augmented Generative Agent for Scientific Research"
    },
    {
      "source": "Jakub Lála",
      "target": "Future House",
      "keywords": "affiliation",
      "description": "Jakub Lála affiliated with Future House"
    },
    {
      "source": "Jakub Lála",
      "target": "Align to Innovate",
      "keywords": "affiliation",
      "description": "Jakub Lála affiliated with Align to Innovate"
    },
    {
      "source": "Jakub Lála",
      "target": "Francis Crick Institute",
      "keywords": "affiliation",
      "description": "Jakub Lála affiliated with Francis Crick Institute"
    },
    {
      "source": "Jakub Lála",
      "target": "University of Oxford",
      "keywords": "affiliation",
      "description": "Jakub Lála affiliated with University of Oxford"
    },
    {
      "source": "Jakub Lála",
      "target": "University of Rochester",
      "keywords": "affiliation",
      "description": "Jakub Lála affiliated with University of Rochester"
    },
    {
      "source": "Odhran O'Donoghue",
      "target": "Future House",
      "keywords": "affiliation",
      "description": "Odhran O'Donoghue affiliated with Future House"
    },
    {
      "source": "Odhran O'Donoghue",
      "target": "Align to Innovate",
      "keywords": "affiliation",
      "description": "Odhran O'Donoghue affiliated with Align to Innovate"
    },
    {
      "source": "Odhran O'Donoghue",
      "target": "Francis Crick Institute",
      "keywords": "affiliation",
      "description": "Odhran O'Donoghue affiliated with Francis Crick Institute"
    },
    {
      "source": "Odhran O'Donoghue",
      "target": "University of Oxford",
      "keywords": "affiliation",
      "description": "Odhran O'Donoghue affiliated with University of Oxford"
    },
    {
      "source": "Odhran O'Donoghue",
      "target": "University of Rochester",
      "keywords": "affiliation",
      "description": "Odhran O'Donoghue affiliated with University of Rochester"
    },
    {
      "source": "Aleksandar Shtedritski",
      "target": "Future House",
      "keywords": "affiliation",
      "description": "Aleksandar Shtedritski affiliated with Future House"
    },
    {
      "source": "Aleksandar Shtedritski",
      "target": "Align to Innovate",
      "keywords": "affiliation",
      "description": "Aleksandar Shtedritski affiliated with Align to Innovate"
    },
    {
      "source": "Aleksandar Shtedritski",
      "target": "Francis Crick Institute",
      "keywords": "affiliation",
      "description": "Aleksandar Shtedritski affiliated with Francis Crick Institute"
    },
    {
      "source": "Aleksandar Shtedritski",
      "target": "University of Oxford",
      "keywords": "affiliation",
      "description": "Aleksandar Shtedritski affiliated with University of Oxford"
    },
    {
      "source": "Aleksandar Shtedritski",
      "target": "University of Rochester",
      "keywords": "affiliation",
      "description": "Aleksandar Shtedritski affiliated with University of Rochester"
    },
    {
      "source": "Sam Cox",
      "target": "Future House",
      "keywords": "affiliation",
      "description": "Sam Cox affiliated with Future House"
    },
    {
      "source": "Sam Cox",
      "target": "Align to Innovate",
      "keywords": "affiliation",
      "description": "Sam Cox affiliated with Align to Innovate"
    },
    {
      "source": "Sam Cox",
      "target": "Francis Crick Institute",
      "keywords": "affiliation",
      "description": "Sam Cox affiliated with Francis Crick Institute"
    },
    {
      "source": "Sam Cox",
      "target": "University of Oxford",
      "keywords": "affiliation",
      "description": "Sam Cox affiliated with University of Oxford"
    },
    {
      "source": "Sam Cox",
      "target": "University of Rochester",
      "keywords": "affiliation",
      "description": "Sam Cox affiliated with University of Rochester"
    },
    {
      "source": "Samuel G Rodriques",
      "target": "Future House",
      "keywords": "affiliation",
      "description": "Samuel G Rodriques affiliated with Future House"
    },
    {
      "source": "Samuel G Rodriques",
      "target": "Align to Innovate",
      "keywords": "affiliation",
      "description": "Samuel G Rodriques affiliated with Align to Innovate"
    },
    {
      "source": "Samuel G Rodriques",
      "target": "Francis Crick Institute",
      "keywords": "affiliation",
      "description": "Samuel G Rodriques affiliated with Francis Crick Institute"
    },
    {
      "source": "Samuel G Rodriques",
      "target": "University of Oxford",
      "keywords": "affiliation",
      "description": "Samuel G Rodriques affiliated with University of Oxford"
    },
    {
      "source": "Samuel G Rodriques",
      "target": "University of Rochester",
      "keywords": "affiliation",
      "description": "Samuel G Rodriques affiliated with University of Rochester"
    },
    {
      "source": "Andrew D White",
      "target": "Future House",
      "keywords": "affiliation",
      "description": "Andrew D White affiliated with Future House"
    },
    {
      "source": "Andrew D White",
      "target": "Align to Innovate",
      "keywords": "affiliation",
      "description": "Andrew D White affiliated with Align to Innovate"
    },
    {
      "source": "Andrew D White",
      "target": "Francis Crick Institute",
      "keywords": "affiliation",
      "description": "Andrew D White affiliated with Francis Crick Institute"
    },
    {
      "source": "Andrew D White",
      "target": "University of Oxford",
      "keywords": "affiliation",
      "description": "Andrew D White affiliated with University of Oxford"
    },
    {
      "source": "Andrew D White",
      "target": "University of Rochester",
      "keywords": "affiliation",
      "description": "Andrew D White affiliated with University of Rochester"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "text-embedding-ada-002",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses text-embedding-ada-002"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses GPT-4"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "GPT-3.5-turbo",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses GPT-3.5-turbo"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "Claude-2",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses Claude-2"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "LitQA",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses LitQA"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "PubMedQA",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses PubMedQA"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "MedQA-USMLE",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses MedQA-USMLE"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "BioASQ",
      "keywords": "uses",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research uses BioASQ"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "ModularRAG",
      "keywords": "proposes",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research proposes ModularRAG"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research proposes HybridRetrieval"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research proposes AbstractiveGeneration"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research proposes SeparateTraining"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "QA",
      "keywords": "applies_to",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research applies to QA"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research applies to DocumentSummarization"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research applies to MedicalRAG"
    },
    {
      "source": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research",
      "target": "ScientificResearch",
      "keywords": "applies_to",
      "description": "PaperQA: Retrieval-Augmented Generative Agent for Scientific Research applies to ScientificResearch"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "LitQA",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on LitQA"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on PubMedQA"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "MedQA-USMLE",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on MedQA-USMLE"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on BioASQ"
    },
    {
      "source": "GPT-4",
      "target": "LitQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on LitQA"
    },
    {
      "source": "GPT-4",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on PubMedQA"
    },
    {
      "source": "GPT-4",
      "target": "MedQA-USMLE",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on MedQA-USMLE"
    },
    {
      "source": "GPT-4",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on BioASQ"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "LitQA",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on LitQA"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on PubMedQA"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "MedQA-USMLE",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on MedQA-USMLE"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on BioASQ"
    },
    {
      "source": "Claude-2",
      "target": "LitQA",
      "keywords": "trained_on",
      "description": "Claude-2 potentially trained on LitQA"
    },
    {
      "source": "Claude-2",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "Claude-2 potentially trained on PubMedQA"
    },
    {
      "source": "Claude-2",
      "target": "MedQA-USMLE",
      "keywords": "trained_on",
      "description": "Claude-2 potentially trained on MedQA-USMLE"
    },
    {
      "source": "Claude-2",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "Claude-2 potentially trained on BioASQ"
    },
    {
      "source": "ModularRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "ModularRAG supports QA"
    },
    {
      "source": "ModularRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "ModularRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "S.M Towhidul Islam Tonmoy",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "S.M Towhidul Islam Tonmoy authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "S M Mehedi Zaman",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "S M Mehedi Zaman authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "Vinija Jain",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "Vinija Jain authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "Anku Rani",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "Anku Rani authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "Vipula Rawte",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "Vipula Rawte authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "Aman Chadha",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "Aman Chadha authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "Amitava Das",
      "target": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "keywords": "authorship",
      "description": "Amitava Das authored A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models"
    },
    {
      "source": "S.M Towhidul Islam Tonmoy",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "S.M Towhidul Islam Tonmoy affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "S.M Towhidul Islam Tonmoy",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "S.M Towhidul Islam Tonmoy affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "S.M Towhidul Islam Tonmoy",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "S.M Towhidul Islam Tonmoy affiliated with Stanford University, USA"
    },
    {
      "source": "S.M Towhidul Islam Tonmoy",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "S.M Towhidul Islam Tonmoy affiliated with Amazon AI, USA"
    },
    {
      "source": "S M Mehedi Zaman",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "S M Mehedi Zaman affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "S M Mehedi Zaman",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "S M Mehedi Zaman affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "S M Mehedi Zaman",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "S M Mehedi Zaman affiliated with Stanford University, USA"
    },
    {
      "source": "S M Mehedi Zaman",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "S M Mehedi Zaman affiliated with Amazon AI, USA"
    },
    {
      "source": "Vinija Jain",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "Vinija Jain affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "Vinija Jain",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "Vinija Jain affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "Vinija Jain",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "Vinija Jain affiliated with Stanford University, USA"
    },
    {
      "source": "Vinija Jain",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "Vinija Jain affiliated with Amazon AI, USA"
    },
    {
      "source": "Anku Rani",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "Anku Rani affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "Anku Rani",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "Anku Rani affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "Anku Rani",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "Anku Rani affiliated with Stanford University, USA"
    },
    {
      "source": "Anku Rani",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "Anku Rani affiliated with Amazon AI, USA"
    },
    {
      "source": "Vipula Rawte",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "Vipula Rawte affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "Vipula Rawte",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "Vipula Rawte affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "Vipula Rawte",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "Vipula Rawte affiliated with Stanford University, USA"
    },
    {
      "source": "Vipula Rawte",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "Vipula Rawte affiliated with Amazon AI, USA"
    },
    {
      "source": "Aman Chadha",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "Aman Chadha affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "Aman Chadha",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "Aman Chadha affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "Aman Chadha",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "Aman Chadha affiliated with Stanford University, USA"
    },
    {
      "source": "Aman Chadha",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "Aman Chadha affiliated with Amazon AI, USA"
    },
    {
      "source": "Amitava Das",
      "target": "Islamic University of Technology, Bangladesh",
      "keywords": "affiliation",
      "description": "Amitava Das affiliated with Islamic University of Technology, Bangladesh"
    },
    {
      "source": "Amitava Das",
      "target": "AI Institute, University of South Carolina, USA",
      "keywords": "affiliation",
      "description": "Amitava Das affiliated with AI Institute, University of South Carolina, USA"
    },
    {
      "source": "Amitava Das",
      "target": "Stanford University, USA",
      "keywords": "affiliation",
      "description": "Amitava Das affiliated with Stanford University, USA"
    },
    {
      "source": "Amitava Das",
      "target": "Amazon AI, USA",
      "keywords": "affiliation",
      "description": "Amitava Das affiliated with Amazon AI, USA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "Dense Passage Retriever (DPR)",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses Dense Passage Retriever (DPR)"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "BERT",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses BERT"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses GPT-3"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "GPT-3.5",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses GPT-3.5"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses GPT-4"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "T5",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses T5"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "BART",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses BART"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "LLaMA",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses LLaMA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses Natural Questions (NQ)"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses TriviaQA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "HotPotQA",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses HotPotQA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "TruthfulQA",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses TruthfulQA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "FreshQA",
      "keywords": "uses",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models uses FreshQA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models proposes PipelineRAG"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models proposes DenseRetrieval"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models proposes HybridGeneration"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models proposes SeparateTraining"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "QA",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models applies to QA"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models applies to DocumentSummarization"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models applies to ConversationalAI"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models applies to MedicalRAG"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models applies to LegalRAG"
    },
    {
      "source": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models applies to EducationalRAG"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on TriviaQA"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on HotPotQA"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on TruthfulQA"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on FreshQA"
    },
    {
      "source": "BERT",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BERT",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TriviaQA"
    },
    {
      "source": "BERT",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on HotPotQA"
    },
    {
      "source": "BERT",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TruthfulQA"
    },
    {
      "source": "BERT",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on FreshQA"
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on HotPotQA"
    },
    {
      "source": "GPT-3",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TruthfulQA"
    },
    {
      "source": "GPT-3",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on FreshQA"
    },
    {
      "source": "GPT-3.5",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-3.5",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3.5",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on HotPotQA"
    },
    {
      "source": "GPT-3.5",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on TruthfulQA"
    },
    {
      "source": "GPT-3.5",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on FreshQA"
    },
    {
      "source": "GPT-4",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "GPT-4",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-4",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on HotPotQA"
    },
    {
      "source": "GPT-4",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on TruthfulQA"
    },
    {
      "source": "GPT-4",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on FreshQA"
    },
    {
      "source": "T5",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "T5",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on TriviaQA"
    },
    {
      "source": "T5",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on HotPotQA"
    },
    {
      "source": "T5",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on TruthfulQA"
    },
    {
      "source": "T5",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on FreshQA"
    },
    {
      "source": "BART",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BART",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on TriviaQA"
    },
    {
      "source": "BART",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on HotPotQA"
    },
    {
      "source": "BART",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on TruthfulQA"
    },
    {
      "source": "BART",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on FreshQA"
    },
    {
      "source": "LLaMA",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "LLaMA",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on TriviaQA"
    },
    {
      "source": "LLaMA",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on HotPotQA"
    },
    {
      "source": "LLaMA",
      "target": "TruthfulQA",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on TruthfulQA"
    },
    {
      "source": "LLaMA",
      "target": "FreshQA",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on FreshQA"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridGeneration supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "Norbert Tihanyi",
      "target": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "keywords": "authorship",
      "description": "Norbert Tihanyi authored CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "source": "Mohamed Amine Ferrag",
      "target": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "keywords": "authorship",
      "description": "Mohamed Amine Ferrag authored CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "source": "Ridhi Jain",
      "target": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "keywords": "authorship",
      "description": "Ridhi Jain authored CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "source": "Tamas Bisztray",
      "target": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "keywords": "authorship",
      "description": "Tamas Bisztray authored CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "source": "Merouane Debbah",
      "target": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "keywords": "authorship",
      "description": "Merouane Debbah authored CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge"
    },
    {
      "source": "Norbert Tihanyi",
      "target": "Technology Innovation Institute (TII)",
      "keywords": "affiliation",
      "description": "Norbert Tihanyi affiliated with Technology Innovation Institute (TII)"
    },
    {
      "source": "Norbert Tihanyi",
      "target": "University of Oslo",
      "keywords": "affiliation",
      "description": "Norbert Tihanyi affiliated with University of Oslo"
    },
    {
      "source": "Norbert Tihanyi",
      "target": "Khalifa University",
      "keywords": "affiliation",
      "description": "Norbert Tihanyi affiliated with Khalifa University"
    },
    {
      "source": "Mohamed Amine Ferrag",
      "target": "Technology Innovation Institute (TII)",
      "keywords": "affiliation",
      "description": "Mohamed Amine Ferrag affiliated with Technology Innovation Institute (TII)"
    },
    {
      "source": "Mohamed Amine Ferrag",
      "target": "University of Oslo",
      "keywords": "affiliation",
      "description": "Mohamed Amine Ferrag affiliated with University of Oslo"
    },
    {
      "source": "Mohamed Amine Ferrag",
      "target": "Khalifa University",
      "keywords": "affiliation",
      "description": "Mohamed Amine Ferrag affiliated with Khalifa University"
    },
    {
      "source": "Ridhi Jain",
      "target": "Technology Innovation Institute (TII)",
      "keywords": "affiliation",
      "description": "Ridhi Jain affiliated with Technology Innovation Institute (TII)"
    },
    {
      "source": "Ridhi Jain",
      "target": "University of Oslo",
      "keywords": "affiliation",
      "description": "Ridhi Jain affiliated with University of Oslo"
    },
    {
      "source": "Ridhi Jain",
      "target": "Khalifa University",
      "keywords": "affiliation",
      "description": "Ridhi Jain affiliated with Khalifa University"
    },
    {
      "source": "Tamas Bisztray",
      "target": "Technology Innovation Institute (TII)",
      "keywords": "affiliation",
      "description": "Tamas Bisztray affiliated with Technology Innovation Institute (TII)"
    },
    {
      "source": "Tamas Bisztray",
      "target": "University of Oslo",
      "keywords": "affiliation",
      "description": "Tamas Bisztray affiliated with University of Oslo"
    },
    {
      "source": "Tamas Bisztray",
      "target": "Khalifa University",
      "keywords": "affiliation",
      "description": "Tamas Bisztray affiliated with Khalifa University"
    },
    {
      "source": "Merouane Debbah",
      "target": "Technology Innovation Institute (TII)",
      "keywords": "affiliation",
      "description": "Merouane Debbah affiliated with Technology Innovation Institute (TII)"
    },
    {
      "source": "Merouane Debbah",
      "target": "University of Oslo",
      "keywords": "affiliation",
      "description": "Merouane Debbah affiliated with University of Oslo"
    },
    {
      "source": "Merouane Debbah",
      "target": "Khalifa University",
      "keywords": "affiliation",
      "description": "Merouane Debbah affiliated with Khalifa University"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "GPT-3.5-turbo",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses GPT-3.5-turbo"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses GPT-4"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "GPT-4o",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses GPT-4o"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "Falcon-180B",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses Falcon-180B"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "T5-base",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses T5-base"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "CyberMetric-80",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses CyberMetric-80"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "CyberMetric-500",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses CyberMetric-500"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "CyberMetric-2000",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses CyberMetric-2000"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "CyberMetric-10000",
      "keywords": "uses",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge uses CyberMetric-10000"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge proposes PipelineRAG"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge proposes DenseRetrieval"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge proposes AbstractiveGeneration"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge proposes SeparateTraining"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "QA",
      "keywords": "applies_to",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge applies to QA"
    },
    {
      "source": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge",
      "target": "CybersecurityRAG",
      "keywords": "applies_to",
      "description": "CyberMetric: A Benchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge applies to CybersecurityRAG"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "CyberMetric-80",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on CyberMetric-80"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "CyberMetric-500",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on CyberMetric-500"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "CyberMetric-2000",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on CyberMetric-2000"
    },
    {
      "source": "GPT-3.5-turbo",
      "target": "CyberMetric-10000",
      "keywords": "trained_on",
      "description": "GPT-3.5-turbo potentially trained on CyberMetric-10000"
    },
    {
      "source": "GPT-4",
      "target": "CyberMetric-80",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on CyberMetric-80"
    },
    {
      "source": "GPT-4",
      "target": "CyberMetric-500",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on CyberMetric-500"
    },
    {
      "source": "GPT-4",
      "target": "CyberMetric-2000",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on CyberMetric-2000"
    },
    {
      "source": "GPT-4",
      "target": "CyberMetric-10000",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on CyberMetric-10000"
    },
    {
      "source": "GPT-4o",
      "target": "CyberMetric-80",
      "keywords": "trained_on",
      "description": "GPT-4o potentially trained on CyberMetric-80"
    },
    {
      "source": "GPT-4o",
      "target": "CyberMetric-500",
      "keywords": "trained_on",
      "description": "GPT-4o potentially trained on CyberMetric-500"
    },
    {
      "source": "GPT-4o",
      "target": "CyberMetric-2000",
      "keywords": "trained_on",
      "description": "GPT-4o potentially trained on CyberMetric-2000"
    },
    {
      "source": "GPT-4o",
      "target": "CyberMetric-10000",
      "keywords": "trained_on",
      "description": "GPT-4o potentially trained on CyberMetric-10000"
    },
    {
      "source": "Falcon-180B",
      "target": "CyberMetric-80",
      "keywords": "trained_on",
      "description": "Falcon-180B potentially trained on CyberMetric-80"
    },
    {
      "source": "Falcon-180B",
      "target": "CyberMetric-500",
      "keywords": "trained_on",
      "description": "Falcon-180B potentially trained on CyberMetric-500"
    },
    {
      "source": "Falcon-180B",
      "target": "CyberMetric-2000",
      "keywords": "trained_on",
      "description": "Falcon-180B potentially trained on CyberMetric-2000"
    },
    {
      "source": "Falcon-180B",
      "target": "CyberMetric-10000",
      "keywords": "trained_on",
      "description": "Falcon-180B potentially trained on CyberMetric-10000"
    },
    {
      "source": "T5-base",
      "target": "CyberMetric-80",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on CyberMetric-80"
    },
    {
      "source": "T5-base",
      "target": "CyberMetric-500",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on CyberMetric-500"
    },
    {
      "source": "T5-base",
      "target": "CyberMetric-2000",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on CyberMetric-2000"
    },
    {
      "source": "T5-base",
      "target": "CyberMetric-10000",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on CyberMetric-10000"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "Weijia Shi",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Weijia Shi authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Sewon Min",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Sewon Min authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Michihiro Yasunaga authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Minjoon Seo",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Minjoon Seo authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Rich James",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Rich James authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Mike Lewis",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Mike Lewis authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Luke Zettlemoyer authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Wen-tau Yih",
      "target": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "keywords": "authorship",
      "description": "Wen-tau Yih authored REPLUG: Retrieval-Augmented Black-Box Language Models"
    },
    {
      "source": "Weijia Shi",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with University of Washington"
    },
    {
      "source": "Weijia Shi",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with Stanford University"
    },
    {
      "source": "Weijia Shi",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with KAIST"
    },
    {
      "source": "Weijia Shi",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Weijia Shi affiliated with Meta AI"
    },
    {
      "source": "Sewon Min",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Sewon Min affiliated with University of Washington"
    },
    {
      "source": "Sewon Min",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Sewon Min affiliated with Stanford University"
    },
    {
      "source": "Sewon Min",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Sewon Min affiliated with KAIST"
    },
    {
      "source": "Sewon Min",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Sewon Min affiliated with Meta AI"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with University of Washington"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with Stanford University"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with KAIST"
    },
    {
      "source": "Michihiro Yasunaga",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Michihiro Yasunaga affiliated with Meta AI"
    },
    {
      "source": "Minjoon Seo",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Minjoon Seo affiliated with University of Washington"
    },
    {
      "source": "Minjoon Seo",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Minjoon Seo affiliated with Stanford University"
    },
    {
      "source": "Minjoon Seo",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Minjoon Seo affiliated with KAIST"
    },
    {
      "source": "Minjoon Seo",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Minjoon Seo affiliated with Meta AI"
    },
    {
      "source": "Rich James",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Rich James affiliated with University of Washington"
    },
    {
      "source": "Rich James",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Rich James affiliated with Stanford University"
    },
    {
      "source": "Rich James",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Rich James affiliated with KAIST"
    },
    {
      "source": "Rich James",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Rich James affiliated with Meta AI"
    },
    {
      "source": "Mike Lewis",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with University of Washington"
    },
    {
      "source": "Mike Lewis",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Stanford University"
    },
    {
      "source": "Mike Lewis",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with KAIST"
    },
    {
      "source": "Mike Lewis",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Meta AI"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with University of Washington"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with Stanford University"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with KAIST"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with Meta AI"
    },
    {
      "source": "Wen-tau Yih",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with University of Washington"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Stanford University",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Stanford University"
    },
    {
      "source": "Wen-tau Yih",
      "target": "KAIST",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with KAIST"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Meta AI",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Meta AI"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Contriever",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses Contriever"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses GPT-3"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Codex",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses Codex"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "GPT-2",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses GPT-2"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "OPT",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses OPT"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "BLOOM",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses BLOOM"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "The Pile",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses The Pile"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "MMLU",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses MMLU"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses Natural Questions"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses TriviaQA"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Wikitext-103",
      "keywords": "uses",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models uses Wikitext-103"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models proposes PipelineRAG"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models proposes DenseRetrieval"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models proposes AbstractiveGeneration"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models proposes SeparateTraining"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "QA",
      "keywords": "applies_to",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models applies to QA"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Language modeling",
      "keywords": "applies_to",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models applies to Language modeling"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Multiple choice QA",
      "keywords": "applies_to",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models applies to Multiple choice QA"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "General domain",
      "keywords": "applies_to",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models applies to General domain"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Code understanding",
      "keywords": "applies_to",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models applies to Code understanding"
    },
    {
      "source": "REPLUG: Retrieval-Augmented Black-Box Language Models",
      "target": "Academic knowledge",
      "keywords": "applies_to",
      "description": "REPLUG: Retrieval-Augmented Black-Box Language Models applies to Academic knowledge"
    },
    {
      "source": "Contriever",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on The Pile"
    },
    {
      "source": "Contriever",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on MMLU"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions"
    },
    {
      "source": "Contriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on TriviaQA"
    },
    {
      "source": "Contriever",
      "target": "Wikitext-103",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Wikitext-103"
    },
    {
      "source": "GPT-3",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on The Pile"
    },
    {
      "source": "GPT-3",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on MMLU"
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3",
      "target": "Wikitext-103",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Wikitext-103"
    },
    {
      "source": "Codex",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "Codex potentially trained on The Pile"
    },
    {
      "source": "Codex",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "Codex potentially trained on MMLU"
    },
    {
      "source": "Codex",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Codex potentially trained on Natural Questions"
    },
    {
      "source": "Codex",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Codex potentially trained on TriviaQA"
    },
    {
      "source": "Codex",
      "target": "Wikitext-103",
      "keywords": "trained_on",
      "description": "Codex potentially trained on Wikitext-103"
    },
    {
      "source": "GPT-2",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on The Pile"
    },
    {
      "source": "GPT-2",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on MMLU"
    },
    {
      "source": "GPT-2",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-2",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-2",
      "target": "Wikitext-103",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Wikitext-103"
    },
    {
      "source": "OPT",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "OPT potentially trained on The Pile"
    },
    {
      "source": "OPT",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "OPT potentially trained on MMLU"
    },
    {
      "source": "OPT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "OPT potentially trained on Natural Questions"
    },
    {
      "source": "OPT",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "OPT potentially trained on TriviaQA"
    },
    {
      "source": "OPT",
      "target": "Wikitext-103",
      "keywords": "trained_on",
      "description": "OPT potentially trained on Wikitext-103"
    },
    {
      "source": "BLOOM",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on The Pile"
    },
    {
      "source": "BLOOM",
      "target": "MMLU",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on MMLU"
    },
    {
      "source": "BLOOM",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on Natural Questions"
    },
    {
      "source": "BLOOM",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on TriviaQA"
    },
    {
      "source": "BLOOM",
      "target": "Wikitext-103",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on Wikitext-103"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "Language modeling",
      "keywords": "supports",
      "description": "PipelineRAG supports Language modeling"
    },
    {
      "source": "PipelineRAG",
      "target": "Multiple choice QA",
      "keywords": "supports",
      "description": "PipelineRAG supports Multiple choice QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "Language modeling",
      "keywords": "supports",
      "description": "DenseRetrieval supports Language modeling"
    },
    {
      "source": "DenseRetrieval",
      "target": "Multiple choice QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports Multiple choice QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Language modeling",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Language modeling"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Multiple choice QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Multiple choice QA"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "Language modeling",
      "keywords": "supports",
      "description": "SeparateTraining supports Language modeling"
    },
    {
      "source": "SeparateTraining",
      "target": "Multiple choice QA",
      "keywords": "supports",
      "description": "SeparateTraining supports Multiple choice QA"
    },
    {
      "source": "Qihao Zhu",
      "target": "Generative Transformers for Design Concept Generation",
      "keywords": "authorship",
      "description": "Qihao Zhu authored Generative Transformers for Design Concept Generation"
    },
    {
      "source": "Jianxi Luo",
      "target": "Generative Transformers for Design Concept Generation",
      "keywords": "authorship",
      "description": "Jianxi Luo authored Generative Transformers for Design Concept Generation"
    },
    {
      "source": "Qihao Zhu",
      "target": "Singapore University of Technology and Design",
      "keywords": "affiliation",
      "description": "Qihao Zhu affiliated with Singapore University of Technology and Design"
    },
    {
      "source": "Jianxi Luo",
      "target": "Singapore University of Technology and Design",
      "keywords": "affiliation",
      "description": "Jianxi Luo affiliated with Singapore University of Technology and Design"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "BERT",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses BERT"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "Word2Vec",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses Word2Vec"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "GPT-2",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses GPT-2"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses GPT-3"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "USPTO Patent Data",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses USPTO Patent Data"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "RedDot Award Dataset",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses RedDot Award Dataset"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "WebText",
      "keywords": "uses",
      "description": "Generative Transformers for Design Concept Generation uses WebText"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Generative Transformers for Design Concept Generation proposes PipelineRAG"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Generative Transformers for Design Concept Generation proposes DenseRetrieval"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Generative Transformers for Design Concept Generation proposes AbstractiveGeneration"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Generative Transformers for Design Concept Generation proposes FinetuningStrategy"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Generative Transformers for Design Concept Generation applies to ConversationalAI"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Generative Transformers for Design Concept Generation applies to DocumentSummarization"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Generative Transformers for Design Concept Generation applies to EducationalRAG"
    },
    {
      "source": "Generative Transformers for Design Concept Generation",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Generative Transformers for Design Concept Generation applies to MedicalRAG"
    },
    {
      "source": "BERT",
      "target": "USPTO Patent Data",
      "keywords": "trained_on",
      "description": "BERT potentially trained on USPTO Patent Data"
    },
    {
      "source": "BERT",
      "target": "RedDot Award Dataset",
      "keywords": "trained_on",
      "description": "BERT potentially trained on RedDot Award Dataset"
    },
    {
      "source": "BERT",
      "target": "WebText",
      "keywords": "trained_on",
      "description": "BERT potentially trained on WebText"
    },
    {
      "source": "Word2Vec",
      "target": "USPTO Patent Data",
      "keywords": "trained_on",
      "description": "Word2Vec potentially trained on USPTO Patent Data"
    },
    {
      "source": "Word2Vec",
      "target": "RedDot Award Dataset",
      "keywords": "trained_on",
      "description": "Word2Vec potentially trained on RedDot Award Dataset"
    },
    {
      "source": "Word2Vec",
      "target": "WebText",
      "keywords": "trained_on",
      "description": "Word2Vec potentially trained on WebText"
    },
    {
      "source": "GPT-2",
      "target": "USPTO Patent Data",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on USPTO Patent Data"
    },
    {
      "source": "GPT-2",
      "target": "RedDot Award Dataset",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on RedDot Award Dataset"
    },
    {
      "source": "GPT-2",
      "target": "WebText",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on WebText"
    },
    {
      "source": "GPT-3",
      "target": "USPTO Patent Data",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on USPTO Patent Data"
    },
    {
      "source": "GPT-3",
      "target": "RedDot Award Dataset",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on RedDot Award Dataset"
    },
    {
      "source": "GPT-3",
      "target": "WebText",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on WebText"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "FinetuningStrategy supports ConversationalAI"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "Patrick Lewis",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Patrick Lewis authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Ethan Perez",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Ethan Perez authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Aleksandra Piktus authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Fabio Petroni",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Fabio Petroni authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Vladimir Karpukhin authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Naman Goyal",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Naman Goyal authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Heinrich Küttler",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Heinrich Küttler authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Mike Lewis",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Mike Lewis authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Wen-tau Yih authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Tim Rocktäschel authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Sebastian Riedel authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Douwe Kiela",
      "target": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "keywords": "authorship",
      "description": "Douwe Kiela authored Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
    },
    {
      "source": "Patrick Lewis",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with Facebook AI Research"
    },
    {
      "source": "Patrick Lewis",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with University College London"
    },
    {
      "source": "Patrick Lewis",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Patrick Lewis affiliated with New York University"
    },
    {
      "source": "Ethan Perez",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Ethan Perez affiliated with Facebook AI Research"
    },
    {
      "source": "Ethan Perez",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Ethan Perez affiliated with University College London"
    },
    {
      "source": "Ethan Perez",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Ethan Perez affiliated with New York University"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Aleksandra Piktus affiliated with Facebook AI Research"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Aleksandra Piktus affiliated with University College London"
    },
    {
      "source": "Aleksandra Piktus",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Aleksandra Piktus affiliated with New York University"
    },
    {
      "source": "Fabio Petroni",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with Facebook AI Research"
    },
    {
      "source": "Fabio Petroni",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with University College London"
    },
    {
      "source": "Fabio Petroni",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Fabio Petroni affiliated with New York University"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Vladimir Karpukhin affiliated with Facebook AI Research"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Vladimir Karpukhin affiliated with University College London"
    },
    {
      "source": "Vladimir Karpukhin",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Vladimir Karpukhin affiliated with New York University"
    },
    {
      "source": "Naman Goyal",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Naman Goyal affiliated with Facebook AI Research"
    },
    {
      "source": "Naman Goyal",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Naman Goyal affiliated with University College London"
    },
    {
      "source": "Naman Goyal",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Naman Goyal affiliated with New York University"
    },
    {
      "source": "Heinrich Küttler",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Heinrich Küttler affiliated with Facebook AI Research"
    },
    {
      "source": "Heinrich Küttler",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Heinrich Küttler affiliated with University College London"
    },
    {
      "source": "Heinrich Küttler",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Heinrich Küttler affiliated with New York University"
    },
    {
      "source": "Mike Lewis",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Facebook AI Research"
    },
    {
      "source": "Mike Lewis",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with University College London"
    },
    {
      "source": "Mike Lewis",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with New York University"
    },
    {
      "source": "Wen-tau Yih",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with Facebook AI Research"
    },
    {
      "source": "Wen-tau Yih",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with University College London"
    },
    {
      "source": "Wen-tau Yih",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Wen-tau Yih affiliated with New York University"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Tim Rocktäschel affiliated with Facebook AI Research"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Tim Rocktäschel affiliated with University College London"
    },
    {
      "source": "Tim Rocktäschel",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Tim Rocktäschel affiliated with New York University"
    },
    {
      "source": "Sebastian Riedel",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with Facebook AI Research"
    },
    {
      "source": "Sebastian Riedel",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with University College London"
    },
    {
      "source": "Sebastian Riedel",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Sebastian Riedel affiliated with New York University"
    },
    {
      "source": "Douwe Kiela",
      "target": "Facebook AI Research",
      "keywords": "affiliation",
      "description": "Douwe Kiela affiliated with Facebook AI Research"
    },
    {
      "source": "Douwe Kiela",
      "target": "University College London",
      "keywords": "affiliation",
      "description": "Douwe Kiela affiliated with University College London"
    },
    {
      "source": "Douwe Kiela",
      "target": "New York University",
      "keywords": "affiliation",
      "description": "Douwe Kiela affiliated with New York University"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Dense Passage Retriever (DPR)",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses Dense Passage Retriever (DPR)"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "BART-large",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses BART-large"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses Natural Questions"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses TriviaQA"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "WebQuestions",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses WebQuestions"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "CuratedTrec",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses CuratedTrec"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses MS-MARCO"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "FEVER",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks uses FEVER"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes PipelineRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes DenseRetrieval"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks proposes JointTraining"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to QA"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to DocumentSummarization"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to ConversationalAI"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Open-domain question answering",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Open-domain question answering"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Abstractive question answering",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Abstractive question answering"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Fact verification",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Fact verification"
    },
    {
      "source": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
      "target": "Question generation",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks applies to Question generation"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on Natural Questions"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on TriviaQA"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on WebQuestions"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on CuratedTrec"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on MS-MARCO"
    },
    {
      "source": "Dense Passage Retriever (DPR)",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "Dense Passage Retriever (DPR) potentially trained on FEVER"
    },
    {
      "source": "BART-large",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on Natural Questions"
    },
    {
      "source": "BART-large",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on TriviaQA"
    },
    {
      "source": "BART-large",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on WebQuestions"
    },
    {
      "source": "BART-large",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on CuratedTrec"
    },
    {
      "source": "BART-large",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on MS-MARCO"
    },
    {
      "source": "BART-large",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BART-large potentially trained on FEVER"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Kelvin Guu",
      "target": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "keywords": "authorship",
      "description": "Kelvin Guu authored REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "source": "Kenton Lee",
      "target": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "keywords": "authorship",
      "description": "Kenton Lee authored REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "source": "Zora Tung",
      "target": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "keywords": "authorship",
      "description": "Zora Tung authored REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "source": "Panupong Pasupat",
      "target": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "keywords": "authorship",
      "description": "Panupong Pasupat authored REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "source": "Ming-Wei Chang",
      "target": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "keywords": "authorship",
      "description": "Ming-Wei Chang authored REALM: Retrieval-Augmented Language Model Pre-Training"
    },
    {
      "source": "Kelvin Guu",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Kelvin Guu affiliated with Google Research"
    },
    {
      "source": "Kenton Lee",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Kenton Lee affiliated with Google Research"
    },
    {
      "source": "Zora Tung",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Zora Tung affiliated with Google Research"
    },
    {
      "source": "Panupong Pasupat",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Panupong Pasupat affiliated with Google Research"
    },
    {
      "source": "Ming-Wei Chang",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Ming-Wei Chang affiliated with Google Research"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "REALM Knowledge Retriever",
      "keywords": "uses",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training uses REALM Knowledge Retriever"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "REALM Knowledge-Augmented Encoder",
      "keywords": "uses",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training uses REALM Knowledge-Augmented Encoder"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "Natural Questions-Open",
      "keywords": "uses",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training uses Natural Questions-Open"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "WebQuestions",
      "keywords": "uses",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training uses WebQuestions"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "CuratedTrec",
      "keywords": "uses",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training uses CuratedTrec"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "CC-News",
      "keywords": "uses",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training uses CC-News"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training proposes PipelineRAG"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training proposes DenseRetrieval"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training proposes AbstractiveGeneration"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training proposes JointTraining"
    },
    {
      "source": "REALM: Retrieval-Augmented Language Model Pre-Training",
      "target": "QA",
      "keywords": "applies_to",
      "description": "REALM: Retrieval-Augmented Language Model Pre-Training applies to QA"
    },
    {
      "source": "REALM Knowledge Retriever",
      "target": "Natural Questions-Open",
      "keywords": "trained_on",
      "description": "REALM Knowledge Retriever potentially trained on Natural Questions-Open"
    },
    {
      "source": "REALM Knowledge Retriever",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "REALM Knowledge Retriever potentially trained on WebQuestions"
    },
    {
      "source": "REALM Knowledge Retriever",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "REALM Knowledge Retriever potentially trained on CuratedTrec"
    },
    {
      "source": "REALM Knowledge Retriever",
      "target": "CC-News",
      "keywords": "trained_on",
      "description": "REALM Knowledge Retriever potentially trained on CC-News"
    },
    {
      "source": "REALM Knowledge-Augmented Encoder",
      "target": "Natural Questions-Open",
      "keywords": "trained_on",
      "description": "REALM Knowledge-Augmented Encoder potentially trained on Natural Questions-Open"
    },
    {
      "source": "REALM Knowledge-Augmented Encoder",
      "target": "WebQuestions",
      "keywords": "trained_on",
      "description": "REALM Knowledge-Augmented Encoder potentially trained on WebQuestions"
    },
    {
      "source": "REALM Knowledge-Augmented Encoder",
      "target": "CuratedTrec",
      "keywords": "trained_on",
      "description": "REALM Knowledge-Augmented Encoder potentially trained on CuratedTrec"
    },
    {
      "source": "REALM Knowledge-Augmented Encoder",
      "target": "CC-News",
      "keywords": "trained_on",
      "description": "REALM Knowledge-Augmented Encoder potentially trained on CC-News"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "Robin Rombach",
      "target": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "keywords": "authorship",
      "description": "Robin Rombach authored Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "source": "Andreas Blattmann",
      "target": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "keywords": "authorship",
      "description": "Andreas Blattmann authored Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "source": "Björn Ommer",
      "target": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "keywords": "authorship",
      "description": "Björn Ommer authored Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models"
    },
    {
      "source": "Robin Rombach",
      "target": "Ludwig-Maximilian University Munich, Germany",
      "keywords": "affiliation",
      "description": "Robin Rombach affiliated with Ludwig-Maximilian University Munich, Germany"
    },
    {
      "source": "Andreas Blattmann",
      "target": "Ludwig-Maximilian University Munich, Germany",
      "keywords": "affiliation",
      "description": "Andreas Blattmann affiliated with Ludwig-Maximilian University Munich, Germany"
    },
    {
      "source": "Björn Ommer",
      "target": "Ludwig-Maximilian University Munich, Germany",
      "keywords": "affiliation",
      "description": "Björn Ommer affiliated with Ludwig-Maximilian University Munich, Germany"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "CLIP-ViT-B/32",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses CLIP-ViT-B/32"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "CLIP-ViT-L/14",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses CLIP-ViT-L/14"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "Latent Diffusion Model",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses Latent Diffusion Model"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "ImageNet",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses ImageNet"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "LAION-2B-en",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses LAION-2B-en"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "WikiArt",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses WikiArt"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "ArtBench",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses ArtBench"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "OpenImages",
      "keywords": "uses",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models uses OpenImages"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models proposes PipelineRAG"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models proposes DenseRetrieval"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models proposes AbstractiveGeneration"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models proposes SeparateTraining"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "Text-to-image synthesis",
      "keywords": "applies_to",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models applies to Text-to-image synthesis"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "Artistic image generation",
      "keywords": "applies_to",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models applies to Artistic image generation"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "Style transfer",
      "keywords": "applies_to",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models applies to Style transfer"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "AI-Art generation",
      "keywords": "applies_to",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models applies to AI-Art generation"
    },
    {
      "source": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models",
      "target": "Visual content creation for artists",
      "keywords": "applies_to",
      "description": "Text-Guided Synthesis of Artistic Images with Retrieval-Augmented Diffusion Models applies to Visual content creation for artists"
    },
    {
      "source": "CLIP-ViT-B/32",
      "target": "ImageNet",
      "keywords": "trained_on",
      "description": "CLIP-ViT-B/32 potentially trained on ImageNet"
    },
    {
      "source": "CLIP-ViT-B/32",
      "target": "LAION-2B-en",
      "keywords": "trained_on",
      "description": "CLIP-ViT-B/32 potentially trained on LAION-2B-en"
    },
    {
      "source": "CLIP-ViT-B/32",
      "target": "WikiArt",
      "keywords": "trained_on",
      "description": "CLIP-ViT-B/32 potentially trained on WikiArt"
    },
    {
      "source": "CLIP-ViT-B/32",
      "target": "ArtBench",
      "keywords": "trained_on",
      "description": "CLIP-ViT-B/32 potentially trained on ArtBench"
    },
    {
      "source": "CLIP-ViT-B/32",
      "target": "OpenImages",
      "keywords": "trained_on",
      "description": "CLIP-ViT-B/32 potentially trained on OpenImages"
    },
    {
      "source": "CLIP-ViT-L/14",
      "target": "ImageNet",
      "keywords": "trained_on",
      "description": "CLIP-ViT-L/14 potentially trained on ImageNet"
    },
    {
      "source": "CLIP-ViT-L/14",
      "target": "LAION-2B-en",
      "keywords": "trained_on",
      "description": "CLIP-ViT-L/14 potentially trained on LAION-2B-en"
    },
    {
      "source": "CLIP-ViT-L/14",
      "target": "WikiArt",
      "keywords": "trained_on",
      "description": "CLIP-ViT-L/14 potentially trained on WikiArt"
    },
    {
      "source": "CLIP-ViT-L/14",
      "target": "ArtBench",
      "keywords": "trained_on",
      "description": "CLIP-ViT-L/14 potentially trained on ArtBench"
    },
    {
      "source": "CLIP-ViT-L/14",
      "target": "OpenImages",
      "keywords": "trained_on",
      "description": "CLIP-ViT-L/14 potentially trained on OpenImages"
    },
    {
      "source": "Latent Diffusion Model",
      "target": "ImageNet",
      "keywords": "trained_on",
      "description": "Latent Diffusion Model potentially trained on ImageNet"
    },
    {
      "source": "Latent Diffusion Model",
      "target": "LAION-2B-en",
      "keywords": "trained_on",
      "description": "Latent Diffusion Model potentially trained on LAION-2B-en"
    },
    {
      "source": "Latent Diffusion Model",
      "target": "WikiArt",
      "keywords": "trained_on",
      "description": "Latent Diffusion Model potentially trained on WikiArt"
    },
    {
      "source": "Latent Diffusion Model",
      "target": "ArtBench",
      "keywords": "trained_on",
      "description": "Latent Diffusion Model potentially trained on ArtBench"
    },
    {
      "source": "Latent Diffusion Model",
      "target": "OpenImages",
      "keywords": "trained_on",
      "description": "Latent Diffusion Model potentially trained on OpenImages"
    },
    {
      "source": "PipelineRAG",
      "target": "Text-to-image synthesis",
      "keywords": "supports",
      "description": "PipelineRAG supports Text-to-image synthesis"
    },
    {
      "source": "PipelineRAG",
      "target": "Artistic image generation",
      "keywords": "supports",
      "description": "PipelineRAG supports Artistic image generation"
    },
    {
      "source": "PipelineRAG",
      "target": "Style transfer",
      "keywords": "supports",
      "description": "PipelineRAG supports Style transfer"
    },
    {
      "source": "DenseRetrieval",
      "target": "Text-to-image synthesis",
      "keywords": "supports",
      "description": "DenseRetrieval supports Text-to-image synthesis"
    },
    {
      "source": "DenseRetrieval",
      "target": "Artistic image generation",
      "keywords": "supports",
      "description": "DenseRetrieval supports Artistic image generation"
    },
    {
      "source": "DenseRetrieval",
      "target": "Style transfer",
      "keywords": "supports",
      "description": "DenseRetrieval supports Style transfer"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Text-to-image synthesis",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Text-to-image synthesis"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Artistic image generation",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Artistic image generation"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Style transfer",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Style transfer"
    },
    {
      "source": "SeparateTraining",
      "target": "Text-to-image synthesis",
      "keywords": "supports",
      "description": "SeparateTraining supports Text-to-image synthesis"
    },
    {
      "source": "SeparateTraining",
      "target": "Artistic image generation",
      "keywords": "supports",
      "description": "SeparateTraining supports Artistic image generation"
    },
    {
      "source": "SeparateTraining",
      "target": "Style transfer",
      "keywords": "supports",
      "description": "SeparateTraining supports Style transfer"
    },
    {
      "source": "Siddharth L.",
      "target": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "keywords": "authorship",
      "description": "Siddharth L. authored Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "source": "Blessing L.T.M.",
      "target": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "keywords": "authorship",
      "description": "Blessing L.T.M. authored Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "source": "Wood K.L.",
      "target": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "keywords": "authorship",
      "description": "Wood K.L. authored Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "source": "Luo J.",
      "target": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "keywords": "authorship",
      "description": "Luo J. authored Retrieval Augmented Generation using Engineering Design Knowledge"
    },
    {
      "source": "Siddharth L.",
      "target": "Department of Systems Engineering, City University of Hong Kong, Hong Kong",
      "keywords": "affiliation",
      "description": "Siddharth L. affiliated with Department of Systems Engineering, City University of Hong Kong, Hong Kong"
    },
    {
      "source": "Blessing L.T.M.",
      "target": "Department of Systems Engineering, City University of Hong Kong, Hong Kong",
      "keywords": "affiliation",
      "description": "Blessing L.T.M. affiliated with Department of Systems Engineering, City University of Hong Kong, Hong Kong"
    },
    {
      "source": "Wood K.L.",
      "target": "Department of Systems Engineering, City University of Hong Kong, Hong Kong",
      "keywords": "affiliation",
      "description": "Wood K.L. affiliated with Department of Systems Engineering, City University of Hong Kong, Hong Kong"
    },
    {
      "source": "Luo J.",
      "target": "Department of Systems Engineering, City University of Hong Kong, Hong Kong",
      "keywords": "affiliation",
      "description": "Luo J. affiliated with Department of Systems Engineering, City University of Hong Kong, Hong Kong"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "spaCy transformers",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses spaCy transformers"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "GPT-4 Turbo",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses GPT-4 Turbo"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "ALBERT",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses ALBERT"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "DistilBERT",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses DistilBERT"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "BERT",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses BERT"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "SciBERT",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses SciBERT"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "BART",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses BART"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "T5",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses T5"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "Engineering Design Facts Dataset",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses Engineering Design Facts Dataset"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "Fan Systems Knowledge Base",
      "keywords": "uses",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge uses Fan Systems Knowledge Base"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge proposes PipelineRAG"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge proposes HybridRetrieval"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge proposes FinetuningStrategy"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge applies to QA"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge applies to DocumentSummarization"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "Engineering Design",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge applies to Engineering Design"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "Patent Analysis",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge applies to Patent Analysis"
    },
    {
      "source": "Retrieval Augmented Generation using Engineering Design Knowledge",
      "target": "Technical Knowledge Retrieval",
      "keywords": "applies_to",
      "description": "Retrieval Augmented Generation using Engineering Design Knowledge applies to Technical Knowledge Retrieval"
    },
    {
      "source": "spaCy transformers",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "spaCy transformers potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "spaCy transformers",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "spaCy transformers potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "GPT-4 Turbo",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "GPT-4 Turbo potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "GPT-4 Turbo",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "GPT-4 Turbo potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "ALBERT",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "ALBERT potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "ALBERT",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "ALBERT potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "DistilBERT",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "DistilBERT potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "DistilBERT",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "DistilBERT potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "BERT",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "BERT",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "SciBERT",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "SciBERT potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "SciBERT",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "SciBERT potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "BART",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "BART potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "BART",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "BART potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "T5",
      "target": "Engineering Design Facts Dataset",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Engineering Design Facts Dataset"
    },
    {
      "source": "T5",
      "target": "Fan Systems Knowledge Base",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Fan Systems Knowledge Base"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "Mingyuan Zhang",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Mingyuan Zhang authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Xinying Guo",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Xinying Guo authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Liang Pan",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Liang Pan authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Zhongang Cai",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Zhongang Cai authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Fangzhou Hong",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Fangzhou Hong authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Huirong Li",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Huirong Li authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Lei Yang",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Lei Yang authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Ziwei Liu",
      "target": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "keywords": "authorship",
      "description": "Ziwei Liu authored ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model"
    },
    {
      "source": "Mingyuan Zhang",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Mingyuan Zhang affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Mingyuan Zhang",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Mingyuan Zhang affiliated with Sensetime, China"
    },
    {
      "source": "Xinying Guo",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Xinying Guo affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Xinying Guo",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Xinying Guo affiliated with Sensetime, China"
    },
    {
      "source": "Liang Pan",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Liang Pan affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Liang Pan",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Liang Pan affiliated with Sensetime, China"
    },
    {
      "source": "Zhongang Cai",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Zhongang Cai affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Zhongang Cai",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Zhongang Cai affiliated with Sensetime, China"
    },
    {
      "source": "Fangzhou Hong",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Fangzhou Hong affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Fangzhou Hong",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Fangzhou Hong affiliated with Sensetime, China"
    },
    {
      "source": "Huirong Li",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Huirong Li affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Huirong Li",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Huirong Li affiliated with Sensetime, China"
    },
    {
      "source": "Lei Yang",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Lei Yang affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Lei Yang",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Lei Yang affiliated with Sensetime, China"
    },
    {
      "source": "Ziwei Liu",
      "target": "S-Lab, Nanyang Technological University, Singapore",
      "keywords": "affiliation",
      "description": "Ziwei Liu affiliated with S-Lab, Nanyang Technological University, Singapore"
    },
    {
      "source": "Ziwei Liu",
      "target": "Sensetime, China",
      "keywords": "affiliation",
      "description": "Ziwei Liu affiliated with Sensetime, China"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "CLIP",
      "keywords": "uses",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model uses CLIP"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "Motion Diffusion Model",
      "keywords": "uses",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model uses Motion Diffusion Model"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "HumanML3D",
      "keywords": "uses",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model uses HumanML3D"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "KIT-ML",
      "keywords": "uses",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model uses KIT-ML"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model proposes PipelineRAG"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model proposes HybridRetrieval"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model proposes AbstractiveGeneration"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model proposes SeparateTraining"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "motion generation",
      "keywords": "applies_to",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model applies to motion generation"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "text-driven synthesis",
      "keywords": "applies_to",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model applies to text-driven synthesis"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "creative industry",
      "keywords": "applies_to",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model applies to creative industry"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "game production",
      "keywords": "applies_to",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model applies to game production"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "film",
      "keywords": "applies_to",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model applies to film"
    },
    {
      "source": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model",
      "target": "virtual reality",
      "keywords": "applies_to",
      "description": "ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model applies to virtual reality"
    },
    {
      "source": "CLIP",
      "target": "HumanML3D",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on HumanML3D"
    },
    {
      "source": "CLIP",
      "target": "KIT-ML",
      "keywords": "trained_on",
      "description": "CLIP potentially trained on KIT-ML"
    },
    {
      "source": "Motion Diffusion Model",
      "target": "HumanML3D",
      "keywords": "trained_on",
      "description": "Motion Diffusion Model potentially trained on HumanML3D"
    },
    {
      "source": "Motion Diffusion Model",
      "target": "KIT-ML",
      "keywords": "trained_on",
      "description": "Motion Diffusion Model potentially trained on KIT-ML"
    },
    {
      "source": "PipelineRAG",
      "target": "motion generation",
      "keywords": "supports",
      "description": "PipelineRAG supports motion generation"
    },
    {
      "source": "PipelineRAG",
      "target": "text-driven synthesis",
      "keywords": "supports",
      "description": "PipelineRAG supports text-driven synthesis"
    },
    {
      "source": "HybridRetrieval",
      "target": "motion generation",
      "keywords": "supports",
      "description": "HybridRetrieval supports motion generation"
    },
    {
      "source": "HybridRetrieval",
      "target": "text-driven synthesis",
      "keywords": "supports",
      "description": "HybridRetrieval supports text-driven synthesis"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "motion generation",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports motion generation"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "text-driven synthesis",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports text-driven synthesis"
    },
    {
      "source": "SeparateTraining",
      "target": "motion generation",
      "keywords": "supports",
      "description": "SeparateTraining supports motion generation"
    },
    {
      "source": "SeparateTraining",
      "target": "text-driven synthesis",
      "keywords": "supports",
      "description": "SeparateTraining supports text-driven synthesis"
    },
    {
      "source": "David Thulke",
      "target": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "keywords": "authorship",
      "description": "David Thulke authored Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "source": "Nico Daheim",
      "target": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "keywords": "authorship",
      "description": "Nico Daheim authored Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "source": "Christian Dugast",
      "target": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "keywords": "authorship",
      "description": "Christian Dugast authored Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "source": "Hermann Ney",
      "target": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "keywords": "authorship",
      "description": "Hermann Ney authored Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog"
    },
    {
      "source": "David Thulke",
      "target": "Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany",
      "keywords": "affiliation",
      "description": "David Thulke affiliated with Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany"
    },
    {
      "source": "David Thulke",
      "target": "AppTek GmbH, Aachen, Germany",
      "keywords": "affiliation",
      "description": "David Thulke affiliated with AppTek GmbH, Aachen, Germany"
    },
    {
      "source": "Nico Daheim",
      "target": "Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany",
      "keywords": "affiliation",
      "description": "Nico Daheim affiliated with Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany"
    },
    {
      "source": "Nico Daheim",
      "target": "AppTek GmbH, Aachen, Germany",
      "keywords": "affiliation",
      "description": "Nico Daheim affiliated with AppTek GmbH, Aachen, Germany"
    },
    {
      "source": "Christian Dugast",
      "target": "Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany",
      "keywords": "affiliation",
      "description": "Christian Dugast affiliated with Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany"
    },
    {
      "source": "Christian Dugast",
      "target": "AppTek GmbH, Aachen, Germany",
      "keywords": "affiliation",
      "description": "Christian Dugast affiliated with AppTek GmbH, Aachen, Germany"
    },
    {
      "source": "Hermann Ney",
      "target": "Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany",
      "keywords": "affiliation",
      "description": "Hermann Ney affiliated with Human Language Technology and Pattern Recognition Group, RWTH Aachen University, Germany"
    },
    {
      "source": "Hermann Ney",
      "target": "AppTek GmbH, Aachen, Germany",
      "keywords": "affiliation",
      "description": "Hermann Ney affiliated with AppTek GmbH, Aachen, Germany"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "RoBERTa",
      "keywords": "uses",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog uses RoBERTa"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "Siamese Embedding Networks",
      "keywords": "uses",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog uses Siamese Embedding Networks"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "BART",
      "keywords": "uses",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog uses BART"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "GPT-2",
      "keywords": "uses",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog uses GPT-2"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "MultiWOZ 2.1",
      "keywords": "uses",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog uses MultiWOZ 2.1"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "DSTC 9 Track 1",
      "keywords": "uses",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog uses DSTC 9 Track 1"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog proposes PipelineRAG"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog proposes HybridRetrieval"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog proposes AbstractiveGeneration"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog proposes JointTraining"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to QA"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to ConversationalAI"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "task-oriented dialog systems",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to task-oriented dialog systems"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "restaurant booking",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to restaurant booking"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "hotel reservation",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to hotel reservation"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "taxi booking",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to taxi booking"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "train booking",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to train booking"
    },
    {
      "source": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog",
      "target": "attraction information",
      "keywords": "applies_to",
      "description": "Efficient Retrieval Augmented Generation from Unstructured Knowledge for Task-Oriented Dialog applies to attraction information"
    },
    {
      "source": "RoBERTa",
      "target": "MultiWOZ 2.1",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on MultiWOZ 2.1"
    },
    {
      "source": "RoBERTa",
      "target": "DSTC 9 Track 1",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on DSTC 9 Track 1"
    },
    {
      "source": "Siamese Embedding Networks",
      "target": "MultiWOZ 2.1",
      "keywords": "trained_on",
      "description": "Siamese Embedding Networks potentially trained on MultiWOZ 2.1"
    },
    {
      "source": "Siamese Embedding Networks",
      "target": "DSTC 9 Track 1",
      "keywords": "trained_on",
      "description": "Siamese Embedding Networks potentially trained on DSTC 9 Track 1"
    },
    {
      "source": "BART",
      "target": "MultiWOZ 2.1",
      "keywords": "trained_on",
      "description": "BART potentially trained on MultiWOZ 2.1"
    },
    {
      "source": "BART",
      "target": "DSTC 9 Track 1",
      "keywords": "trained_on",
      "description": "BART potentially trained on DSTC 9 Track 1"
    },
    {
      "source": "GPT-2",
      "target": "MultiWOZ 2.1",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on MultiWOZ 2.1"
    },
    {
      "source": "GPT-2",
      "target": "DSTC 9 Track 1",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on DSTC 9 Track 1"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Sebastian Borgeaud",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Sebastian Borgeaud authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Arthur Mensch",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Arthur Mensch authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Jordan Hoffmann",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Jordan Hoffmann authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Trevor Cai",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Trevor Cai authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Eliza Rutherford",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Eliza Rutherford authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Katie Millican",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Katie Millican authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "George van den Driessche",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "George van den Driessche authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Jean-Baptiste Lespiau",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Jean-Baptiste Lespiau authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Bogdan Damoc",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Bogdan Damoc authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Aidan Clark",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Aidan Clark authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Diego de Las Casas",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Diego de Las Casas authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Aurelia Guy",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Aurelia Guy authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Jacob Menick",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Jacob Menick authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Roman Ring",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Roman Ring authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Tom Hennigan",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Tom Hennigan authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Saffron Huang",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Saffron Huang authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Loren Maggiore",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Loren Maggiore authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Chris Jones",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Chris Jones authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Albin Cassirer",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Albin Cassirer authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Andy Brock",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Andy Brock authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Michela Paganini",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Michela Paganini authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Geoffrey Irving",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Geoffrey Irving authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Oriol Vinyals",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Oriol Vinyals authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Simon Osindero",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Simon Osindero authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Karen Simonyan",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Karen Simonyan authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Jack W. Rae",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Jack W. Rae authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Erich Elsen",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Erich Elsen authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Laurent Sifre",
      "target": "Improving language models by retrieving from trillions of tokens",
      "keywords": "authorship",
      "description": "Laurent Sifre authored Improving language models by retrieving from trillions of tokens"
    },
    {
      "source": "Sebastian Borgeaud",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Sebastian Borgeaud affiliated with DeepMind"
    },
    {
      "source": "Arthur Mensch",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Arthur Mensch affiliated with DeepMind"
    },
    {
      "source": "Jordan Hoffmann",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Jordan Hoffmann affiliated with DeepMind"
    },
    {
      "source": "Trevor Cai",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Trevor Cai affiliated with DeepMind"
    },
    {
      "source": "Eliza Rutherford",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Eliza Rutherford affiliated with DeepMind"
    },
    {
      "source": "Katie Millican",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Katie Millican affiliated with DeepMind"
    },
    {
      "source": "George van den Driessche",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "George van den Driessche affiliated with DeepMind"
    },
    {
      "source": "Jean-Baptiste Lespiau",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Jean-Baptiste Lespiau affiliated with DeepMind"
    },
    {
      "source": "Bogdan Damoc",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Bogdan Damoc affiliated with DeepMind"
    },
    {
      "source": "Aidan Clark",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Aidan Clark affiliated with DeepMind"
    },
    {
      "source": "Diego de Las Casas",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Diego de Las Casas affiliated with DeepMind"
    },
    {
      "source": "Aurelia Guy",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Aurelia Guy affiliated with DeepMind"
    },
    {
      "source": "Jacob Menick",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Jacob Menick affiliated with DeepMind"
    },
    {
      "source": "Roman Ring",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Roman Ring affiliated with DeepMind"
    },
    {
      "source": "Tom Hennigan",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Tom Hennigan affiliated with DeepMind"
    },
    {
      "source": "Saffron Huang",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Saffron Huang affiliated with DeepMind"
    },
    {
      "source": "Loren Maggiore",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Loren Maggiore affiliated with DeepMind"
    },
    {
      "source": "Chris Jones",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Chris Jones affiliated with DeepMind"
    },
    {
      "source": "Albin Cassirer",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Albin Cassirer affiliated with DeepMind"
    },
    {
      "source": "Andy Brock",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Andy Brock affiliated with DeepMind"
    },
    {
      "source": "Michela Paganini",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Michela Paganini affiliated with DeepMind"
    },
    {
      "source": "Geoffrey Irving",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Geoffrey Irving affiliated with DeepMind"
    },
    {
      "source": "Oriol Vinyals",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Oriol Vinyals affiliated with DeepMind"
    },
    {
      "source": "Simon Osindero",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Simon Osindero affiliated with DeepMind"
    },
    {
      "source": "Karen Simonyan",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Karen Simonyan affiliated with DeepMind"
    },
    {
      "source": "Jack W. Rae",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Jack W. Rae affiliated with DeepMind"
    },
    {
      "source": "Erich Elsen",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Erich Elsen affiliated with DeepMind"
    },
    {
      "source": "Laurent Sifre",
      "target": "DeepMind",
      "keywords": "affiliation",
      "description": "Laurent Sifre affiliated with DeepMind"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "BERT",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses BERT"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "Retro",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses Retro"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "Baseline Transformer",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses Baseline Transformer"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "MassiveText",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses MassiveText"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "C4",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses C4"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "Wikitext103",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses Wikitext103"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "The Pile",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses The Pile"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Improving language models by retrieving from trillions of tokens uses Natural Questions"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "End2EndRAG",
      "keywords": "proposes",
      "description": "Improving language models by retrieving from trillions of tokens proposes End2EndRAG"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Improving language models by retrieving from trillions of tokens proposes DenseRetrieval"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Improving language models by retrieving from trillions of tokens proposes AbstractiveGeneration"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Improving language models by retrieving from trillions of tokens proposes SeparateTraining"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Improving language models by retrieving from trillions of tokens applies to QA"
    },
    {
      "source": "Improving language models by retrieving from trillions of tokens",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Improving language models by retrieving from trillions of tokens applies to DocumentSummarization"
    },
    {
      "source": "BERT",
      "target": "MassiveText",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MassiveText"
    },
    {
      "source": "BERT",
      "target": "C4",
      "keywords": "trained_on",
      "description": "BERT potentially trained on C4"
    },
    {
      "source": "BERT",
      "target": "Wikitext103",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Wikitext103"
    },
    {
      "source": "BERT",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "BERT potentially trained on The Pile"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "Retro",
      "target": "MassiveText",
      "keywords": "trained_on",
      "description": "Retro potentially trained on MassiveText"
    },
    {
      "source": "Retro",
      "target": "C4",
      "keywords": "trained_on",
      "description": "Retro potentially trained on C4"
    },
    {
      "source": "Retro",
      "target": "Wikitext103",
      "keywords": "trained_on",
      "description": "Retro potentially trained on Wikitext103"
    },
    {
      "source": "Retro",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "Retro potentially trained on The Pile"
    },
    {
      "source": "Retro",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Retro potentially trained on Natural Questions"
    },
    {
      "source": "Baseline Transformer",
      "target": "MassiveText",
      "keywords": "trained_on",
      "description": "Baseline Transformer potentially trained on MassiveText"
    },
    {
      "source": "Baseline Transformer",
      "target": "C4",
      "keywords": "trained_on",
      "description": "Baseline Transformer potentially trained on C4"
    },
    {
      "source": "Baseline Transformer",
      "target": "Wikitext103",
      "keywords": "trained_on",
      "description": "Baseline Transformer potentially trained on Wikitext103"
    },
    {
      "source": "Baseline Transformer",
      "target": "The Pile",
      "keywords": "trained_on",
      "description": "Baseline Transformer potentially trained on The Pile"
    },
    {
      "source": "Baseline Transformer",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Baseline Transformer potentially trained on Natural Questions"
    },
    {
      "source": "End2EndRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "End2EndRAG supports QA"
    },
    {
      "source": "End2EndRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "End2EndRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Yunfan Gao",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Yunfan Gao authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Yun Xiong",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Yun Xiong authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Xinyu Gao",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Xinyu Gao authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Kangxiang Jia",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Kangxiang Jia authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Jinliu Pan",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Jinliu Pan authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Yuxi Bi",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Yuxi Bi authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Yi Dai",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Yi Dai authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Jiawei Sun",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Jiawei Sun authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Meng Wang",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Meng Wang authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Haofen Wang",
      "target": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "keywords": "authorship",
      "description": "Haofen Wang authored Retrieval-Augmented Generation for Large Language Models: A Survey"
    },
    {
      "source": "Yunfan Gao",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Yunfan Gao affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Yunfan Gao",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Yunfan Gao affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Yunfan Gao",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Yunfan Gao affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Yun Xiong",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Yun Xiong affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Yun Xiong",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Yun Xiong affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Yun Xiong",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Yun Xiong affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Xinyu Gao",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Xinyu Gao affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Xinyu Gao",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Xinyu Gao affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Xinyu Gao",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Xinyu Gao affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Kangxiang Jia",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Kangxiang Jia affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Kangxiang Jia",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Kangxiang Jia affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Kangxiang Jia",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Kangxiang Jia affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Jinliu Pan",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Jinliu Pan affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Jinliu Pan",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Jinliu Pan affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Jinliu Pan",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Jinliu Pan affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Yuxi Bi",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Yuxi Bi affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Yuxi Bi",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Yuxi Bi affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Yuxi Bi",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Yuxi Bi affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Yi Dai",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Yi Dai affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Yi Dai",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Yi Dai affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Yi Dai",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Yi Dai affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Jiawei Sun",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Jiawei Sun affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Jiawei Sun",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Jiawei Sun affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Jiawei Sun",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Jiawei Sun affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Meng Wang",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Meng Wang affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Meng Wang",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Meng Wang affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Meng Wang",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Meng Wang affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Haofen Wang",
      "target": "Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University",
      "keywords": "affiliation",
      "description": "Haofen Wang affiliated with Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University"
    },
    {
      "source": "Haofen Wang",
      "target": "Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University",
      "keywords": "affiliation",
      "description": "Haofen Wang affiliated with Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University"
    },
    {
      "source": "Haofen Wang",
      "target": "College of Design and Innovation, Tongji University",
      "keywords": "affiliation",
      "description": "Haofen Wang affiliated with College of Design and Innovation, Tongji University"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "BERT",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses BERT"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "BM25",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses BM25"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "DPR",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses DPR"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "ChatGPT",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses ChatGPT"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses GPT-3"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "T5",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses T5"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "BART",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses BART"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses Natural Questions"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses TriviaQA"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses MS-MARCO"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "HotpotQA",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses HotpotQA"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "BEIR",
      "keywords": "uses",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey uses BEIR"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey proposes PipelineRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey proposes HybridRetrieval"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey proposes AbstractiveGeneration"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey proposes JointTraining"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to QA"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to DocumentSummarization"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to ConversationalAI"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "Information Extraction",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to Information Extraction"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "Fact Checking",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to Fact Checking"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "Code Search",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to Code Search"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to MedicalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to LegalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to EducationalRAG"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "Scientific Research",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to Scientific Research"
    },
    {
      "source": "Retrieval-Augmented Generation for Large Language Models: A Survey",
      "target": "Enterprise Search",
      "keywords": "applies_to",
      "description": "Retrieval-Augmented Generation for Large Language Models: A Survey applies to Enterprise Search"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "BERT",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TriviaQA"
    },
    {
      "source": "BERT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MS-MARCO"
    },
    {
      "source": "BERT",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "BERT potentially trained on HotpotQA"
    },
    {
      "source": "BERT",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BERT potentially trained on BEIR"
    },
    {
      "source": "BM25",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions"
    },
    {
      "source": "BM25",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TriviaQA"
    },
    {
      "source": "BM25",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on MS-MARCO"
    },
    {
      "source": "BM25",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on HotpotQA"
    },
    {
      "source": "BM25",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on BEIR"
    },
    {
      "source": "DPR",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "DPR potentially trained on Natural Questions"
    },
    {
      "source": "DPR",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "DPR potentially trained on TriviaQA"
    },
    {
      "source": "DPR",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "DPR potentially trained on MS-MARCO"
    },
    {
      "source": "DPR",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "DPR potentially trained on HotpotQA"
    },
    {
      "source": "DPR",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "DPR potentially trained on BEIR"
    },
    {
      "source": "ChatGPT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on Natural Questions"
    },
    {
      "source": "ChatGPT",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on TriviaQA"
    },
    {
      "source": "ChatGPT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on MS-MARCO"
    },
    {
      "source": "ChatGPT",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on HotpotQA"
    },
    {
      "source": "ChatGPT",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on BEIR"
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on MS-MARCO"
    },
    {
      "source": "GPT-3",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on HotpotQA"
    },
    {
      "source": "GPT-3",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on BEIR"
    },
    {
      "source": "T5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions"
    },
    {
      "source": "T5",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on TriviaQA"
    },
    {
      "source": "T5",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "T5 potentially trained on MS-MARCO"
    },
    {
      "source": "T5",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "T5 potentially trained on HotpotQA"
    },
    {
      "source": "T5",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "T5 potentially trained on BEIR"
    },
    {
      "source": "BART",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions"
    },
    {
      "source": "BART",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on TriviaQA"
    },
    {
      "source": "BART",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BART potentially trained on MS-MARCO"
    },
    {
      "source": "BART",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "BART potentially trained on HotpotQA"
    },
    {
      "source": "BART",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BART potentially trained on BEIR"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "PipelineRAG",
      "target": "Information Extraction",
      "keywords": "supports",
      "description": "PipelineRAG supports Information Extraction"
    },
    {
      "source": "PipelineRAG",
      "target": "Fact Checking",
      "keywords": "supports",
      "description": "PipelineRAG supports Fact Checking"
    },
    {
      "source": "PipelineRAG",
      "target": "Code Search",
      "keywords": "supports",
      "description": "PipelineRAG supports Code Search"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "Information Extraction",
      "keywords": "supports",
      "description": "HybridRetrieval supports Information Extraction"
    },
    {
      "source": "HybridRetrieval",
      "target": "Fact Checking",
      "keywords": "supports",
      "description": "HybridRetrieval supports Fact Checking"
    },
    {
      "source": "HybridRetrieval",
      "target": "Code Search",
      "keywords": "supports",
      "description": "HybridRetrieval supports Code Search"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Information Extraction",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Information Extraction"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Fact Checking",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Fact Checking"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Code Search",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Code Search"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "Information Extraction",
      "keywords": "supports",
      "description": "JointTraining supports Information Extraction"
    },
    {
      "source": "JointTraining",
      "target": "Fact Checking",
      "keywords": "supports",
      "description": "JointTraining supports Fact Checking"
    },
    {
      "source": "JointTraining",
      "target": "Code Search",
      "keywords": "supports",
      "description": "JointTraining supports Code Search"
    },
    {
      "source": "Guangzhi Xiong",
      "target": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "keywords": "authorship",
      "description": "Guangzhi Xiong authored Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "source": "Qiao Jin",
      "target": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "keywords": "authorship",
      "description": "Qiao Jin authored Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "source": "Xiao Wang",
      "target": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "keywords": "authorship",
      "description": "Xiao Wang authored Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "source": "Minjia Zhang",
      "target": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "keywords": "authorship",
      "description": "Minjia Zhang authored Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "source": "Zhiyong Lu",
      "target": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "keywords": "authorship",
      "description": "Zhiyong Lu authored Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "source": "Aidong Zhang",
      "target": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "keywords": "authorship",
      "description": "Aidong Zhang authored Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions"
    },
    {
      "source": "Guangzhi Xiong",
      "target": "Department of Computer Science, University of Virginia",
      "keywords": "affiliation",
      "description": "Guangzhi Xiong affiliated with Department of Computer Science, University of Virginia"
    },
    {
      "source": "Guangzhi Xiong",
      "target": "National Library of Medicine, National Institutes of Health",
      "keywords": "affiliation",
      "description": "Guangzhi Xiong affiliated with National Library of Medicine, National Institutes of Health"
    },
    {
      "source": "Guangzhi Xiong",
      "target": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "keywords": "affiliation",
      "description": "Guangzhi Xiong affiliated with Department of Computer Science, University of Illinois Urbana-Champaign"
    },
    {
      "source": "Qiao Jin",
      "target": "Department of Computer Science, University of Virginia",
      "keywords": "affiliation",
      "description": "Qiao Jin affiliated with Department of Computer Science, University of Virginia"
    },
    {
      "source": "Qiao Jin",
      "target": "National Library of Medicine, National Institutes of Health",
      "keywords": "affiliation",
      "description": "Qiao Jin affiliated with National Library of Medicine, National Institutes of Health"
    },
    {
      "source": "Qiao Jin",
      "target": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "keywords": "affiliation",
      "description": "Qiao Jin affiliated with Department of Computer Science, University of Illinois Urbana-Champaign"
    },
    {
      "source": "Xiao Wang",
      "target": "Department of Computer Science, University of Virginia",
      "keywords": "affiliation",
      "description": "Xiao Wang affiliated with Department of Computer Science, University of Virginia"
    },
    {
      "source": "Xiao Wang",
      "target": "National Library of Medicine, National Institutes of Health",
      "keywords": "affiliation",
      "description": "Xiao Wang affiliated with National Library of Medicine, National Institutes of Health"
    },
    {
      "source": "Xiao Wang",
      "target": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "keywords": "affiliation",
      "description": "Xiao Wang affiliated with Department of Computer Science, University of Illinois Urbana-Champaign"
    },
    {
      "source": "Minjia Zhang",
      "target": "Department of Computer Science, University of Virginia",
      "keywords": "affiliation",
      "description": "Minjia Zhang affiliated with Department of Computer Science, University of Virginia"
    },
    {
      "source": "Minjia Zhang",
      "target": "National Library of Medicine, National Institutes of Health",
      "keywords": "affiliation",
      "description": "Minjia Zhang affiliated with National Library of Medicine, National Institutes of Health"
    },
    {
      "source": "Minjia Zhang",
      "target": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "keywords": "affiliation",
      "description": "Minjia Zhang affiliated with Department of Computer Science, University of Illinois Urbana-Champaign"
    },
    {
      "source": "Zhiyong Lu",
      "target": "Department of Computer Science, University of Virginia",
      "keywords": "affiliation",
      "description": "Zhiyong Lu affiliated with Department of Computer Science, University of Virginia"
    },
    {
      "source": "Zhiyong Lu",
      "target": "National Library of Medicine, National Institutes of Health",
      "keywords": "affiliation",
      "description": "Zhiyong Lu affiliated with National Library of Medicine, National Institutes of Health"
    },
    {
      "source": "Zhiyong Lu",
      "target": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "keywords": "affiliation",
      "description": "Zhiyong Lu affiliated with Department of Computer Science, University of Illinois Urbana-Champaign"
    },
    {
      "source": "Aidong Zhang",
      "target": "Department of Computer Science, University of Virginia",
      "keywords": "affiliation",
      "description": "Aidong Zhang affiliated with Department of Computer Science, University of Virginia"
    },
    {
      "source": "Aidong Zhang",
      "target": "National Library of Medicine, National Institutes of Health",
      "keywords": "affiliation",
      "description": "Aidong Zhang affiliated with National Library of Medicine, National Institutes of Health"
    },
    {
      "source": "Aidong Zhang",
      "target": "Department of Computer Science, University of Illinois Urbana-Champaign",
      "keywords": "affiliation",
      "description": "Aidong Zhang affiliated with Department of Computer Science, University of Illinois Urbana-Champaign"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "MedCPT",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses MedCPT"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "GPT-3.5-Turbo",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses GPT-3.5-Turbo"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "Llama-3.1-8B",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses Llama-3.1-8B"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "MedQA",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses MedQA"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "MMLU-Med",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses MMLU-Med"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "PubMedQA",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses PubMedQA"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "BioASQ",
      "keywords": "uses",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions uses BioASQ"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "IterativeRAG",
      "keywords": "proposes",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions proposes IterativeRAG"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions proposes DenseRetrieval"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "IterativeGeneration",
      "keywords": "proposes",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions proposes IterativeGeneration"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions proposes SeparateTraining"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions applies to QA"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "Medical Question Answering",
      "keywords": "applies_to",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions applies to Medical Question Answering"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions applies to MedicalRAG"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "Clinical decision support",
      "keywords": "applies_to",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions applies to Clinical decision support"
    },
    {
      "source": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
      "target": "Medical licensing examination preparation",
      "keywords": "applies_to",
      "description": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions applies to Medical licensing examination preparation"
    },
    {
      "source": "MedCPT",
      "target": "MedQA",
      "keywords": "trained_on",
      "description": "MedCPT potentially trained on MedQA"
    },
    {
      "source": "MedCPT",
      "target": "MMLU-Med",
      "keywords": "trained_on",
      "description": "MedCPT potentially trained on MMLU-Med"
    },
    {
      "source": "MedCPT",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "MedCPT potentially trained on PubMedQA"
    },
    {
      "source": "MedCPT",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "MedCPT potentially trained on BioASQ"
    },
    {
      "source": "GPT-3.5-Turbo",
      "target": "MedQA",
      "keywords": "trained_on",
      "description": "GPT-3.5-Turbo potentially trained on MedQA"
    },
    {
      "source": "GPT-3.5-Turbo",
      "target": "MMLU-Med",
      "keywords": "trained_on",
      "description": "GPT-3.5-Turbo potentially trained on MMLU-Med"
    },
    {
      "source": "GPT-3.5-Turbo",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "GPT-3.5-Turbo potentially trained on PubMedQA"
    },
    {
      "source": "GPT-3.5-Turbo",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "GPT-3.5-Turbo potentially trained on BioASQ"
    },
    {
      "source": "Llama-3.1-8B",
      "target": "MedQA",
      "keywords": "trained_on",
      "description": "Llama-3.1-8B potentially trained on MedQA"
    },
    {
      "source": "Llama-3.1-8B",
      "target": "MMLU-Med",
      "keywords": "trained_on",
      "description": "Llama-3.1-8B potentially trained on MMLU-Med"
    },
    {
      "source": "Llama-3.1-8B",
      "target": "PubMedQA",
      "keywords": "trained_on",
      "description": "Llama-3.1-8B potentially trained on PubMedQA"
    },
    {
      "source": "Llama-3.1-8B",
      "target": "BioASQ",
      "keywords": "trained_on",
      "description": "Llama-3.1-8B potentially trained on BioASQ"
    },
    {
      "source": "IterativeRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "IterativeRAG supports QA"
    },
    {
      "source": "IterativeRAG",
      "target": "Medical Question Answering",
      "keywords": "supports",
      "description": "IterativeRAG supports Medical Question Answering"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "Medical Question Answering",
      "keywords": "supports",
      "description": "DenseRetrieval supports Medical Question Answering"
    },
    {
      "source": "IterativeGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "IterativeGeneration supports QA"
    },
    {
      "source": "IterativeGeneration",
      "target": "Medical Question Answering",
      "keywords": "supports",
      "description": "IterativeGeneration supports Medical Question Answering"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "Medical Question Answering",
      "keywords": "supports",
      "description": "SeparateTraining supports Medical Question Answering"
    },
    {
      "source": "Jiawei Chen",
      "target": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Jiawei Chen authored Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "source": "Hongyu Lin",
      "target": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Hongyu Lin authored Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "source": "Xianpei Han",
      "target": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Xianpei Han authored Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "source": "Le Sun",
      "target": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Le Sun authored Benchmarking Large Language Models in Retrieval-Augmented Generation"
    },
    {
      "source": "Jiawei Chen",
      "target": "Chinese Information Processing Laboratory",
      "keywords": "affiliation",
      "description": "Jiawei Chen affiliated with Chinese Information Processing Laboratory"
    },
    {
      "source": "Jiawei Chen",
      "target": "State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Jiawei Chen affiliated with State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences"
    },
    {
      "source": "Jiawei Chen",
      "target": "University of Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Jiawei Chen affiliated with University of Chinese Academy of Sciences"
    },
    {
      "source": "Hongyu Lin",
      "target": "Chinese Information Processing Laboratory",
      "keywords": "affiliation",
      "description": "Hongyu Lin affiliated with Chinese Information Processing Laboratory"
    },
    {
      "source": "Hongyu Lin",
      "target": "State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Hongyu Lin affiliated with State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences"
    },
    {
      "source": "Hongyu Lin",
      "target": "University of Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Hongyu Lin affiliated with University of Chinese Academy of Sciences"
    },
    {
      "source": "Xianpei Han",
      "target": "Chinese Information Processing Laboratory",
      "keywords": "affiliation",
      "description": "Xianpei Han affiliated with Chinese Information Processing Laboratory"
    },
    {
      "source": "Xianpei Han",
      "target": "State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Xianpei Han affiliated with State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences"
    },
    {
      "source": "Xianpei Han",
      "target": "University of Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Xianpei Han affiliated with University of Chinese Academy of Sciences"
    },
    {
      "source": "Le Sun",
      "target": "Chinese Information Processing Laboratory",
      "keywords": "affiliation",
      "description": "Le Sun affiliated with Chinese Information Processing Laboratory"
    },
    {
      "source": "Le Sun",
      "target": "State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Le Sun affiliated with State Key Laboratory of Computer Science Institute of Software, Chinese Academy of Sciences"
    },
    {
      "source": "Le Sun",
      "target": "University of Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Le Sun affiliated with University of Chinese Academy of Sciences"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "m3e-base",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses m3e-base"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "all-mpnet-base-v2",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses all-mpnet-base-v2"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "ChatGPT",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses ChatGPT"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "ChatGLM-6B",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses ChatGLM-6B"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "ChatGLM2-6B",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses ChatGLM2-6B"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "Vicuna-7B-v1.3",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses Vicuna-7B-v1.3"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "Qwen-7B-Chat",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses Qwen-7B-Chat"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "BELLE-7B-2M",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses BELLE-7B-2M"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "uses",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation uses RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation proposes PipelineRAG"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation proposes HybridRetrieval"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation proposes AbstractiveGeneration"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation proposes SeparateTraining"
    },
    {
      "source": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Benchmarking Large Language Models in Retrieval-Augmented Generation applies to QA"
    },
    {
      "source": "m3e-base",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "m3e-base potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "all-mpnet-base-v2",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "all-mpnet-base-v2 potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "ChatGPT",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "ChatGPT potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "ChatGLM-6B",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "ChatGLM-6B potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "ChatGLM2-6B",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "ChatGLM2-6B potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "Vicuna-7B-v1.3",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "Vicuna-7B-v1.3 potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "Qwen-7B-Chat",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "Qwen-7B-Chat potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "BELLE-7B-2M",
      "target": "RGB (Retrieval-Augmented Generation Benchmark)",
      "keywords": "trained_on",
      "description": "BELLE-7B-2M potentially trained on RGB (Retrieval-Augmented Generation Benchmark)"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "Mike Lewis",
      "target": "Pre-training via Paraphrasing",
      "keywords": "authorship",
      "description": "Mike Lewis authored Pre-training via Paraphrasing"
    },
    {
      "source": "Marjan Ghazvininejad",
      "target": "Pre-training via Paraphrasing",
      "keywords": "authorship",
      "description": "Marjan Ghazvininejad authored Pre-training via Paraphrasing"
    },
    {
      "source": "Gargi Ghosh",
      "target": "Pre-training via Paraphrasing",
      "keywords": "authorship",
      "description": "Gargi Ghosh authored Pre-training via Paraphrasing"
    },
    {
      "source": "Armen Aghajanyan",
      "target": "Pre-training via Paraphrasing",
      "keywords": "authorship",
      "description": "Armen Aghajanyan authored Pre-training via Paraphrasing"
    },
    {
      "source": "Sida Wang",
      "target": "Pre-training via Paraphrasing",
      "keywords": "authorship",
      "description": "Sida Wang authored Pre-training via Paraphrasing"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Pre-training via Paraphrasing",
      "keywords": "authorship",
      "description": "Luke Zettlemoyer authored Pre-training via Paraphrasing"
    },
    {
      "source": "Mike Lewis",
      "target": "Facebook AI",
      "keywords": "affiliation",
      "description": "Mike Lewis affiliated with Facebook AI"
    },
    {
      "source": "Marjan Ghazvininejad",
      "target": "Facebook AI",
      "keywords": "affiliation",
      "description": "Marjan Ghazvininejad affiliated with Facebook AI"
    },
    {
      "source": "Gargi Ghosh",
      "target": "Facebook AI",
      "keywords": "affiliation",
      "description": "Gargi Ghosh affiliated with Facebook AI"
    },
    {
      "source": "Armen Aghajanyan",
      "target": "Facebook AI",
      "keywords": "affiliation",
      "description": "Armen Aghajanyan affiliated with Facebook AI"
    },
    {
      "source": "Sida Wang",
      "target": "Facebook AI",
      "keywords": "affiliation",
      "description": "Sida Wang affiliated with Facebook AI"
    },
    {
      "source": "Luke Zettlemoyer",
      "target": "Facebook AI",
      "keywords": "affiliation",
      "description": "Luke Zettlemoyer affiliated with Facebook AI"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "Document encoder g",
      "keywords": "uses",
      "description": "Pre-training via Paraphrasing uses Document encoder g"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "MARGE",
      "keywords": "uses",
      "description": "Pre-training via Paraphrasing uses MARGE"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "CC-NEWS",
      "keywords": "uses",
      "description": "Pre-training via Paraphrasing uses CC-NEWS"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "Wikipedia",
      "keywords": "uses",
      "description": "Pre-training via Paraphrasing uses Wikipedia"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "BUCC2018",
      "keywords": "uses",
      "description": "Pre-training via Paraphrasing uses BUCC2018"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "Tatoeba",
      "keywords": "uses",
      "description": "Pre-training via Paraphrasing uses Tatoeba"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Pre-training via Paraphrasing proposes PipelineRAG"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Pre-training via Paraphrasing proposes DenseRetrieval"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Pre-training via Paraphrasing proposes AbstractiveGeneration"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Pre-training via Paraphrasing proposes JointTraining"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Pre-training via Paraphrasing applies to DocumentSummarization"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Pre-training via Paraphrasing applies to QA"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Pre-training via Paraphrasing applies to ConversationalAI"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "Cross-lingual transfer",
      "keywords": "applies_to",
      "description": "Pre-training via Paraphrasing applies to Cross-lingual transfer"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "Document-level machine translation",
      "keywords": "applies_to",
      "description": "Pre-training via Paraphrasing applies to Document-level machine translation"
    },
    {
      "source": "Pre-training via Paraphrasing",
      "target": "Zero-shot learning",
      "keywords": "applies_to",
      "description": "Pre-training via Paraphrasing applies to Zero-shot learning"
    },
    {
      "source": "Document encoder g",
      "target": "CC-NEWS",
      "keywords": "trained_on",
      "description": "Document encoder g potentially trained on CC-NEWS"
    },
    {
      "source": "Document encoder g",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "Document encoder g potentially trained on Wikipedia"
    },
    {
      "source": "Document encoder g",
      "target": "BUCC2018",
      "keywords": "trained_on",
      "description": "Document encoder g potentially trained on BUCC2018"
    },
    {
      "source": "Document encoder g",
      "target": "Tatoeba",
      "keywords": "trained_on",
      "description": "Document encoder g potentially trained on Tatoeba"
    },
    {
      "source": "MARGE",
      "target": "CC-NEWS",
      "keywords": "trained_on",
      "description": "MARGE potentially trained on CC-NEWS"
    },
    {
      "source": "MARGE",
      "target": "Wikipedia",
      "keywords": "trained_on",
      "description": "MARGE potentially trained on Wikipedia"
    },
    {
      "source": "MARGE",
      "target": "BUCC2018",
      "keywords": "trained_on",
      "description": "MARGE potentially trained on BUCC2018"
    },
    {
      "source": "MARGE",
      "target": "Tatoeba",
      "keywords": "trained_on",
      "description": "MARGE potentially trained on Tatoeba"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "DenseRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Huayang Li",
      "target": "A Survey on Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Huayang Li authored A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "source": "Yixuan Su",
      "target": "A Survey on Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Yixuan Su authored A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "source": "Deng Cai",
      "target": "A Survey on Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Deng Cai authored A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "source": "Yan Wang",
      "target": "A Survey on Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Yan Wang authored A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "source": "Lemao Liu",
      "target": "A Survey on Retrieval-Augmented Text Generation",
      "keywords": "authorship",
      "description": "Lemao Liu authored A Survey on Retrieval-Augmented Text Generation"
    },
    {
      "source": "Huayang Li",
      "target": "Nara Institute of Science and Technology",
      "keywords": "affiliation",
      "description": "Huayang Li affiliated with Nara Institute of Science and Technology"
    },
    {
      "source": "Huayang Li",
      "target": "University of Cambridge",
      "keywords": "affiliation",
      "description": "Huayang Li affiliated with University of Cambridge"
    },
    {
      "source": "Huayang Li",
      "target": "The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Huayang Li affiliated with The Chinese University of Hong Kong"
    },
    {
      "source": "Huayang Li",
      "target": "Tencent AI Lab",
      "keywords": "affiliation",
      "description": "Huayang Li affiliated with Tencent AI Lab"
    },
    {
      "source": "Yixuan Su",
      "target": "Nara Institute of Science and Technology",
      "keywords": "affiliation",
      "description": "Yixuan Su affiliated with Nara Institute of Science and Technology"
    },
    {
      "source": "Yixuan Su",
      "target": "University of Cambridge",
      "keywords": "affiliation",
      "description": "Yixuan Su affiliated with University of Cambridge"
    },
    {
      "source": "Yixuan Su",
      "target": "The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Yixuan Su affiliated with The Chinese University of Hong Kong"
    },
    {
      "source": "Yixuan Su",
      "target": "Tencent AI Lab",
      "keywords": "affiliation",
      "description": "Yixuan Su affiliated with Tencent AI Lab"
    },
    {
      "source": "Deng Cai",
      "target": "Nara Institute of Science and Technology",
      "keywords": "affiliation",
      "description": "Deng Cai affiliated with Nara Institute of Science and Technology"
    },
    {
      "source": "Deng Cai",
      "target": "University of Cambridge",
      "keywords": "affiliation",
      "description": "Deng Cai affiliated with University of Cambridge"
    },
    {
      "source": "Deng Cai",
      "target": "The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Deng Cai affiliated with The Chinese University of Hong Kong"
    },
    {
      "source": "Deng Cai",
      "target": "Tencent AI Lab",
      "keywords": "affiliation",
      "description": "Deng Cai affiliated with Tencent AI Lab"
    },
    {
      "source": "Yan Wang",
      "target": "Nara Institute of Science and Technology",
      "keywords": "affiliation",
      "description": "Yan Wang affiliated with Nara Institute of Science and Technology"
    },
    {
      "source": "Yan Wang",
      "target": "University of Cambridge",
      "keywords": "affiliation",
      "description": "Yan Wang affiliated with University of Cambridge"
    },
    {
      "source": "Yan Wang",
      "target": "The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Yan Wang affiliated with The Chinese University of Hong Kong"
    },
    {
      "source": "Yan Wang",
      "target": "Tencent AI Lab",
      "keywords": "affiliation",
      "description": "Yan Wang affiliated with Tencent AI Lab"
    },
    {
      "source": "Lemao Liu",
      "target": "Nara Institute of Science and Technology",
      "keywords": "affiliation",
      "description": "Lemao Liu affiliated with Nara Institute of Science and Technology"
    },
    {
      "source": "Lemao Liu",
      "target": "University of Cambridge",
      "keywords": "affiliation",
      "description": "Lemao Liu affiliated with University of Cambridge"
    },
    {
      "source": "Lemao Liu",
      "target": "The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Lemao Liu affiliated with The Chinese University of Hong Kong"
    },
    {
      "source": "Lemao Liu",
      "target": "Tencent AI Lab",
      "keywords": "affiliation",
      "description": "Lemao Liu affiliated with Tencent AI Lab"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "BERT-based encoders",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses BERT-based encoders"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "TF-IDF",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses TF-IDF"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "BM25",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses BM25"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "SEQ2SEQ encoder-decoder",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses SEQ2SEQ encoder-decoder"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "Transformer",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses Transformer"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "RNN-based models",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses RNN-based models"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "Training Corpus",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses Training Corpus"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "External Datasets",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses External Datasets"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "Unsupervised Corpus",
      "keywords": "uses",
      "description": "A Survey on Retrieval-Augmented Text Generation uses Unsupervised Corpus"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "A Survey on Retrieval-Augmented Text Generation proposes PipelineRAG"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "A Survey on Retrieval-Augmented Text Generation proposes HybridRetrieval"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "A Survey on Retrieval-Augmented Text Generation proposes HybridGeneration"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "A Survey on Retrieval-Augmented Text Generation proposes SeparateTraining"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to QA"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to ConversationalAI"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to DocumentSummarization"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "dialogue response generation",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to dialogue response generation"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "machine translation",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to machine translation"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "language modeling",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to language modeling"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "paraphrase generation",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to paraphrase generation"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "text style transfer",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to text style transfer"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "data-to-text generation",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to data-to-text generation"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "code generation",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to code generation"
    },
    {
      "source": "A Survey on Retrieval-Augmented Text Generation",
      "target": "abstractive summarization",
      "keywords": "applies_to",
      "description": "A Survey on Retrieval-Augmented Text Generation applies to abstractive summarization"
    },
    {
      "source": "BERT-based encoders",
      "target": "Training Corpus",
      "keywords": "trained_on",
      "description": "BERT-based encoders potentially trained on Training Corpus"
    },
    {
      "source": "BERT-based encoders",
      "target": "External Datasets",
      "keywords": "trained_on",
      "description": "BERT-based encoders potentially trained on External Datasets"
    },
    {
      "source": "BERT-based encoders",
      "target": "Unsupervised Corpus",
      "keywords": "trained_on",
      "description": "BERT-based encoders potentially trained on Unsupervised Corpus"
    },
    {
      "source": "TF-IDF",
      "target": "Training Corpus",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on Training Corpus"
    },
    {
      "source": "TF-IDF",
      "target": "External Datasets",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on External Datasets"
    },
    {
      "source": "TF-IDF",
      "target": "Unsupervised Corpus",
      "keywords": "trained_on",
      "description": "TF-IDF potentially trained on Unsupervised Corpus"
    },
    {
      "source": "BM25",
      "target": "Training Corpus",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Training Corpus"
    },
    {
      "source": "BM25",
      "target": "External Datasets",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on External Datasets"
    },
    {
      "source": "BM25",
      "target": "Unsupervised Corpus",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Unsupervised Corpus"
    },
    {
      "source": "SEQ2SEQ encoder-decoder",
      "target": "Training Corpus",
      "keywords": "trained_on",
      "description": "SEQ2SEQ encoder-decoder potentially trained on Training Corpus"
    },
    {
      "source": "SEQ2SEQ encoder-decoder",
      "target": "External Datasets",
      "keywords": "trained_on",
      "description": "SEQ2SEQ encoder-decoder potentially trained on External Datasets"
    },
    {
      "source": "SEQ2SEQ encoder-decoder",
      "target": "Unsupervised Corpus",
      "keywords": "trained_on",
      "description": "SEQ2SEQ encoder-decoder potentially trained on Unsupervised Corpus"
    },
    {
      "source": "Transformer",
      "target": "Training Corpus",
      "keywords": "trained_on",
      "description": "Transformer potentially trained on Training Corpus"
    },
    {
      "source": "Transformer",
      "target": "External Datasets",
      "keywords": "trained_on",
      "description": "Transformer potentially trained on External Datasets"
    },
    {
      "source": "Transformer",
      "target": "Unsupervised Corpus",
      "keywords": "trained_on",
      "description": "Transformer potentially trained on Unsupervised Corpus"
    },
    {
      "source": "RNN-based models",
      "target": "Training Corpus",
      "keywords": "trained_on",
      "description": "RNN-based models potentially trained on Training Corpus"
    },
    {
      "source": "RNN-based models",
      "target": "External Datasets",
      "keywords": "trained_on",
      "description": "RNN-based models potentially trained on External Datasets"
    },
    {
      "source": "RNN-based models",
      "target": "Unsupervised Corpus",
      "keywords": "trained_on",
      "description": "RNN-based models potentially trained on Unsupervised Corpus"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridGeneration supports ConversationalAI"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "SeparateTraining supports ConversationalAI"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Alireza Salemi",
      "target": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Alireza Salemi authored Evaluating Retrieval Quality in Retrieval-Augmented Generation"
    },
    {
      "source": "Hamed Zamani",
      "target": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "keywords": "authorship",
      "description": "Hamed Zamani authored Evaluating Retrieval Quality in Retrieval-Augmented Generation"
    },
    {
      "source": "Alireza Salemi",
      "target": "University of Massachusetts Amherst",
      "keywords": "affiliation",
      "description": "Alireza Salemi affiliated with University of Massachusetts Amherst"
    },
    {
      "source": "Hamed Zamani",
      "target": "University of Massachusetts Amherst",
      "keywords": "affiliation",
      "description": "Hamed Zamani affiliated with University of Massachusetts Amherst"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "BM25",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses BM25"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Contriever",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses Contriever"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "T5-small",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses T5-small"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "T5-base",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses T5-base"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Mistral-7B",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses Mistral-7B"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses Natural Questions (NQ)"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses TriviaQA"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "HotpotQA",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses HotpotQA"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "FEVER",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses FEVER"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "uses",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation uses Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation proposes PipelineRAG"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation proposes HybridRetrieval"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation proposes AbstractiveGeneration"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation proposes FinetuningStrategy"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation applies to QA"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation applies to DocumentSummarization"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation applies to ConversationalAI"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Open-domain question answering",
      "keywords": "applies_to",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation applies to Open-domain question answering"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Fact verification",
      "keywords": "applies_to",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation applies to Fact verification"
    },
    {
      "source": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
      "target": "Knowledge-grounded dialogue",
      "keywords": "applies_to",
      "description": "Evaluating Retrieval Quality in Retrieval-Augmented Generation applies to Knowledge-grounded dialogue"
    },
    {
      "source": "BM25",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BM25",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TriviaQA"
    },
    {
      "source": "BM25",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on HotpotQA"
    },
    {
      "source": "BM25",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on FEVER"
    },
    {
      "source": "BM25",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Contriever",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on TriviaQA"
    },
    {
      "source": "Contriever",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on HotpotQA"
    },
    {
      "source": "Contriever",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on FEVER"
    },
    {
      "source": "Contriever",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "T5-small",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "T5-small potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "T5-small",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5-small potentially trained on TriviaQA"
    },
    {
      "source": "T5-small",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "T5-small potentially trained on HotpotQA"
    },
    {
      "source": "T5-small",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "T5-small potentially trained on FEVER"
    },
    {
      "source": "T5-small",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "T5-small potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "T5-base",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "T5-base",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on TriviaQA"
    },
    {
      "source": "T5-base",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on HotpotQA"
    },
    {
      "source": "T5-base",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on FEVER"
    },
    {
      "source": "T5-base",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "T5-base potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "Mistral-7B",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Mistral-7B potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Mistral-7B",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "Mistral-7B potentially trained on TriviaQA"
    },
    {
      "source": "Mistral-7B",
      "target": "HotpotQA",
      "keywords": "trained_on",
      "description": "Mistral-7B potentially trained on HotpotQA"
    },
    {
      "source": "Mistral-7B",
      "target": "FEVER",
      "keywords": "trained_on",
      "description": "Mistral-7B potentially trained on FEVER"
    },
    {
      "source": "Mistral-7B",
      "target": "Wizard of Wikipedia (WoW)",
      "keywords": "trained_on",
      "description": "Mistral-7B potentially trained on Wizard of Wikipedia (WoW)"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "FinetuningStrategy supports ConversationalAI"
    },
    {
      "source": "Nikhil Kandpal",
      "target": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "keywords": "authorship",
      "description": "Nikhil Kandpal authored Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "source": "Haikang Deng",
      "target": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "keywords": "authorship",
      "description": "Haikang Deng authored Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "source": "Adam Roberts",
      "target": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "keywords": "authorship",
      "description": "Adam Roberts authored Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "source": "Eric Wallace",
      "target": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "keywords": "authorship",
      "description": "Eric Wallace authored Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "source": "Colin Raffel",
      "target": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "keywords": "authorship",
      "description": "Colin Raffel authored Large Language Models Struggle to Learn Long-Tail Knowledge"
    },
    {
      "source": "Nikhil Kandpal",
      "target": "UNC Chapel Hill",
      "keywords": "affiliation",
      "description": "Nikhil Kandpal affiliated with UNC Chapel Hill"
    },
    {
      "source": "Nikhil Kandpal",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Nikhil Kandpal affiliated with Google Research"
    },
    {
      "source": "Nikhil Kandpal",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Nikhil Kandpal affiliated with UC Berkeley"
    },
    {
      "source": "Haikang Deng",
      "target": "UNC Chapel Hill",
      "keywords": "affiliation",
      "description": "Haikang Deng affiliated with UNC Chapel Hill"
    },
    {
      "source": "Haikang Deng",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Haikang Deng affiliated with Google Research"
    },
    {
      "source": "Haikang Deng",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Haikang Deng affiliated with UC Berkeley"
    },
    {
      "source": "Adam Roberts",
      "target": "UNC Chapel Hill",
      "keywords": "affiliation",
      "description": "Adam Roberts affiliated with UNC Chapel Hill"
    },
    {
      "source": "Adam Roberts",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Adam Roberts affiliated with Google Research"
    },
    {
      "source": "Adam Roberts",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Adam Roberts affiliated with UC Berkeley"
    },
    {
      "source": "Eric Wallace",
      "target": "UNC Chapel Hill",
      "keywords": "affiliation",
      "description": "Eric Wallace affiliated with UNC Chapel Hill"
    },
    {
      "source": "Eric Wallace",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Eric Wallace affiliated with Google Research"
    },
    {
      "source": "Eric Wallace",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Eric Wallace affiliated with UC Berkeley"
    },
    {
      "source": "Colin Raffel",
      "target": "UNC Chapel Hill",
      "keywords": "affiliation",
      "description": "Colin Raffel affiliated with UNC Chapel Hill"
    },
    {
      "source": "Colin Raffel",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Colin Raffel affiliated with Google Research"
    },
    {
      "source": "Colin Raffel",
      "target": "UC Berkeley",
      "keywords": "affiliation",
      "description": "Colin Raffel affiliated with UC Berkeley"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "DBpedia Spotlight Entity Linker",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses DBpedia Spotlight Entity Linker"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "BM25",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses BM25"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "GPT-Neo",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses GPT-Neo"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "BLOOM",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses BLOOM"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses GPT-3"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "TriviaQA",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses TriviaQA"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge uses Natural Questions"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge proposes PipelineRAG"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "SparseRetrieval",
      "keywords": "proposes",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge proposes SparseRetrieval"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge proposes AbstractiveGeneration"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge proposes SeparateTraining"
    },
    {
      "source": "Large Language Models Struggle to Learn Long-Tail Knowledge",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Large Language Models Struggle to Learn Long-Tail Knowledge applies to QA"
    },
    {
      "source": "DBpedia Spotlight Entity Linker",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "DBpedia Spotlight Entity Linker potentially trained on TriviaQA"
    },
    {
      "source": "DBpedia Spotlight Entity Linker",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "DBpedia Spotlight Entity Linker potentially trained on Natural Questions"
    },
    {
      "source": "BM25",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TriviaQA"
    },
    {
      "source": "BM25",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-Neo",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-Neo potentially trained on TriviaQA"
    },
    {
      "source": "GPT-Neo",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-Neo potentially trained on Natural Questions"
    },
    {
      "source": "BLOOM",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on TriviaQA"
    },
    {
      "source": "BLOOM",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BLOOM potentially trained on Natural Questions"
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on TriviaQA"
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Natural Questions"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "SparseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "SparseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "Hessa A. Alawwad",
      "target": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "keywords": "authorship",
      "description": "Hessa A. Alawwad authored Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "source": "Areej Alhothali",
      "target": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "keywords": "authorship",
      "description": "Areej Alhothali authored Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "source": "Usman Naseem",
      "target": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "keywords": "authorship",
      "description": "Usman Naseem authored Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "source": "Ali Alkhathlan",
      "target": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "keywords": "authorship",
      "description": "Ali Alkhathlan authored Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "source": "Amani Jamal",
      "target": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "keywords": "authorship",
      "description": "Amani Jamal authored Enhancing textual textbook question answering with large language models and retrieval augmented generation"
    },
    {
      "source": "Hessa A. Alawwad",
      "target": "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
      "keywords": "affiliation",
      "description": "Hessa A. Alawwad affiliated with Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
    },
    {
      "source": "Hessa A. Alawwad",
      "target": "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia",
      "keywords": "affiliation",
      "description": "Hessa A. Alawwad affiliated with College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia"
    },
    {
      "source": "Hessa A. Alawwad",
      "target": "School of Computing, Macquarie University, Australia",
      "keywords": "affiliation",
      "description": "Hessa A. Alawwad affiliated with School of Computing, Macquarie University, Australia"
    },
    {
      "source": "Areej Alhothali",
      "target": "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
      "keywords": "affiliation",
      "description": "Areej Alhothali affiliated with Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
    },
    {
      "source": "Areej Alhothali",
      "target": "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia",
      "keywords": "affiliation",
      "description": "Areej Alhothali affiliated with College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia"
    },
    {
      "source": "Areej Alhothali",
      "target": "School of Computing, Macquarie University, Australia",
      "keywords": "affiliation",
      "description": "Areej Alhothali affiliated with School of Computing, Macquarie University, Australia"
    },
    {
      "source": "Usman Naseem",
      "target": "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
      "keywords": "affiliation",
      "description": "Usman Naseem affiliated with Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
    },
    {
      "source": "Usman Naseem",
      "target": "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia",
      "keywords": "affiliation",
      "description": "Usman Naseem affiliated with College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia"
    },
    {
      "source": "Usman Naseem",
      "target": "School of Computing, Macquarie University, Australia",
      "keywords": "affiliation",
      "description": "Usman Naseem affiliated with School of Computing, Macquarie University, Australia"
    },
    {
      "source": "Ali Alkhathlan",
      "target": "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
      "keywords": "affiliation",
      "description": "Ali Alkhathlan affiliated with Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
    },
    {
      "source": "Ali Alkhathlan",
      "target": "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia",
      "keywords": "affiliation",
      "description": "Ali Alkhathlan affiliated with College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia"
    },
    {
      "source": "Ali Alkhathlan",
      "target": "School of Computing, Macquarie University, Australia",
      "keywords": "affiliation",
      "description": "Ali Alkhathlan affiliated with School of Computing, Macquarie University, Australia"
    },
    {
      "source": "Amani Jamal",
      "target": "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
      "keywords": "affiliation",
      "description": "Amani Jamal affiliated with Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
    },
    {
      "source": "Amani Jamal",
      "target": "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia",
      "keywords": "affiliation",
      "description": "Amani Jamal affiliated with College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Saudi Arabia"
    },
    {
      "source": "Amani Jamal",
      "target": "School of Computing, Macquarie University, Australia",
      "keywords": "affiliation",
      "description": "Amani Jamal affiliated with School of Computing, Macquarie University, Australia"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "text-embedding-ada-002",
      "keywords": "uses",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation uses text-embedding-ada-002"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "Llama-2",
      "keywords": "uses",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation uses Llama-2"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "CK12-QA",
      "keywords": "uses",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation uses CK12-QA"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation proposes PipelineRAG"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation proposes DenseRetrieval"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation proposes AbstractiveGeneration"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "FinetunedModel",
      "keywords": "proposes",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation proposes FinetunedModel"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation applies to QA"
    },
    {
      "source": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Enhancing textual textbook question answering with large language models and retrieval augmented generation applies to EducationalRAG"
    },
    {
      "source": "text-embedding-ada-002",
      "target": "CK12-QA",
      "keywords": "trained_on",
      "description": "text-embedding-ada-002 potentially trained on CK12-QA"
    },
    {
      "source": "Llama-2",
      "target": "CK12-QA",
      "keywords": "trained_on",
      "description": "Llama-2 potentially trained on CK12-QA"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "FinetunedModel",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetunedModel supports QA"
    },
    {
      "source": "Markus J. Buehler",
      "target": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "keywords": "authorship",
      "description": "Markus J. Buehler authored MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities"
    },
    {
      "source": "Markus J. Buehler",
      "target": "Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology",
      "keywords": "affiliation",
      "description": "Markus J. Buehler affiliated with Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology"
    },
    {
      "source": "Markus J. Buehler",
      "target": "Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology",
      "keywords": "affiliation",
      "description": "Markus J. Buehler affiliated with Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Google Scholar search",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses Google Scholar search"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "MechGPT-13B",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses MechGPT-13B"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "MechGPT-70B",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses MechGPT-70B"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "MechGPT-70B-XL",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses MechGPT-70B-XL"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses GPT-4"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Atomistic Modeling of Materials Failure textbook",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses Atomistic Modeling of Materials Failure textbook"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Question-Answer pairs",
      "keywords": "uses",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities uses Question-Answer pairs"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "HierarchicalRAG",
      "keywords": "proposes",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities proposes HierarchicalRAG"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities proposes HybridRetrieval"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities proposes HybridGeneration"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities proposes FinetuningStrategy"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "QA",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to QA"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Knowledge retrieval",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Knowledge retrieval"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Hypothesis generation",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Hypothesis generation"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Cross-domain reasoning",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Cross-domain reasoning"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Research development",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Research development"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "MechanicsRAG",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to MechanicsRAG"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Materials science research",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Materials science research"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Scientific literature analysis",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Scientific literature analysis"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Educational applications",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Educational applications"
    },
    {
      "source": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities",
      "target": "Creative problem solving",
      "keywords": "applies_to",
      "description": "MechGPT, a language-based strategy for mechanics and materials modeling that connects knowledge across scales, disciplines and modalities applies to Creative problem solving"
    },
    {
      "source": "Google Scholar search",
      "target": "Atomistic Modeling of Materials Failure textbook",
      "keywords": "trained_on",
      "description": "Google Scholar search potentially trained on Atomistic Modeling of Materials Failure textbook"
    },
    {
      "source": "Google Scholar search",
      "target": "Question-Answer pairs",
      "keywords": "trained_on",
      "description": "Google Scholar search potentially trained on Question-Answer pairs"
    },
    {
      "source": "MechGPT-13B",
      "target": "Atomistic Modeling of Materials Failure textbook",
      "keywords": "trained_on",
      "description": "MechGPT-13B potentially trained on Atomistic Modeling of Materials Failure textbook"
    },
    {
      "source": "MechGPT-13B",
      "target": "Question-Answer pairs",
      "keywords": "trained_on",
      "description": "MechGPT-13B potentially trained on Question-Answer pairs"
    },
    {
      "source": "MechGPT-70B",
      "target": "Atomistic Modeling of Materials Failure textbook",
      "keywords": "trained_on",
      "description": "MechGPT-70B potentially trained on Atomistic Modeling of Materials Failure textbook"
    },
    {
      "source": "MechGPT-70B",
      "target": "Question-Answer pairs",
      "keywords": "trained_on",
      "description": "MechGPT-70B potentially trained on Question-Answer pairs"
    },
    {
      "source": "MechGPT-70B-XL",
      "target": "Atomistic Modeling of Materials Failure textbook",
      "keywords": "trained_on",
      "description": "MechGPT-70B-XL potentially trained on Atomistic Modeling of Materials Failure textbook"
    },
    {
      "source": "MechGPT-70B-XL",
      "target": "Question-Answer pairs",
      "keywords": "trained_on",
      "description": "MechGPT-70B-XL potentially trained on Question-Answer pairs"
    },
    {
      "source": "GPT-4",
      "target": "Atomistic Modeling of Materials Failure textbook",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Atomistic Modeling of Materials Failure textbook"
    },
    {
      "source": "GPT-4",
      "target": "Question-Answer pairs",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Question-Answer pairs"
    },
    {
      "source": "HierarchicalRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "HierarchicalRAG supports QA"
    },
    {
      "source": "HierarchicalRAG",
      "target": "Knowledge retrieval",
      "keywords": "supports",
      "description": "HierarchicalRAG supports Knowledge retrieval"
    },
    {
      "source": "HierarchicalRAG",
      "target": "Hypothesis generation",
      "keywords": "supports",
      "description": "HierarchicalRAG supports Hypothesis generation"
    },
    {
      "source": "HierarchicalRAG",
      "target": "Cross-domain reasoning",
      "keywords": "supports",
      "description": "HierarchicalRAG supports Cross-domain reasoning"
    },
    {
      "source": "HierarchicalRAG",
      "target": "Research development",
      "keywords": "supports",
      "description": "HierarchicalRAG supports Research development"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "Knowledge retrieval",
      "keywords": "supports",
      "description": "HybridRetrieval supports Knowledge retrieval"
    },
    {
      "source": "HybridRetrieval",
      "target": "Hypothesis generation",
      "keywords": "supports",
      "description": "HybridRetrieval supports Hypothesis generation"
    },
    {
      "source": "HybridRetrieval",
      "target": "Cross-domain reasoning",
      "keywords": "supports",
      "description": "HybridRetrieval supports Cross-domain reasoning"
    },
    {
      "source": "HybridRetrieval",
      "target": "Research development",
      "keywords": "supports",
      "description": "HybridRetrieval supports Research development"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "Knowledge retrieval",
      "keywords": "supports",
      "description": "HybridGeneration supports Knowledge retrieval"
    },
    {
      "source": "HybridGeneration",
      "target": "Hypothesis generation",
      "keywords": "supports",
      "description": "HybridGeneration supports Hypothesis generation"
    },
    {
      "source": "HybridGeneration",
      "target": "Cross-domain reasoning",
      "keywords": "supports",
      "description": "HybridGeneration supports Cross-domain reasoning"
    },
    {
      "source": "HybridGeneration",
      "target": "Research development",
      "keywords": "supports",
      "description": "HybridGeneration supports Research development"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "Knowledge retrieval",
      "keywords": "supports",
      "description": "FinetuningStrategy supports Knowledge retrieval"
    },
    {
      "source": "FinetuningStrategy",
      "target": "Hypothesis generation",
      "keywords": "supports",
      "description": "FinetuningStrategy supports Hypothesis generation"
    },
    {
      "source": "FinetuningStrategy",
      "target": "Cross-domain reasoning",
      "keywords": "supports",
      "description": "FinetuningStrategy supports Cross-domain reasoning"
    },
    {
      "source": "FinetuningStrategy",
      "target": "Research development",
      "keywords": "supports",
      "description": "FinetuningStrategy supports Research development"
    },
    {
      "source": "Jimmy Lin",
      "target": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "keywords": "authorship",
      "description": "Jimmy Lin authored Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "source": "Rodrigo Nogueira",
      "target": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "keywords": "authorship",
      "description": "Rodrigo Nogueira authored Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "source": "Andrew Yates",
      "target": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "keywords": "authorship",
      "description": "Andrew Yates authored Pretrained Transformers for Text Ranking: BERT and Beyond"
    },
    {
      "source": "Jimmy Lin",
      "target": "David R. Cheriton School of Computer Science, University of Waterloo",
      "keywords": "affiliation",
      "description": "Jimmy Lin affiliated with David R. Cheriton School of Computer Science, University of Waterloo"
    },
    {
      "source": "Jimmy Lin",
      "target": "University of Amsterdam",
      "keywords": "affiliation",
      "description": "Jimmy Lin affiliated with University of Amsterdam"
    },
    {
      "source": "Jimmy Lin",
      "target": "Max Planck Institute for Informatics",
      "keywords": "affiliation",
      "description": "Jimmy Lin affiliated with Max Planck Institute for Informatics"
    },
    {
      "source": "Rodrigo Nogueira",
      "target": "David R. Cheriton School of Computer Science, University of Waterloo",
      "keywords": "affiliation",
      "description": "Rodrigo Nogueira affiliated with David R. Cheriton School of Computer Science, University of Waterloo"
    },
    {
      "source": "Rodrigo Nogueira",
      "target": "University of Amsterdam",
      "keywords": "affiliation",
      "description": "Rodrigo Nogueira affiliated with University of Amsterdam"
    },
    {
      "source": "Rodrigo Nogueira",
      "target": "Max Planck Institute for Informatics",
      "keywords": "affiliation",
      "description": "Rodrigo Nogueira affiliated with Max Planck Institute for Informatics"
    },
    {
      "source": "Andrew Yates",
      "target": "David R. Cheriton School of Computer Science, University of Waterloo",
      "keywords": "affiliation",
      "description": "Andrew Yates affiliated with David R. Cheriton School of Computer Science, University of Waterloo"
    },
    {
      "source": "Andrew Yates",
      "target": "University of Amsterdam",
      "keywords": "affiliation",
      "description": "Andrew Yates affiliated with University of Amsterdam"
    },
    {
      "source": "Andrew Yates",
      "target": "Max Planck Institute for Informatics",
      "keywords": "affiliation",
      "description": "Andrew Yates affiliated with Max Planck Institute for Informatics"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "BERT",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses BERT"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "RoBERTa",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses RoBERTa"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "ELECTRA",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses ELECTRA"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "T5",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses T5"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "GPT",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses GPT"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "BART",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses BART"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "MS MARCO",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses MS MARCO"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "Robust04",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses Robust04"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "TREC Deep Learning Track",
      "keywords": "uses",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond uses TREC Deep Learning Track"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond proposes PipelineRAG"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond proposes HybridRetrieval"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond proposes HybridGeneration"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond proposes FinetuningStrategy"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to QA"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to DocumentSummarization"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "ad hoc retrieval",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to ad hoc retrieval"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "passage retrieval",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to passage retrieval"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "document ranking",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to document ranking"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "web search",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to web search"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "scientific literature retrieval",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to scientific literature retrieval"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "biomedical search",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to biomedical search"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "legal document retrieval",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to legal document retrieval"
    },
    {
      "source": "Pretrained Transformers for Text Ranking: BERT and Beyond",
      "target": "news article ranking",
      "keywords": "applies_to",
      "description": "Pretrained Transformers for Text Ranking: BERT and Beyond applies to news article ranking"
    },
    {
      "source": "BERT",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MS MARCO"
    },
    {
      "source": "BERT",
      "target": "Robust04",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Robust04"
    },
    {
      "source": "BERT",
      "target": "TREC Deep Learning Track",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TREC Deep Learning Track"
    },
    {
      "source": "RoBERTa",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on MS MARCO"
    },
    {
      "source": "RoBERTa",
      "target": "Robust04",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on Robust04"
    },
    {
      "source": "RoBERTa",
      "target": "TREC Deep Learning Track",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on TREC Deep Learning Track"
    },
    {
      "source": "ELECTRA",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "ELECTRA potentially trained on MS MARCO"
    },
    {
      "source": "ELECTRA",
      "target": "Robust04",
      "keywords": "trained_on",
      "description": "ELECTRA potentially trained on Robust04"
    },
    {
      "source": "ELECTRA",
      "target": "TREC Deep Learning Track",
      "keywords": "trained_on",
      "description": "ELECTRA potentially trained on TREC Deep Learning Track"
    },
    {
      "source": "T5",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "T5 potentially trained on MS MARCO"
    },
    {
      "source": "T5",
      "target": "Robust04",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Robust04"
    },
    {
      "source": "T5",
      "target": "TREC Deep Learning Track",
      "keywords": "trained_on",
      "description": "T5 potentially trained on TREC Deep Learning Track"
    },
    {
      "source": "GPT",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "GPT potentially trained on MS MARCO"
    },
    {
      "source": "GPT",
      "target": "Robust04",
      "keywords": "trained_on",
      "description": "GPT potentially trained on Robust04"
    },
    {
      "source": "GPT",
      "target": "TREC Deep Learning Track",
      "keywords": "trained_on",
      "description": "GPT potentially trained on TREC Deep Learning Track"
    },
    {
      "source": "BART",
      "target": "MS MARCO",
      "keywords": "trained_on",
      "description": "BART potentially trained on MS MARCO"
    },
    {
      "source": "BART",
      "target": "Robust04",
      "keywords": "trained_on",
      "description": "BART potentially trained on Robust04"
    },
    {
      "source": "BART",
      "target": "TREC Deep Learning Track",
      "keywords": "trained_on",
      "description": "BART potentially trained on TREC Deep Learning Track"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ad hoc retrieval",
      "keywords": "supports",
      "description": "PipelineRAG supports ad hoc retrieval"
    },
    {
      "source": "PipelineRAG",
      "target": "passage retrieval",
      "keywords": "supports",
      "description": "PipelineRAG supports passage retrieval"
    },
    {
      "source": "PipelineRAG",
      "target": "document ranking",
      "keywords": "supports",
      "description": "PipelineRAG supports document ranking"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ad hoc retrieval",
      "keywords": "supports",
      "description": "HybridRetrieval supports ad hoc retrieval"
    },
    {
      "source": "HybridRetrieval",
      "target": "passage retrieval",
      "keywords": "supports",
      "description": "HybridRetrieval supports passage retrieval"
    },
    {
      "source": "HybridRetrieval",
      "target": "document ranking",
      "keywords": "supports",
      "description": "HybridRetrieval supports document ranking"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "ad hoc retrieval",
      "keywords": "supports",
      "description": "HybridGeneration supports ad hoc retrieval"
    },
    {
      "source": "HybridGeneration",
      "target": "passage retrieval",
      "keywords": "supports",
      "description": "HybridGeneration supports passage retrieval"
    },
    {
      "source": "HybridGeneration",
      "target": "document ranking",
      "keywords": "supports",
      "description": "HybridGeneration supports document ranking"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "FinetuningStrategy supports DocumentSummarization"
    },
    {
      "source": "FinetuningStrategy",
      "target": "ad hoc retrieval",
      "keywords": "supports",
      "description": "FinetuningStrategy supports ad hoc retrieval"
    },
    {
      "source": "FinetuningStrategy",
      "target": "passage retrieval",
      "keywords": "supports",
      "description": "FinetuningStrategy supports passage retrieval"
    },
    {
      "source": "FinetuningStrategy",
      "target": "document ranking",
      "keywords": "supports",
      "description": "FinetuningStrategy supports document ranking"
    },
    {
      "source": "Angels Balaguer",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Angels Balaguer authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Vinamra Benara",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Vinamra Benara authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Renato Cunha",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Renato Cunha authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Roberto Estevão",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Roberto Estevão authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Todd Hendry",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Todd Hendry authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Daniel Holstein",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Daniel Holstein authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Jennifer Marsman",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Jennifer Marsman authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Nick Mecklenburg",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Nick Mecklenburg authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Sara Malvar",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Sara Malvar authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Leonardo O. Nunes",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Leonardo O. Nunes authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Rafael Padilha",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Rafael Padilha authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Morris Sharp",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Morris Sharp authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Bruno Silva",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Bruno Silva authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Swati Sharma",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Swati Sharma authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Vijay Aski",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Vijay Aski authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Ranveer Chandra",
      "target": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "keywords": "authorship",
      "description": "Ranveer Chandra authored RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE"
    },
    {
      "source": "Angels Balaguer",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Angels Balaguer affiliated with Microsoft"
    },
    {
      "source": "Vinamra Benara",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Vinamra Benara affiliated with Microsoft"
    },
    {
      "source": "Renato Cunha",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Renato Cunha affiliated with Microsoft"
    },
    {
      "source": "Roberto Estevão",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Roberto Estevão affiliated with Microsoft"
    },
    {
      "source": "Todd Hendry",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Todd Hendry affiliated with Microsoft"
    },
    {
      "source": "Daniel Holstein",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Daniel Holstein affiliated with Microsoft"
    },
    {
      "source": "Jennifer Marsman",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Jennifer Marsman affiliated with Microsoft"
    },
    {
      "source": "Nick Mecklenburg",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Nick Mecklenburg affiliated with Microsoft"
    },
    {
      "source": "Sara Malvar",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Sara Malvar affiliated with Microsoft"
    },
    {
      "source": "Leonardo O. Nunes",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Leonardo O. Nunes affiliated with Microsoft"
    },
    {
      "source": "Rafael Padilha",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Rafael Padilha affiliated with Microsoft"
    },
    {
      "source": "Morris Sharp",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Morris Sharp affiliated with Microsoft"
    },
    {
      "source": "Bruno Silva",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Bruno Silva affiliated with Microsoft"
    },
    {
      "source": "Swati Sharma",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Swati Sharma affiliated with Microsoft"
    },
    {
      "source": "Vijay Aski",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Vijay Aski affiliated with Microsoft"
    },
    {
      "source": "Ranveer Chandra",
      "target": "Microsoft",
      "keywords": "affiliation",
      "description": "Ranveer Chandra affiliated with Microsoft"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "sentence transformers",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses sentence transformers"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses GPT-4"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "GPT-3.5",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses GPT-3.5"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "Llama2-13B",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses Llama2-13B"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "Llama2-13B-chat",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses Llama2-13B-chat"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "Vicuna-13B-v1.5-16k",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses Vicuna-13B-v1.5-16k"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "USA Agriculture Dataset",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses USA Agriculture Dataset"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "Washington State Dataset",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses Washington State Dataset"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "Brazil Embrapa Dataset",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses Brazil Embrapa Dataset"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "India KVK Dataset",
      "keywords": "uses",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE uses India KVK Dataset"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE proposes PipelineRAG"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE proposes DenseRetrieval"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE proposes AbstractiveGeneration"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE proposes SeparateTraining"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "QA",
      "keywords": "applies_to",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE applies to QA"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE applies to DocumentSummarization"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE applies to MedicalRAG"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE applies to LegalRAG"
    },
    {
      "source": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "RAG VS FINE-TUNING: PIPELINES, TRADEOFFS, AND A CASE STUDY ON AGRICULTURE applies to EducationalRAG"
    },
    {
      "source": "sentence transformers",
      "target": "USA Agriculture Dataset",
      "keywords": "trained_on",
      "description": "sentence transformers potentially trained on USA Agriculture Dataset"
    },
    {
      "source": "sentence transformers",
      "target": "Washington State Dataset",
      "keywords": "trained_on",
      "description": "sentence transformers potentially trained on Washington State Dataset"
    },
    {
      "source": "sentence transformers",
      "target": "Brazil Embrapa Dataset",
      "keywords": "trained_on",
      "description": "sentence transformers potentially trained on Brazil Embrapa Dataset"
    },
    {
      "source": "sentence transformers",
      "target": "India KVK Dataset",
      "keywords": "trained_on",
      "description": "sentence transformers potentially trained on India KVK Dataset"
    },
    {
      "source": "GPT-4",
      "target": "USA Agriculture Dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on USA Agriculture Dataset"
    },
    {
      "source": "GPT-4",
      "target": "Washington State Dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Washington State Dataset"
    },
    {
      "source": "GPT-4",
      "target": "Brazil Embrapa Dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Brazil Embrapa Dataset"
    },
    {
      "source": "GPT-4",
      "target": "India KVK Dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on India KVK Dataset"
    },
    {
      "source": "GPT-3.5",
      "target": "USA Agriculture Dataset",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on USA Agriculture Dataset"
    },
    {
      "source": "GPT-3.5",
      "target": "Washington State Dataset",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on Washington State Dataset"
    },
    {
      "source": "GPT-3.5",
      "target": "Brazil Embrapa Dataset",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on Brazil Embrapa Dataset"
    },
    {
      "source": "GPT-3.5",
      "target": "India KVK Dataset",
      "keywords": "trained_on",
      "description": "GPT-3.5 potentially trained on India KVK Dataset"
    },
    {
      "source": "Llama2-13B",
      "target": "USA Agriculture Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B potentially trained on USA Agriculture Dataset"
    },
    {
      "source": "Llama2-13B",
      "target": "Washington State Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B potentially trained on Washington State Dataset"
    },
    {
      "source": "Llama2-13B",
      "target": "Brazil Embrapa Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B potentially trained on Brazil Embrapa Dataset"
    },
    {
      "source": "Llama2-13B",
      "target": "India KVK Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B potentially trained on India KVK Dataset"
    },
    {
      "source": "Llama2-13B-chat",
      "target": "USA Agriculture Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B-chat potentially trained on USA Agriculture Dataset"
    },
    {
      "source": "Llama2-13B-chat",
      "target": "Washington State Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B-chat potentially trained on Washington State Dataset"
    },
    {
      "source": "Llama2-13B-chat",
      "target": "Brazil Embrapa Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B-chat potentially trained on Brazil Embrapa Dataset"
    },
    {
      "source": "Llama2-13B-chat",
      "target": "India KVK Dataset",
      "keywords": "trained_on",
      "description": "Llama2-13B-chat potentially trained on India KVK Dataset"
    },
    {
      "source": "Vicuna-13B-v1.5-16k",
      "target": "USA Agriculture Dataset",
      "keywords": "trained_on",
      "description": "Vicuna-13B-v1.5-16k potentially trained on USA Agriculture Dataset"
    },
    {
      "source": "Vicuna-13B-v1.5-16k",
      "target": "Washington State Dataset",
      "keywords": "trained_on",
      "description": "Vicuna-13B-v1.5-16k potentially trained on Washington State Dataset"
    },
    {
      "source": "Vicuna-13B-v1.5-16k",
      "target": "Brazil Embrapa Dataset",
      "keywords": "trained_on",
      "description": "Vicuna-13B-v1.5-16k potentially trained on Brazil Embrapa Dataset"
    },
    {
      "source": "Vicuna-13B-v1.5-16k",
      "target": "India KVK Dataset",
      "keywords": "trained_on",
      "description": "Vicuna-13B-v1.5-16k potentially trained on India KVK Dataset"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Kunal Sawarkar",
      "target": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "keywords": "authorship",
      "description": "Kunal Sawarkar authored Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "source": "Abhilasha Mangal",
      "target": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "keywords": "authorship",
      "description": "Abhilasha Mangal authored Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "source": "Shivam Raj Solanki",
      "target": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "keywords": "authorship",
      "description": "Shivam Raj Solanki authored Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers"
    },
    {
      "source": "Kunal Sawarkar",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Kunal Sawarkar affiliated with IBM"
    },
    {
      "source": "Kunal Sawarkar",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Kunal Sawarkar affiliated with IBM"
    },
    {
      "source": "Kunal Sawarkar",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Kunal Sawarkar affiliated with IBM"
    },
    {
      "source": "Abhilasha Mangal",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Abhilasha Mangal affiliated with IBM"
    },
    {
      "source": "Abhilasha Mangal",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Abhilasha Mangal affiliated with IBM"
    },
    {
      "source": "Abhilasha Mangal",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Abhilasha Mangal affiliated with IBM"
    },
    {
      "source": "Shivam Raj Solanki",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Shivam Raj Solanki affiliated with IBM"
    },
    {
      "source": "Shivam Raj Solanki",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Shivam Raj Solanki affiliated with IBM"
    },
    {
      "source": "Shivam Raj Solanki",
      "target": "IBM",
      "keywords": "affiliation",
      "description": "Shivam Raj Solanki affiliated with IBM"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "BM25",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses BM25"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Sentence Transformers",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses Sentence Transformers"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Elastic Learned Sparse Encoder (ELSER)",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses Elastic Learned Sparse Encoder (ELSER)"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Large Language Models (LLM)",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses Large Language Models (LLM)"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Natural Questions (NQ)",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses Natural Questions (NQ)"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "TREC-COVID",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses TREC-COVID"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Stanford Question Answering Dataset (SQuAD)",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses Stanford Question Answering Dataset (SQuAD)"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "HotPotQA",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses HotPotQA"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "CoQA",
      "keywords": "uses",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers uses CoQA"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers proposes PipelineRAG"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers proposes HybridRetrieval"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers proposes AbstractiveGeneration"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers proposes SeparateTraining"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers applies to QA"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers applies to DocumentSummarization"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Enterprise datasets",
      "keywords": "applies_to",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers applies to Enterprise datasets"
    },
    {
      "source": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
      "target": "Large-scale information retrieval",
      "keywords": "applies_to",
      "description": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers applies to Large-scale information retrieval"
    },
    {
      "source": "BM25",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "BM25",
      "target": "TREC-COVID",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on TREC-COVID"
    },
    {
      "source": "BM25",
      "target": "Stanford Question Answering Dataset (SQuAD)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Stanford Question Answering Dataset (SQuAD)"
    },
    {
      "source": "BM25",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on HotPotQA"
    },
    {
      "source": "BM25",
      "target": "CoQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on CoQA"
    },
    {
      "source": "Sentence Transformers",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Sentence Transformers potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Sentence Transformers",
      "target": "TREC-COVID",
      "keywords": "trained_on",
      "description": "Sentence Transformers potentially trained on TREC-COVID"
    },
    {
      "source": "Sentence Transformers",
      "target": "Stanford Question Answering Dataset (SQuAD)",
      "keywords": "trained_on",
      "description": "Sentence Transformers potentially trained on Stanford Question Answering Dataset (SQuAD)"
    },
    {
      "source": "Sentence Transformers",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "Sentence Transformers potentially trained on HotPotQA"
    },
    {
      "source": "Sentence Transformers",
      "target": "CoQA",
      "keywords": "trained_on",
      "description": "Sentence Transformers potentially trained on CoQA"
    },
    {
      "source": "Elastic Learned Sparse Encoder (ELSER)",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Elastic Learned Sparse Encoder (ELSER) potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Elastic Learned Sparse Encoder (ELSER)",
      "target": "TREC-COVID",
      "keywords": "trained_on",
      "description": "Elastic Learned Sparse Encoder (ELSER) potentially trained on TREC-COVID"
    },
    {
      "source": "Elastic Learned Sparse Encoder (ELSER)",
      "target": "Stanford Question Answering Dataset (SQuAD)",
      "keywords": "trained_on",
      "description": "Elastic Learned Sparse Encoder (ELSER) potentially trained on Stanford Question Answering Dataset (SQuAD)"
    },
    {
      "source": "Elastic Learned Sparse Encoder (ELSER)",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "Elastic Learned Sparse Encoder (ELSER) potentially trained on HotPotQA"
    },
    {
      "source": "Elastic Learned Sparse Encoder (ELSER)",
      "target": "CoQA",
      "keywords": "trained_on",
      "description": "Elastic Learned Sparse Encoder (ELSER) potentially trained on CoQA"
    },
    {
      "source": "Large Language Models (LLM)",
      "target": "Natural Questions (NQ)",
      "keywords": "trained_on",
      "description": "Large Language Models (LLM) potentially trained on Natural Questions (NQ)"
    },
    {
      "source": "Large Language Models (LLM)",
      "target": "TREC-COVID",
      "keywords": "trained_on",
      "description": "Large Language Models (LLM) potentially trained on TREC-COVID"
    },
    {
      "source": "Large Language Models (LLM)",
      "target": "Stanford Question Answering Dataset (SQuAD)",
      "keywords": "trained_on",
      "description": "Large Language Models (LLM) potentially trained on Stanford Question Answering Dataset (SQuAD)"
    },
    {
      "source": "Large Language Models (LLM)",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "Large Language Models (LLM) potentially trained on HotPotQA"
    },
    {
      "source": "Large Language Models (LLM)",
      "target": "CoQA",
      "keywords": "trained_on",
      "description": "Large Language Models (LLM) potentially trained on CoQA"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Wenqi Fan",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Wenqi Fan authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Yujuan Ding",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Yujuan Ding authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Liangbo Ning",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Liangbo Ning authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Shijie Wang",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Shijie Wang authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Hengyun Li",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Hengyun Li authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Dawei Yin",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Dawei Yin authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Tat-Seng Chua",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Tat-Seng Chua authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Qing Li",
      "target": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "keywords": "authorship",
      "description": "Qing Li authored A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models"
    },
    {
      "source": "Wenqi Fan",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Wenqi Fan affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Wenqi Fan",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Wenqi Fan affiliated with Baidu Inc"
    },
    {
      "source": "Wenqi Fan",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Wenqi Fan affiliated with National University of Singapore"
    },
    {
      "source": "Yujuan Ding",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Yujuan Ding affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Yujuan Ding",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Yujuan Ding affiliated with Baidu Inc"
    },
    {
      "source": "Yujuan Ding",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Yujuan Ding affiliated with National University of Singapore"
    },
    {
      "source": "Liangbo Ning",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Liangbo Ning affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Liangbo Ning",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Liangbo Ning affiliated with Baidu Inc"
    },
    {
      "source": "Liangbo Ning",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Liangbo Ning affiliated with National University of Singapore"
    },
    {
      "source": "Shijie Wang",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Shijie Wang affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Shijie Wang",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Shijie Wang affiliated with Baidu Inc"
    },
    {
      "source": "Shijie Wang",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Shijie Wang affiliated with National University of Singapore"
    },
    {
      "source": "Hengyun Li",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Hengyun Li affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Hengyun Li",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Hengyun Li affiliated with Baidu Inc"
    },
    {
      "source": "Hengyun Li",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Hengyun Li affiliated with National University of Singapore"
    },
    {
      "source": "Dawei Yin",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Dawei Yin affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Dawei Yin",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Dawei Yin affiliated with Baidu Inc"
    },
    {
      "source": "Dawei Yin",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Dawei Yin affiliated with National University of Singapore"
    },
    {
      "source": "Tat-Seng Chua",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Tat-Seng Chua affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Tat-Seng Chua",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Tat-Seng Chua affiliated with Baidu Inc"
    },
    {
      "source": "Tat-Seng Chua",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Tat-Seng Chua affiliated with National University of Singapore"
    },
    {
      "source": "Qing Li",
      "target": "The Hong Kong Polytechnic University",
      "keywords": "affiliation",
      "description": "Qing Li affiliated with The Hong Kong Polytechnic University"
    },
    {
      "source": "Qing Li",
      "target": "Baidu Inc",
      "keywords": "affiliation",
      "description": "Qing Li affiliated with Baidu Inc"
    },
    {
      "source": "Qing Li",
      "target": "National University of Singapore",
      "keywords": "affiliation",
      "description": "Qing Li affiliated with National University of Singapore"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "DPR (Dense Passage Retriever)",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses DPR (Dense Passage Retriever)"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Contriever",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses Contriever"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "BM25",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses BM25"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "GPT series",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses GPT series"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "T5",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses T5"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "BART",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses BART"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses Natural Questions"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses MS-MARCO"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "BEIR",
      "keywords": "uses",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models uses BEIR"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models proposes PipelineRAG"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models proposes HybridRetrieval"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models proposes HybridGeneration"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models proposes JointTraining"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "QA",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to QA"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to DocumentSummarization"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to ConversationalAI"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Code Generation",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to Code Generation"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Machine Translation",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to Machine Translation"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to MedicalRAG"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to LegalRAG"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to EducationalRAG"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Financial Analysis",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to Financial Analysis"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Scientific Literature Review",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to Scientific Literature Review"
    },
    {
      "source": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models",
      "target": "Molecular Discovery",
      "keywords": "applies_to",
      "description": "A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models applies to Molecular Discovery"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on Natural Questions"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on MS-MARCO"
    },
    {
      "source": "DPR (Dense Passage Retriever)",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "DPR (Dense Passage Retriever) potentially trained on BEIR"
    },
    {
      "source": "Contriever",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on Natural Questions"
    },
    {
      "source": "Contriever",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on MS-MARCO"
    },
    {
      "source": "Contriever",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on BEIR"
    },
    {
      "source": "BM25",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on Natural Questions"
    },
    {
      "source": "BM25",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on MS-MARCO"
    },
    {
      "source": "BM25",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on BEIR"
    },
    {
      "source": "GPT series",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT series potentially trained on Natural Questions"
    },
    {
      "source": "GPT series",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "GPT series potentially trained on MS-MARCO"
    },
    {
      "source": "GPT series",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "GPT series potentially trained on BEIR"
    },
    {
      "source": "T5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions"
    },
    {
      "source": "T5",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "T5 potentially trained on MS-MARCO"
    },
    {
      "source": "T5",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "T5 potentially trained on BEIR"
    },
    {
      "source": "BART",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BART potentially trained on Natural Questions"
    },
    {
      "source": "BART",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BART potentially trained on MS-MARCO"
    },
    {
      "source": "BART",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BART potentially trained on BEIR"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentSummarization"
    },
    {
      "source": "PipelineRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "PipelineRAG supports ConversationalAI"
    },
    {
      "source": "PipelineRAG",
      "target": "Code Generation",
      "keywords": "supports",
      "description": "PipelineRAG supports Code Generation"
    },
    {
      "source": "PipelineRAG",
      "target": "Machine Translation",
      "keywords": "supports",
      "description": "PipelineRAG supports Machine Translation"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "Code Generation",
      "keywords": "supports",
      "description": "HybridRetrieval supports Code Generation"
    },
    {
      "source": "HybridRetrieval",
      "target": "Machine Translation",
      "keywords": "supports",
      "description": "HybridRetrieval supports Machine Translation"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridGeneration supports ConversationalAI"
    },
    {
      "source": "HybridGeneration",
      "target": "Code Generation",
      "keywords": "supports",
      "description": "HybridGeneration supports Code Generation"
    },
    {
      "source": "HybridGeneration",
      "target": "Machine Translation",
      "keywords": "supports",
      "description": "HybridGeneration supports Machine Translation"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "Code Generation",
      "keywords": "supports",
      "description": "JointTraining supports Code Generation"
    },
    {
      "source": "JointTraining",
      "target": "Machine Translation",
      "keywords": "supports",
      "description": "JointTraining supports Machine Translation"
    },
    {
      "source": "Heydar Soudani",
      "target": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "keywords": "authorship",
      "description": "Heydar Soudani authored Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "source": "Evangelos Kanoulas",
      "target": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "keywords": "authorship",
      "description": "Evangelos Kanoulas authored Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "source": "Faegheh Hasibi",
      "target": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "keywords": "authorship",
      "description": "Faegheh Hasibi authored Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge"
    },
    {
      "source": "Heydar Soudani",
      "target": "Radboud University",
      "keywords": "affiliation",
      "description": "Heydar Soudani affiliated with Radboud University"
    },
    {
      "source": "Heydar Soudani",
      "target": "University of Amsterdam",
      "keywords": "affiliation",
      "description": "Heydar Soudani affiliated with University of Amsterdam"
    },
    {
      "source": "Heydar Soudani",
      "target": "Radboud University",
      "keywords": "affiliation",
      "description": "Heydar Soudani affiliated with Radboud University"
    },
    {
      "source": "Evangelos Kanoulas",
      "target": "Radboud University",
      "keywords": "affiliation",
      "description": "Evangelos Kanoulas affiliated with Radboud University"
    },
    {
      "source": "Evangelos Kanoulas",
      "target": "University of Amsterdam",
      "keywords": "affiliation",
      "description": "Evangelos Kanoulas affiliated with University of Amsterdam"
    },
    {
      "source": "Evangelos Kanoulas",
      "target": "Radboud University",
      "keywords": "affiliation",
      "description": "Evangelos Kanoulas affiliated with Radboud University"
    },
    {
      "source": "Faegheh Hasibi",
      "target": "Radboud University",
      "keywords": "affiliation",
      "description": "Faegheh Hasibi affiliated with Radboud University"
    },
    {
      "source": "Faegheh Hasibi",
      "target": "University of Amsterdam",
      "keywords": "affiliation",
      "description": "Faegheh Hasibi affiliated with University of Amsterdam"
    },
    {
      "source": "Faegheh Hasibi",
      "target": "Radboud University",
      "keywords": "affiliation",
      "description": "Faegheh Hasibi affiliated with Radboud University"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "BM25",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses BM25"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "DPR",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses DPR"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Contriever",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses Contriever"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "FlanT5",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses FlanT5"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "TinyLlama",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses TinyLlama"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "StableLM2",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses StableLM2"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "MiniCPM",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses MiniCPM"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Mistral",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses Mistral"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Zephyr",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses Zephyr"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Llama2-chat",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses Llama2-chat"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Llama3-chat",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses Llama3-chat"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "PopQA",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses PopQA"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "WitQA",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses WitQA"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "EntityQuestion (EQ)",
      "keywords": "uses",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge uses EntityQuestion (EQ)"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge proposes PipelineRAG"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge proposes HybridRetrieval"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge proposes AbstractiveGeneration"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "FinetuningStrategy",
      "keywords": "proposes",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge proposes FinetuningStrategy"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge applies to QA"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Less-resourced domains",
      "keywords": "applies_to",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge applies to Less-resourced domains"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Industrial chatbots",
      "keywords": "applies_to",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge applies to Industrial chatbots"
    },
    {
      "source": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge",
      "target": "Company-specific knowledge systems",
      "keywords": "applies_to",
      "description": "Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge applies to Company-specific knowledge systems"
    },
    {
      "source": "BM25",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on PopQA"
    },
    {
      "source": "BM25",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on WitQA"
    },
    {
      "source": "BM25",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "BM25 potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "DPR",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "DPR potentially trained on PopQA"
    },
    {
      "source": "DPR",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "DPR potentially trained on WitQA"
    },
    {
      "source": "DPR",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "DPR potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "Contriever",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on PopQA"
    },
    {
      "source": "Contriever",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on WitQA"
    },
    {
      "source": "Contriever",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "Contriever potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "FlanT5",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "FlanT5 potentially trained on PopQA"
    },
    {
      "source": "FlanT5",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "FlanT5 potentially trained on WitQA"
    },
    {
      "source": "FlanT5",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "FlanT5 potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "TinyLlama",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "TinyLlama potentially trained on PopQA"
    },
    {
      "source": "TinyLlama",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "TinyLlama potentially trained on WitQA"
    },
    {
      "source": "TinyLlama",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "TinyLlama potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "StableLM2",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "StableLM2 potentially trained on PopQA"
    },
    {
      "source": "StableLM2",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "StableLM2 potentially trained on WitQA"
    },
    {
      "source": "StableLM2",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "StableLM2 potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "MiniCPM",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "MiniCPM potentially trained on PopQA"
    },
    {
      "source": "MiniCPM",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "MiniCPM potentially trained on WitQA"
    },
    {
      "source": "MiniCPM",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "MiniCPM potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "Mistral",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Mistral potentially trained on PopQA"
    },
    {
      "source": "Mistral",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "Mistral potentially trained on WitQA"
    },
    {
      "source": "Mistral",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "Mistral potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "Zephyr",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Zephyr potentially trained on PopQA"
    },
    {
      "source": "Zephyr",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "Zephyr potentially trained on WitQA"
    },
    {
      "source": "Zephyr",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "Zephyr potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "Llama2-chat",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Llama2-chat potentially trained on PopQA"
    },
    {
      "source": "Llama2-chat",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "Llama2-chat potentially trained on WitQA"
    },
    {
      "source": "Llama2-chat",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "Llama2-chat potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "Llama3-chat",
      "target": "PopQA",
      "keywords": "trained_on",
      "description": "Llama3-chat potentially trained on PopQA"
    },
    {
      "source": "Llama3-chat",
      "target": "WitQA",
      "keywords": "trained_on",
      "description": "Llama3-chat potentially trained on WitQA"
    },
    {
      "source": "Llama3-chat",
      "target": "EntityQuestion (EQ)",
      "keywords": "trained_on",
      "description": "Llama3-chat potentially trained on EntityQuestion (EQ)"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "FinetuningStrategy",
      "target": "QA",
      "keywords": "supports",
      "description": "FinetuningStrategy supports QA"
    },
    {
      "source": "Jianjie Luo",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Jianjie Luo authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Yehao Li",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Yehao Li authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Yingwei Pan",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Yingwei Pan authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Ting Yao",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Ting Yao authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Jianlin Feng",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Jianlin Feng authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Hongyang Chao",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Hongyang Chao authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Tao Mei",
      "target": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "keywords": "authorship",
      "description": "Tao Mei authored Semantic-Conditional Diffusion Networks for Image Captioning"
    },
    {
      "source": "Jianjie Luo",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Jianjie Luo affiliated with Sun Yat-sen University"
    },
    {
      "source": "Jianjie Luo",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Jianjie Luo affiliated with JD Explore Academy"
    },
    {
      "source": "Yehao Li",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Yehao Li affiliated with Sun Yat-sen University"
    },
    {
      "source": "Yehao Li",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Yehao Li affiliated with JD Explore Academy"
    },
    {
      "source": "Yingwei Pan",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Yingwei Pan affiliated with Sun Yat-sen University"
    },
    {
      "source": "Yingwei Pan",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Yingwei Pan affiliated with JD Explore Academy"
    },
    {
      "source": "Ting Yao",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Ting Yao affiliated with Sun Yat-sen University"
    },
    {
      "source": "Ting Yao",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Ting Yao affiliated with JD Explore Academy"
    },
    {
      "source": "Jianlin Feng",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Jianlin Feng affiliated with Sun Yat-sen University"
    },
    {
      "source": "Jianlin Feng",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Jianlin Feng affiliated with JD Explore Academy"
    },
    {
      "source": "Hongyang Chao",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Hongyang Chao affiliated with Sun Yat-sen University"
    },
    {
      "source": "Hongyang Chao",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Hongyang Chao affiliated with JD Explore Academy"
    },
    {
      "source": "Tao Mei",
      "target": "Sun Yat-sen University",
      "keywords": "affiliation",
      "description": "Tao Mei affiliated with Sun Yat-sen University"
    },
    {
      "source": "Tao Mei",
      "target": "JD Explore Academy",
      "keywords": "affiliation",
      "description": "Tao Mei affiliated with JD Explore Academy"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Cross-modal retrieval model",
      "keywords": "uses",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning uses Cross-modal retrieval model"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Diffusion Transformer",
      "keywords": "uses",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning uses Diffusion Transformer"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Autoregressive Transformer teacher model",
      "keywords": "uses",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning uses Autoregressive Transformer teacher model"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "COCO",
      "keywords": "uses",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning uses COCO"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Karpathy split",
      "keywords": "uses",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning uses Karpathy split"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning proposes PipelineRAG"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning proposes DenseRetrieval"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning proposes AbstractiveGeneration"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning proposes JointTraining"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Image Captioning",
      "keywords": "applies_to",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning applies to Image Captioning"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Computer Vision",
      "keywords": "applies_to",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning applies to Computer Vision"
    },
    {
      "source": "Semantic-Conditional Diffusion Networks for Image Captioning",
      "target": "Visual-Language Understanding",
      "keywords": "applies_to",
      "description": "Semantic-Conditional Diffusion Networks for Image Captioning applies to Visual-Language Understanding"
    },
    {
      "source": "Cross-modal retrieval model",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "Cross-modal retrieval model potentially trained on COCO"
    },
    {
      "source": "Cross-modal retrieval model",
      "target": "Karpathy split",
      "keywords": "trained_on",
      "description": "Cross-modal retrieval model potentially trained on Karpathy split"
    },
    {
      "source": "Diffusion Transformer",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "Diffusion Transformer potentially trained on COCO"
    },
    {
      "source": "Diffusion Transformer",
      "target": "Karpathy split",
      "keywords": "trained_on",
      "description": "Diffusion Transformer potentially trained on Karpathy split"
    },
    {
      "source": "Autoregressive Transformer teacher model",
      "target": "COCO",
      "keywords": "trained_on",
      "description": "Autoregressive Transformer teacher model potentially trained on COCO"
    },
    {
      "source": "Autoregressive Transformer teacher model",
      "target": "Karpathy split",
      "keywords": "trained_on",
      "description": "Autoregressive Transformer teacher model potentially trained on Karpathy split"
    },
    {
      "source": "PipelineRAG",
      "target": "Image Captioning",
      "keywords": "supports",
      "description": "PipelineRAG supports Image Captioning"
    },
    {
      "source": "DenseRetrieval",
      "target": "Image Captioning",
      "keywords": "supports",
      "description": "DenseRetrieval supports Image Captioning"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "Image Captioning",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports Image Captioning"
    },
    {
      "source": "JointTraining",
      "target": "Image Captioning",
      "keywords": "supports",
      "description": "JointTraining supports Image Captioning"
    },
    {
      "source": "Donald Metzler",
      "target": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "keywords": "authorship",
      "description": "Donald Metzler authored Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "source": "Yi Tay",
      "target": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "keywords": "authorship",
      "description": "Yi Tay authored Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "source": "Dara Bahri",
      "target": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "keywords": "authorship",
      "description": "Dara Bahri authored Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "source": "Marc Najork",
      "target": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "keywords": "authorship",
      "description": "Marc Najork authored Rethinking Search: Making Domain Experts out of Dilettantes"
    },
    {
      "source": "Donald Metzler",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Donald Metzler affiliated with Google Research"
    },
    {
      "source": "Yi Tay",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Yi Tay affiliated with Google Research"
    },
    {
      "source": "Dara Bahri",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Dara Bahri affiliated with Google Research"
    },
    {
      "source": "Marc Najork",
      "target": "Google Research",
      "keywords": "affiliation",
      "description": "Marc Najork affiliated with Google Research"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "Dense vector-based indexes",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses Dense vector-based indexes"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "BERT",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses BERT"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "GPT-2",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses GPT-2"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "GPT-3",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses GPT-3"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "T5",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses T5"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "BART",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses BART"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "Web corpus",
      "keywords": "uses",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes uses Web corpus"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "End2EndRAG",
      "keywords": "proposes",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes proposes End2EndRAG"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes proposes HybridRetrieval"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes proposes AbstractiveGeneration"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes proposes JointTraining"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes applies to QA"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes applies to DocumentSummarization"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes applies to ConversationalAI"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes applies to MedicalRAG"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes applies to LegalRAG"
    },
    {
      "source": "Rethinking Search: Making Domain Experts out of Dilettantes",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Rethinking Search: Making Domain Experts out of Dilettantes applies to EducationalRAG"
    },
    {
      "source": "Dense vector-based indexes",
      "target": "Web corpus",
      "keywords": "trained_on",
      "description": "Dense vector-based indexes potentially trained on Web corpus"
    },
    {
      "source": "BERT",
      "target": "Web corpus",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Web corpus"
    },
    {
      "source": "GPT-2",
      "target": "Web corpus",
      "keywords": "trained_on",
      "description": "GPT-2 potentially trained on Web corpus"
    },
    {
      "source": "GPT-3",
      "target": "Web corpus",
      "keywords": "trained_on",
      "description": "GPT-3 potentially trained on Web corpus"
    },
    {
      "source": "T5",
      "target": "Web corpus",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Web corpus"
    },
    {
      "source": "BART",
      "target": "Web corpus",
      "keywords": "trained_on",
      "description": "BART potentially trained on Web corpus"
    },
    {
      "source": "End2EndRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "End2EndRAG supports QA"
    },
    {
      "source": "End2EndRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "End2EndRAG supports DocumentSummarization"
    },
    {
      "source": "End2EndRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "End2EndRAG supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "Boci Peng",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Boci Peng authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Yun Zhu",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Yun Zhu authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Yongchao Liu",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Yongchao Liu authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Xiaohe Bo",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Xiaohe Bo authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Haizhou Shi",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Haizhou Shi authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Chuntao Hong",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Chuntao Hong authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Yan Zhang",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Yan Zhang authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Siliang Tang",
      "target": "Graph Retrieval-Augmented Generation: A Survey",
      "keywords": "authorship",
      "description": "Siliang Tang authored Graph Retrieval-Augmented Generation: A Survey"
    },
    {
      "source": "Boci Peng",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Boci Peng affiliated with Peking University"
    },
    {
      "source": "Boci Peng",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Boci Peng affiliated with Zhejiang University"
    },
    {
      "source": "Boci Peng",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Boci Peng affiliated with Ant Group"
    },
    {
      "source": "Boci Peng",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Boci Peng affiliated with Renmin University of China"
    },
    {
      "source": "Boci Peng",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Boci Peng affiliated with Rutgers University"
    },
    {
      "source": "Yun Zhu",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with Peking University"
    },
    {
      "source": "Yun Zhu",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with Zhejiang University"
    },
    {
      "source": "Yun Zhu",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with Ant Group"
    },
    {
      "source": "Yun Zhu",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with Renmin University of China"
    },
    {
      "source": "Yun Zhu",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Yun Zhu affiliated with Rutgers University"
    },
    {
      "source": "Yongchao Liu",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Yongchao Liu affiliated with Peking University"
    },
    {
      "source": "Yongchao Liu",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Yongchao Liu affiliated with Zhejiang University"
    },
    {
      "source": "Yongchao Liu",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Yongchao Liu affiliated with Ant Group"
    },
    {
      "source": "Yongchao Liu",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Yongchao Liu affiliated with Renmin University of China"
    },
    {
      "source": "Yongchao Liu",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Yongchao Liu affiliated with Rutgers University"
    },
    {
      "source": "Xiaohe Bo",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Xiaohe Bo affiliated with Peking University"
    },
    {
      "source": "Xiaohe Bo",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Xiaohe Bo affiliated with Zhejiang University"
    },
    {
      "source": "Xiaohe Bo",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Xiaohe Bo affiliated with Ant Group"
    },
    {
      "source": "Xiaohe Bo",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Xiaohe Bo affiliated with Renmin University of China"
    },
    {
      "source": "Xiaohe Bo",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Xiaohe Bo affiliated with Rutgers University"
    },
    {
      "source": "Haizhou Shi",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Haizhou Shi affiliated with Peking University"
    },
    {
      "source": "Haizhou Shi",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Haizhou Shi affiliated with Zhejiang University"
    },
    {
      "source": "Haizhou Shi",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Haizhou Shi affiliated with Ant Group"
    },
    {
      "source": "Haizhou Shi",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Haizhou Shi affiliated with Renmin University of China"
    },
    {
      "source": "Haizhou Shi",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Haizhou Shi affiliated with Rutgers University"
    },
    {
      "source": "Chuntao Hong",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Chuntao Hong affiliated with Peking University"
    },
    {
      "source": "Chuntao Hong",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Chuntao Hong affiliated with Zhejiang University"
    },
    {
      "source": "Chuntao Hong",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Chuntao Hong affiliated with Ant Group"
    },
    {
      "source": "Chuntao Hong",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Chuntao Hong affiliated with Renmin University of China"
    },
    {
      "source": "Chuntao Hong",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Chuntao Hong affiliated with Rutgers University"
    },
    {
      "source": "Yan Zhang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Yan Zhang affiliated with Peking University"
    },
    {
      "source": "Yan Zhang",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Yan Zhang affiliated with Zhejiang University"
    },
    {
      "source": "Yan Zhang",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Yan Zhang affiliated with Ant Group"
    },
    {
      "source": "Yan Zhang",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Yan Zhang affiliated with Renmin University of China"
    },
    {
      "source": "Yan Zhang",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Yan Zhang affiliated with Rutgers University"
    },
    {
      "source": "Siliang Tang",
      "target": "Peking University",
      "keywords": "affiliation",
      "description": "Siliang Tang affiliated with Peking University"
    },
    {
      "source": "Siliang Tang",
      "target": "Zhejiang University",
      "keywords": "affiliation",
      "description": "Siliang Tang affiliated with Zhejiang University"
    },
    {
      "source": "Siliang Tang",
      "target": "Ant Group",
      "keywords": "affiliation",
      "description": "Siliang Tang affiliated with Ant Group"
    },
    {
      "source": "Siliang Tang",
      "target": "Renmin University of China",
      "keywords": "affiliation",
      "description": "Siliang Tang affiliated with Renmin University of China"
    },
    {
      "source": "Siliang Tang",
      "target": "Rutgers University",
      "keywords": "affiliation",
      "description": "Siliang Tang affiliated with Rutgers University"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "BERT",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses BERT"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "RoBERTa",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses RoBERTa"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "SentenceBERT",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses SentenceBERT"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses GPT-4"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "LLaMA",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses LLaMA"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "T5",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses T5"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "Qwen2",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses Qwen2"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "WebQSP",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses WebQSP"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses Natural Questions"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "MS-MARCO",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses MS-MARCO"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "BEIR",
      "keywords": "uses",
      "description": "Graph Retrieval-Augmented Generation: A Survey uses BEIR"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "ModularRAG",
      "keywords": "proposes",
      "description": "Graph Retrieval-Augmented Generation: A Survey proposes ModularRAG"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "Graph Retrieval-Augmented Generation: A Survey proposes HybridRetrieval"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "HybridGeneration",
      "keywords": "proposes",
      "description": "Graph Retrieval-Augmented Generation: A Survey proposes HybridGeneration"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "JointTraining",
      "keywords": "proposes",
      "description": "Graph Retrieval-Augmented Generation: A Survey proposes JointTraining"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "QA",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to QA"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "KBQA",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to KBQA"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "CSQA",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to CSQA"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "EntityLinking",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to EntityLinking"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "RelationExtraction",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to RelationExtraction"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "FactVerification",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to FactVerification"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "LinkPrediction",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to LinkPrediction"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "ConversationalAI",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to ConversationalAI"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to DocumentSummarization"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "MedicalRAG",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to MedicalRAG"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "LegalRAG",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to LegalRAG"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "EducationalRAG",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to EducationalRAG"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "E-commerce",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to E-commerce"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "Academic Research",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to Academic Research"
    },
    {
      "source": "Graph Retrieval-Augmented Generation: A Survey",
      "target": "Literature Analysis",
      "keywords": "applies_to",
      "description": "Graph Retrieval-Augmented Generation: A Survey applies to Literature Analysis"
    },
    {
      "source": "BERT",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "BERT potentially trained on WebQSP"
    },
    {
      "source": "BERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "BERT potentially trained on Natural Questions"
    },
    {
      "source": "BERT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MS-MARCO"
    },
    {
      "source": "BERT",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "BERT potentially trained on BEIR"
    },
    {
      "source": "RoBERTa",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on WebQSP"
    },
    {
      "source": "RoBERTa",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on Natural Questions"
    },
    {
      "source": "RoBERTa",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on MS-MARCO"
    },
    {
      "source": "RoBERTa",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "RoBERTa potentially trained on BEIR"
    },
    {
      "source": "SentenceBERT",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "SentenceBERT potentially trained on WebQSP"
    },
    {
      "source": "SentenceBERT",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "SentenceBERT potentially trained on Natural Questions"
    },
    {
      "source": "SentenceBERT",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "SentenceBERT potentially trained on MS-MARCO"
    },
    {
      "source": "SentenceBERT",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "SentenceBERT potentially trained on BEIR"
    },
    {
      "source": "GPT-4",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on WebQSP"
    },
    {
      "source": "GPT-4",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Natural Questions"
    },
    {
      "source": "GPT-4",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on MS-MARCO"
    },
    {
      "source": "GPT-4",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on BEIR"
    },
    {
      "source": "LLaMA",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on WebQSP"
    },
    {
      "source": "LLaMA",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on Natural Questions"
    },
    {
      "source": "LLaMA",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on MS-MARCO"
    },
    {
      "source": "LLaMA",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "LLaMA potentially trained on BEIR"
    },
    {
      "source": "T5",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "T5 potentially trained on WebQSP"
    },
    {
      "source": "T5",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "T5 potentially trained on Natural Questions"
    },
    {
      "source": "T5",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "T5 potentially trained on MS-MARCO"
    },
    {
      "source": "T5",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "T5 potentially trained on BEIR"
    },
    {
      "source": "Qwen2",
      "target": "WebQSP",
      "keywords": "trained_on",
      "description": "Qwen2 potentially trained on WebQSP"
    },
    {
      "source": "Qwen2",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "Qwen2 potentially trained on Natural Questions"
    },
    {
      "source": "Qwen2",
      "target": "MS-MARCO",
      "keywords": "trained_on",
      "description": "Qwen2 potentially trained on MS-MARCO"
    },
    {
      "source": "Qwen2",
      "target": "BEIR",
      "keywords": "trained_on",
      "description": "Qwen2 potentially trained on BEIR"
    },
    {
      "source": "ModularRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "ModularRAG supports QA"
    },
    {
      "source": "ModularRAG",
      "target": "KBQA",
      "keywords": "supports",
      "description": "ModularRAG supports KBQA"
    },
    {
      "source": "ModularRAG",
      "target": "CSQA",
      "keywords": "supports",
      "description": "ModularRAG supports CSQA"
    },
    {
      "source": "ModularRAG",
      "target": "EntityLinking",
      "keywords": "supports",
      "description": "ModularRAG supports EntityLinking"
    },
    {
      "source": "ModularRAG",
      "target": "RelationExtraction",
      "keywords": "supports",
      "description": "ModularRAG supports RelationExtraction"
    },
    {
      "source": "ModularRAG",
      "target": "FactVerification",
      "keywords": "supports",
      "description": "ModularRAG supports FactVerification"
    },
    {
      "source": "ModularRAG",
      "target": "LinkPrediction",
      "keywords": "supports",
      "description": "ModularRAG supports LinkPrediction"
    },
    {
      "source": "ModularRAG",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "ModularRAG supports ConversationalAI"
    },
    {
      "source": "ModularRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "ModularRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "KBQA",
      "keywords": "supports",
      "description": "HybridRetrieval supports KBQA"
    },
    {
      "source": "HybridRetrieval",
      "target": "CSQA",
      "keywords": "supports",
      "description": "HybridRetrieval supports CSQA"
    },
    {
      "source": "HybridRetrieval",
      "target": "EntityLinking",
      "keywords": "supports",
      "description": "HybridRetrieval supports EntityLinking"
    },
    {
      "source": "HybridRetrieval",
      "target": "RelationExtraction",
      "keywords": "supports",
      "description": "HybridRetrieval supports RelationExtraction"
    },
    {
      "source": "HybridRetrieval",
      "target": "FactVerification",
      "keywords": "supports",
      "description": "HybridRetrieval supports FactVerification"
    },
    {
      "source": "HybridRetrieval",
      "target": "LinkPrediction",
      "keywords": "supports",
      "description": "HybridRetrieval supports LinkPrediction"
    },
    {
      "source": "HybridRetrieval",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridRetrieval supports ConversationalAI"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "HybridGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridGeneration supports QA"
    },
    {
      "source": "HybridGeneration",
      "target": "KBQA",
      "keywords": "supports",
      "description": "HybridGeneration supports KBQA"
    },
    {
      "source": "HybridGeneration",
      "target": "CSQA",
      "keywords": "supports",
      "description": "HybridGeneration supports CSQA"
    },
    {
      "source": "HybridGeneration",
      "target": "EntityLinking",
      "keywords": "supports",
      "description": "HybridGeneration supports EntityLinking"
    },
    {
      "source": "HybridGeneration",
      "target": "RelationExtraction",
      "keywords": "supports",
      "description": "HybridGeneration supports RelationExtraction"
    },
    {
      "source": "HybridGeneration",
      "target": "FactVerification",
      "keywords": "supports",
      "description": "HybridGeneration supports FactVerification"
    },
    {
      "source": "HybridGeneration",
      "target": "LinkPrediction",
      "keywords": "supports",
      "description": "HybridGeneration supports LinkPrediction"
    },
    {
      "source": "HybridGeneration",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "HybridGeneration supports ConversationalAI"
    },
    {
      "source": "HybridGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridGeneration supports DocumentSummarization"
    },
    {
      "source": "JointTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "JointTraining supports QA"
    },
    {
      "source": "JointTraining",
      "target": "KBQA",
      "keywords": "supports",
      "description": "JointTraining supports KBQA"
    },
    {
      "source": "JointTraining",
      "target": "CSQA",
      "keywords": "supports",
      "description": "JointTraining supports CSQA"
    },
    {
      "source": "JointTraining",
      "target": "EntityLinking",
      "keywords": "supports",
      "description": "JointTraining supports EntityLinking"
    },
    {
      "source": "JointTraining",
      "target": "RelationExtraction",
      "keywords": "supports",
      "description": "JointTraining supports RelationExtraction"
    },
    {
      "source": "JointTraining",
      "target": "FactVerification",
      "keywords": "supports",
      "description": "JointTraining supports FactVerification"
    },
    {
      "source": "JointTraining",
      "target": "LinkPrediction",
      "keywords": "supports",
      "description": "JointTraining supports LinkPrediction"
    },
    {
      "source": "JointTraining",
      "target": "ConversationalAI",
      "keywords": "supports",
      "description": "JointTraining supports ConversationalAI"
    },
    {
      "source": "JointTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "JointTraining supports DocumentSummarization"
    },
    {
      "source": "Darren Edge",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Darren Edge authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Ha Trinh",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Ha Trinh authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Newman Cheng",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Newman Cheng authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Joshua Bradley",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Joshua Bradley authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Alex Chao",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Alex Chao authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Apurva Mody",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Apurva Mody authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Steven Truitt",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Steven Truitt authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Dasha Metropolitansky",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Dasha Metropolitansky authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Robert Osazuwa Ness",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Robert Osazuwa Ness authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Jonathan Larson",
      "target": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "keywords": "authorship",
      "description": "Jonathan Larson authored From Local to Global: A GraphRAG Approach to Query-Focused Summarization"
    },
    {
      "source": "Darren Edge",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Darren Edge affiliated with Microsoft Research"
    },
    {
      "source": "Darren Edge",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Darren Edge affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Darren Edge",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Darren Edge affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Ha Trinh",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Ha Trinh affiliated with Microsoft Research"
    },
    {
      "source": "Ha Trinh",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Ha Trinh affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Ha Trinh",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Ha Trinh affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Newman Cheng",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Newman Cheng affiliated with Microsoft Research"
    },
    {
      "source": "Newman Cheng",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Newman Cheng affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Newman Cheng",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Newman Cheng affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Joshua Bradley",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Joshua Bradley affiliated with Microsoft Research"
    },
    {
      "source": "Joshua Bradley",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Joshua Bradley affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Joshua Bradley",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Joshua Bradley affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Alex Chao",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Alex Chao affiliated with Microsoft Research"
    },
    {
      "source": "Alex Chao",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Alex Chao affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Alex Chao",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Alex Chao affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Apurva Mody",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Apurva Mody affiliated with Microsoft Research"
    },
    {
      "source": "Apurva Mody",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Apurva Mody affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Apurva Mody",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Apurva Mody affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Steven Truitt",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Steven Truitt affiliated with Microsoft Research"
    },
    {
      "source": "Steven Truitt",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Steven Truitt affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Steven Truitt",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Steven Truitt affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Dasha Metropolitansky",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Dasha Metropolitansky affiliated with Microsoft Research"
    },
    {
      "source": "Dasha Metropolitansky",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Dasha Metropolitansky affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Dasha Metropolitansky",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Dasha Metropolitansky affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Robert Osazuwa Ness",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Robert Osazuwa Ness affiliated with Microsoft Research"
    },
    {
      "source": "Robert Osazuwa Ness",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Robert Osazuwa Ness affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Robert Osazuwa Ness",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Robert Osazuwa Ness affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "Jonathan Larson",
      "target": "Microsoft Research",
      "keywords": "affiliation",
      "description": "Jonathan Larson affiliated with Microsoft Research"
    },
    {
      "source": "Jonathan Larson",
      "target": "Microsoft Strategic Missions and Technologies",
      "keywords": "affiliation",
      "description": "Jonathan Larson affiliated with Microsoft Strategic Missions and Technologies"
    },
    {
      "source": "Jonathan Larson",
      "target": "Microsoft Office of the CTO",
      "keywords": "affiliation",
      "description": "Jonathan Larson affiliated with Microsoft Office of the CTO"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "Vector RAG baseline",
      "keywords": "uses",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization uses Vector RAG baseline"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "GPT-4",
      "keywords": "uses",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization uses GPT-4"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "Behind the Tech podcast transcripts",
      "keywords": "uses",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization uses Behind the Tech podcast transcripts"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "News articles dataset",
      "keywords": "uses",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization uses News articles dataset"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "HotPotQA",
      "keywords": "uses",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization uses HotPotQA"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "HierarchicalRAG",
      "keywords": "proposes",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization proposes HierarchicalRAG"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "HybridRetrieval",
      "keywords": "proposes",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization proposes HybridRetrieval"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization proposes AbstractiveGeneration"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization proposes SeparateTraining"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "QA",
      "keywords": "applies_to",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization applies to QA"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "DocumentSummarization",
      "keywords": "applies_to",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization applies to DocumentSummarization"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "Global sensemaking over large text corpora",
      "keywords": "applies_to",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization applies to Global sensemaking over large text corpora"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "Intelligence analysis",
      "keywords": "applies_to",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization applies to Intelligence analysis"
    },
    {
      "source": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization",
      "target": "Scientific discovery support",
      "keywords": "applies_to",
      "description": "From Local to Global: A GraphRAG Approach to Query-Focused Summarization applies to Scientific discovery support"
    },
    {
      "source": "Vector RAG baseline",
      "target": "Behind the Tech podcast transcripts",
      "keywords": "trained_on",
      "description": "Vector RAG baseline potentially trained on Behind the Tech podcast transcripts"
    },
    {
      "source": "Vector RAG baseline",
      "target": "News articles dataset",
      "keywords": "trained_on",
      "description": "Vector RAG baseline potentially trained on News articles dataset"
    },
    {
      "source": "Vector RAG baseline",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "Vector RAG baseline potentially trained on HotPotQA"
    },
    {
      "source": "GPT-4",
      "target": "Behind the Tech podcast transcripts",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on Behind the Tech podcast transcripts"
    },
    {
      "source": "GPT-4",
      "target": "News articles dataset",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on News articles dataset"
    },
    {
      "source": "GPT-4",
      "target": "HotPotQA",
      "keywords": "trained_on",
      "description": "GPT-4 potentially trained on HotPotQA"
    },
    {
      "source": "HierarchicalRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "HierarchicalRAG supports QA"
    },
    {
      "source": "HierarchicalRAG",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HierarchicalRAG supports DocumentSummarization"
    },
    {
      "source": "HybridRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "HybridRetrieval supports QA"
    },
    {
      "source": "HybridRetrieval",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "HybridRetrieval supports DocumentSummarization"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports DocumentSummarization"
    },
    {
      "source": "SeparateTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "SeparateTraining supports QA"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentSummarization",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentSummarization"
    },
    {
      "source": "Xiao Wang",
      "target": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "keywords": "authorship",
      "description": "Xiao Wang authored Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "source": "Craig Macdonald",
      "target": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "keywords": "authorship",
      "description": "Craig Macdonald authored Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "keywords": "authorship",
      "description": "Nicola Tonellotto authored Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "source": "Iadh Ounis",
      "target": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "keywords": "authorship",
      "description": "Iadh Ounis authored Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval"
    },
    {
      "source": "Xiao Wang",
      "target": "University of Glasgow",
      "keywords": "affiliation",
      "description": "Xiao Wang affiliated with University of Glasgow"
    },
    {
      "source": "Xiao Wang",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Xiao Wang affiliated with University of Pisa"
    },
    {
      "source": "Craig Macdonald",
      "target": "University of Glasgow",
      "keywords": "affiliation",
      "description": "Craig Macdonald affiliated with University of Glasgow"
    },
    {
      "source": "Craig Macdonald",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Craig Macdonald affiliated with University of Pisa"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "University of Glasgow",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with University of Glasgow"
    },
    {
      "source": "Nicola Tonellotto",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Nicola Tonellotto affiliated with University of Pisa"
    },
    {
      "source": "Iadh Ounis",
      "target": "University of Glasgow",
      "keywords": "affiliation",
      "description": "Iadh Ounis affiliated with University of Glasgow"
    },
    {
      "source": "Iadh Ounis",
      "target": "University of Pisa",
      "keywords": "affiliation",
      "description": "Iadh Ounis affiliated with University of Pisa"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "ColBERT",
      "keywords": "uses",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval uses ColBERT"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "BERT",
      "keywords": "uses",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval uses BERT"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "BERT reranker",
      "keywords": "uses",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval uses BERT reranker"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "MSMARCO passage ranking",
      "keywords": "uses",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval uses MSMARCO passage ranking"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "TREC 2019 Deep Learning track",
      "keywords": "uses",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval uses TREC 2019 Deep Learning track"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "TREC 2020 Deep Learning track",
      "keywords": "uses",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval uses TREC 2020 Deep Learning track"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval proposes PipelineRAG"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval proposes DenseRetrieval"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "ExtractiveGeneration",
      "keywords": "proposes",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval proposes ExtractiveGeneration"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval proposes SeparateTraining"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "DocumentRetrieval",
      "keywords": "applies_to",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval applies to DocumentRetrieval"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "PassageRanking",
      "keywords": "applies_to",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval applies to PassageRanking"
    },
    {
      "source": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval",
      "target": "GeneralDomain",
      "keywords": "applies_to",
      "description": "Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval applies to GeneralDomain"
    },
    {
      "source": "ColBERT",
      "target": "MSMARCO passage ranking",
      "keywords": "trained_on",
      "description": "ColBERT potentially trained on MSMARCO passage ranking"
    },
    {
      "source": "ColBERT",
      "target": "TREC 2019 Deep Learning track",
      "keywords": "trained_on",
      "description": "ColBERT potentially trained on TREC 2019 Deep Learning track"
    },
    {
      "source": "ColBERT",
      "target": "TREC 2020 Deep Learning track",
      "keywords": "trained_on",
      "description": "ColBERT potentially trained on TREC 2020 Deep Learning track"
    },
    {
      "source": "BERT",
      "target": "MSMARCO passage ranking",
      "keywords": "trained_on",
      "description": "BERT potentially trained on MSMARCO passage ranking"
    },
    {
      "source": "BERT",
      "target": "TREC 2019 Deep Learning track",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TREC 2019 Deep Learning track"
    },
    {
      "source": "BERT",
      "target": "TREC 2020 Deep Learning track",
      "keywords": "trained_on",
      "description": "BERT potentially trained on TREC 2020 Deep Learning track"
    },
    {
      "source": "BERT reranker",
      "target": "MSMARCO passage ranking",
      "keywords": "trained_on",
      "description": "BERT reranker potentially trained on MSMARCO passage ranking"
    },
    {
      "source": "BERT reranker",
      "target": "TREC 2019 Deep Learning track",
      "keywords": "trained_on",
      "description": "BERT reranker potentially trained on TREC 2019 Deep Learning track"
    },
    {
      "source": "BERT reranker",
      "target": "TREC 2020 Deep Learning track",
      "keywords": "trained_on",
      "description": "BERT reranker potentially trained on TREC 2020 Deep Learning track"
    },
    {
      "source": "PipelineRAG",
      "target": "DocumentRetrieval",
      "keywords": "supports",
      "description": "PipelineRAG supports DocumentRetrieval"
    },
    {
      "source": "PipelineRAG",
      "target": "PassageRanking",
      "keywords": "supports",
      "description": "PipelineRAG supports PassageRanking"
    },
    {
      "source": "DenseRetrieval",
      "target": "DocumentRetrieval",
      "keywords": "supports",
      "description": "DenseRetrieval supports DocumentRetrieval"
    },
    {
      "source": "DenseRetrieval",
      "target": "PassageRanking",
      "keywords": "supports",
      "description": "DenseRetrieval supports PassageRanking"
    },
    {
      "source": "ExtractiveGeneration",
      "target": "DocumentRetrieval",
      "keywords": "supports",
      "description": "ExtractiveGeneration supports DocumentRetrieval"
    },
    {
      "source": "ExtractiveGeneration",
      "target": "PassageRanking",
      "keywords": "supports",
      "description": "ExtractiveGeneration supports PassageRanking"
    },
    {
      "source": "SeparateTraining",
      "target": "DocumentRetrieval",
      "keywords": "supports",
      "description": "SeparateTraining supports DocumentRetrieval"
    },
    {
      "source": "SeparateTraining",
      "target": "PassageRanking",
      "keywords": "supports",
      "description": "SeparateTraining supports PassageRanking"
    },
    {
      "source": "Xiao Zhang",
      "target": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "keywords": "authorship",
      "description": "Xiao Zhang authored Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "source": "Yixiao Ge",
      "target": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "keywords": "authorship",
      "description": "Yixiao Ge authored Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "source": "Yu Qiao",
      "target": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "keywords": "authorship",
      "description": "Yu Qiao authored Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "source": "Hongsheng Li",
      "target": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "keywords": "authorship",
      "description": "Hongsheng Li authored Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification"
    },
    {
      "source": "Xiao Zhang",
      "target": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Xiao Zhang affiliated with CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong"
    },
    {
      "source": "Xiao Zhang",
      "target": "SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Xiao Zhang affiliated with SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences"
    },
    {
      "source": "Xiao Zhang",
      "target": "Shanghai AI Laboratory",
      "keywords": "affiliation",
      "description": "Xiao Zhang affiliated with Shanghai AI Laboratory"
    },
    {
      "source": "Xiao Zhang",
      "target": "School of CST, Xidian University",
      "keywords": "affiliation",
      "description": "Xiao Zhang affiliated with School of CST, Xidian University"
    },
    {
      "source": "Yixiao Ge",
      "target": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Yixiao Ge affiliated with CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong"
    },
    {
      "source": "Yixiao Ge",
      "target": "SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Yixiao Ge affiliated with SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences"
    },
    {
      "source": "Yixiao Ge",
      "target": "Shanghai AI Laboratory",
      "keywords": "affiliation",
      "description": "Yixiao Ge affiliated with Shanghai AI Laboratory"
    },
    {
      "source": "Yixiao Ge",
      "target": "School of CST, Xidian University",
      "keywords": "affiliation",
      "description": "Yixiao Ge affiliated with School of CST, Xidian University"
    },
    {
      "source": "Yu Qiao",
      "target": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Yu Qiao affiliated with CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong"
    },
    {
      "source": "Yu Qiao",
      "target": "SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Yu Qiao affiliated with SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences"
    },
    {
      "source": "Yu Qiao",
      "target": "Shanghai AI Laboratory",
      "keywords": "affiliation",
      "description": "Yu Qiao affiliated with Shanghai AI Laboratory"
    },
    {
      "source": "Yu Qiao",
      "target": "School of CST, Xidian University",
      "keywords": "affiliation",
      "description": "Yu Qiao affiliated with School of CST, Xidian University"
    },
    {
      "source": "Hongsheng Li",
      "target": "CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong",
      "keywords": "affiliation",
      "description": "Hongsheng Li affiliated with CUHK-SenseTime Joint Laboratory, The Chinese University of Hong Kong"
    },
    {
      "source": "Hongsheng Li",
      "target": "SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences",
      "keywords": "affiliation",
      "description": "Hongsheng Li affiliated with SIAT-SenseTime Joint Lab, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences"
    },
    {
      "source": "Hongsheng Li",
      "target": "Shanghai AI Laboratory",
      "keywords": "affiliation",
      "description": "Hongsheng Li affiliated with Shanghai AI Laboratory"
    },
    {
      "source": "Hongsheng Li",
      "target": "School of CST, Xidian University",
      "keywords": "affiliation",
      "description": "Hongsheng Li affiliated with School of CST, Xidian University"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "ResNet-50",
      "keywords": "uses",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification uses ResNet-50"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Market-1501",
      "keywords": "uses",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification uses Market-1501"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "DukeMTMC-reID",
      "keywords": "uses",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification uses DukeMTMC-reID"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "MSMT17",
      "keywords": "uses",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification uses MSMT17"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "VeRi-776",
      "keywords": "uses",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification uses VeRi-776"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification proposes PipelineRAG"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Not applicable",
      "keywords": "proposes",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification proposes Not applicable"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Not applicable",
      "keywords": "proposes",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification proposes Not applicable"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "SeparateTraining",
      "keywords": "proposes",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification proposes SeparateTraining"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Object Re-identification",
      "keywords": "applies_to",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification applies to Object Re-identification"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Person Re-identification",
      "keywords": "applies_to",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification applies to Person Re-identification"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Vehicle Re-identification",
      "keywords": "applies_to",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification applies to Vehicle Re-identification"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Surveillance systems",
      "keywords": "applies_to",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification applies to Surveillance systems"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Security applications",
      "keywords": "applies_to",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification applies to Security applications"
    },
    {
      "source": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification",
      "target": "Urban monitoring",
      "keywords": "applies_to",
      "description": "Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification applies to Urban monitoring"
    },
    {
      "source": "ResNet-50",
      "target": "Market-1501",
      "keywords": "trained_on",
      "description": "ResNet-50 potentially trained on Market-1501"
    },
    {
      "source": "ResNet-50",
      "target": "DukeMTMC-reID",
      "keywords": "trained_on",
      "description": "ResNet-50 potentially trained on DukeMTMC-reID"
    },
    {
      "source": "ResNet-50",
      "target": "MSMT17",
      "keywords": "trained_on",
      "description": "ResNet-50 potentially trained on MSMT17"
    },
    {
      "source": "ResNet-50",
      "target": "VeRi-776",
      "keywords": "trained_on",
      "description": "ResNet-50 potentially trained on VeRi-776"
    },
    {
      "source": "PipelineRAG",
      "target": "Object Re-identification",
      "keywords": "supports",
      "description": "PipelineRAG supports Object Re-identification"
    },
    {
      "source": "PipelineRAG",
      "target": "Person Re-identification",
      "keywords": "supports",
      "description": "PipelineRAG supports Person Re-identification"
    },
    {
      "source": "PipelineRAG",
      "target": "Vehicle Re-identification",
      "keywords": "supports",
      "description": "PipelineRAG supports Vehicle Re-identification"
    },
    {
      "source": "Not applicable",
      "target": "Object Re-identification",
      "keywords": "supports",
      "description": "Not applicable supports Object Re-identification"
    },
    {
      "source": "Not applicable",
      "target": "Person Re-identification",
      "keywords": "supports",
      "description": "Not applicable supports Person Re-identification"
    },
    {
      "source": "Not applicable",
      "target": "Vehicle Re-identification",
      "keywords": "supports",
      "description": "Not applicable supports Vehicle Re-identification"
    },
    {
      "source": "Not applicable",
      "target": "Object Re-identification",
      "keywords": "supports",
      "description": "Not applicable supports Object Re-identification"
    },
    {
      "source": "Not applicable",
      "target": "Person Re-identification",
      "keywords": "supports",
      "description": "Not applicable supports Person Re-identification"
    },
    {
      "source": "Not applicable",
      "target": "Vehicle Re-identification",
      "keywords": "supports",
      "description": "Not applicable supports Vehicle Re-identification"
    },
    {
      "source": "SeparateTraining",
      "target": "Object Re-identification",
      "keywords": "supports",
      "description": "SeparateTraining supports Object Re-identification"
    },
    {
      "source": "SeparateTraining",
      "target": "Person Re-identification",
      "keywords": "supports",
      "description": "SeparateTraining supports Person Re-identification"
    },
    {
      "source": "SeparateTraining",
      "target": "Vehicle Re-identification",
      "keywords": "supports",
      "description": "SeparateTraining supports Vehicle Re-identification"
    },
    {
      "source": "Akari Asai",
      "target": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "keywords": "authorship",
      "description": "Akari Asai authored One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval"
    },
    {
      "source": "Xinyan Yu",
      "target": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "keywords": "authorship",
      "description": "Xinyan Yu authored One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval"
    },
    {
      "source": "Jungo Kasai",
      "target": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "keywords": "authorship",
      "description": "Jungo Kasai authored One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "keywords": "authorship",
      "description": "Hannaneh Hajishirzi authored One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval"
    },
    {
      "source": "Akari Asai",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Akari Asai affiliated with University of Washington"
    },
    {
      "source": "Akari Asai",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Akari Asai affiliated with Allen Institute for AI"
    },
    {
      "source": "Xinyan Yu",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Xinyan Yu affiliated with University of Washington"
    },
    {
      "source": "Xinyan Yu",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Xinyan Yu affiliated with Allen Institute for AI"
    },
    {
      "source": "Jungo Kasai",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Jungo Kasai affiliated with University of Washington"
    },
    {
      "source": "Jungo Kasai",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Jungo Kasai affiliated with Allen Institute for AI"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "University of Washington",
      "keywords": "affiliation",
      "description": "Hannaneh Hajishirzi affiliated with University of Washington"
    },
    {
      "source": "Hannaneh Hajishirzi",
      "target": "Allen Institute for AI",
      "keywords": "affiliation",
      "description": "Hannaneh Hajishirzi affiliated with Allen Institute for AI"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "mDPR (multilingual Dense Passage Retriever)",
      "keywords": "uses",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval uses mDPR (multilingual Dense Passage Retriever)"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "mGEN (multilingual Answer Generator)",
      "keywords": "uses",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval uses mGEN (multilingual Answer Generator)"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "XOR-TYDI QA",
      "keywords": "uses",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval uses XOR-TYDI QA"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "MKQA",
      "keywords": "uses",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval uses MKQA"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "Natural Questions",
      "keywords": "uses",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval uses Natural Questions"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "TYDI QA",
      "keywords": "uses",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval uses TYDI QA"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "PipelineRAG",
      "keywords": "proposes",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval proposes PipelineRAG"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "DenseRetrieval",
      "keywords": "proposes",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval proposes DenseRetrieval"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "AbstractiveGeneration",
      "keywords": "proposes",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval proposes AbstractiveGeneration"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "IterativeTraining",
      "keywords": "proposes",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval proposes IterativeTraining"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "QA",
      "keywords": "applies_to",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval applies to QA"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "multilingual information seeking",
      "keywords": "applies_to",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval applies to multilingual information seeking"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "cross-lingual knowledge access",
      "keywords": "applies_to",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval applies to cross-lingual knowledge access"
    },
    {
      "source": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval",
      "target": "low-resource language QA",
      "keywords": "applies_to",
      "description": "One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval applies to low-resource language QA"
    },
    {
      "source": "mDPR (multilingual Dense Passage Retriever)",
      "target": "XOR-TYDI QA",
      "keywords": "trained_on",
      "description": "mDPR (multilingual Dense Passage Retriever) potentially trained on XOR-TYDI QA"
    },
    {
      "source": "mDPR (multilingual Dense Passage Retriever)",
      "target": "MKQA",
      "keywords": "trained_on",
      "description": "mDPR (multilingual Dense Passage Retriever) potentially trained on MKQA"
    },
    {
      "source": "mDPR (multilingual Dense Passage Retriever)",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "mDPR (multilingual Dense Passage Retriever) potentially trained on Natural Questions"
    },
    {
      "source": "mDPR (multilingual Dense Passage Retriever)",
      "target": "TYDI QA",
      "keywords": "trained_on",
      "description": "mDPR (multilingual Dense Passage Retriever) potentially trained on TYDI QA"
    },
    {
      "source": "mGEN (multilingual Answer Generator)",
      "target": "XOR-TYDI QA",
      "keywords": "trained_on",
      "description": "mGEN (multilingual Answer Generator) potentially trained on XOR-TYDI QA"
    },
    {
      "source": "mGEN (multilingual Answer Generator)",
      "target": "MKQA",
      "keywords": "trained_on",
      "description": "mGEN (multilingual Answer Generator) potentially trained on MKQA"
    },
    {
      "source": "mGEN (multilingual Answer Generator)",
      "target": "Natural Questions",
      "keywords": "trained_on",
      "description": "mGEN (multilingual Answer Generator) potentially trained on Natural Questions"
    },
    {
      "source": "mGEN (multilingual Answer Generator)",
      "target": "TYDI QA",
      "keywords": "trained_on",
      "description": "mGEN (multilingual Answer Generator) potentially trained on TYDI QA"
    },
    {
      "source": "PipelineRAG",
      "target": "QA",
      "keywords": "supports",
      "description": "PipelineRAG supports QA"
    },
    {
      "source": "DenseRetrieval",
      "target": "QA",
      "keywords": "supports",
      "description": "DenseRetrieval supports QA"
    },
    {
      "source": "AbstractiveGeneration",
      "target": "QA",
      "keywords": "supports",
      "description": "AbstractiveGeneration supports QA"
    },
    {
      "source": "IterativeTraining",
      "target": "QA",
      "keywords": "supports",
      "description": "IterativeTraining supports QA"
    }
  ]
}